"""
Google Cloud Video Intelligence API åˆ†æå™¨

ä¸“é—¨å¤„ç†Google Cloudè§†é¢‘åˆ†æåŠŸèƒ½çš„æ¨¡å—
"""

import os
import time
import logging
import json
import uuid
from typing import Dict, Any, List, Tuple, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class GoogleVideoAnalyzer:
    """Google Cloud Video Intelligence API åˆ†æå™¨"""

    def __init__(self, credentials_path: Optional[str] = None):
        """
        åˆå§‹åŒ–Google Cloudåˆ†æå™¨

        Args:
            credentials_path: Google Cloudå‡­æ®æ–‡ä»¶è·¯å¾„
        """
        # ğŸ”§ ä¿®å¤ï¼šæ­£ç¡®çš„å‡­æ®è·¯å¾„ä¼˜å…ˆçº§
        # 1. ç”¨æˆ·æä¾›çš„è·¯å¾„
        # 2. data/temp/google_cloud/ä¸‹çš„å®é™…å‡­æ®æ–‡ä»¶ï¼ˆä¼˜å…ˆï¼‰
        # 3. temp/ç›®å½•ä¸‹çš„é€šç”¨å‡­æ®æ–‡ä»¶
        # 4. ç¯å¢ƒå˜é‡æŒ‡å®šçš„è·¯å¾„ï¼ˆæœ€åï¼‰
        actual_cred_path = "data/temp/google_cloud/video-ai-461014-d0c437ff635f.json"
        temp_cred_path = "temp/google_credentials.json"
        
        if credentials_path:
            self.credentials_path = credentials_path
        elif os.path.exists(actual_cred_path):
            self.credentials_path = actual_cred_path
        elif os.path.exists(temp_cred_path):
            self.credentials_path = temp_cred_path
        else:
            self.credentials_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
        
        self.client = None
        self.storage_client = None
        self.project_id = None

        # è®¾ç½®ç¯å¢ƒå˜é‡
        if self.credentials_path and os.path.exists(self.credentials_path):
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(os.path.abspath(self.credentials_path))
            logger.info(f"ä½¿ç”¨Google Cloudå‡­æ®: {self.credentials_path}")

            # è·å–é¡¹ç›®ID
            try:
                with open(self.credentials_path, 'r', encoding='utf-8') as f:
                    cred_data = json.load(f)
                    self.project_id = cred_data.get('project_id')
                    logger.info(f"é¡¹ç›®ID: {self.project_id}")
            except Exception as e:
                logger.warning(f"æ— æ³•è¯»å–é¡¹ç›®ID: {e}")
        else:
            logger.warning(f"Google Cloudå‡­æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.credentials_path}")

        self._initialize_clients()

    def _initialize_clients(self):
        """åˆå§‹åŒ–Google Cloudå®¢æˆ·ç«¯"""
        try:
            from google.cloud import videointelligence_v1 as vi
            from google.cloud import storage

            self.client = vi.VideoIntelligenceServiceClient()
            self.storage_client = storage.Client()
            logger.info("Google Cloudå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Google Cloudå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.client = None
            self.storage_client = None

    def check_credentials(self) -> Tuple[bool, Optional[str]]:
        """æ£€æŸ¥Google Cloudå‡­æ®æ˜¯å¦æœ‰æ•ˆ"""
        if self.credentials_path and os.path.exists(self.credentials_path):
            try:
                # éªŒè¯JSONæ–‡ä»¶æ ¼å¼
                import json
                with open(self.credentials_path, 'r', encoding='utf-8') as f:
                    cred_data = json.load(f)

                # æ£€æŸ¥å¿…è¦å­—æ®µ
                required_fields = ['type', 'project_id', 'private_key', 'client_email']
                if all(field in cred_data for field in required_fields):
                    logger.info(f"Google Cloudå‡­æ®æœ‰æ•ˆï¼Œé¡¹ç›®ID: {cred_data.get('project_id', 'Unknown')}")
                    return True, self.credentials_path
                else:
                    logger.error("Google Cloudå‡­æ®æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ")
                    return False, None
            except Exception as e:
                logger.error(f"Google Cloudå‡­æ®æ–‡ä»¶éªŒè¯å¤±è´¥: {str(e)}")
                return False, None
        else:
            logger.warning(f"Google Cloudå‡­æ®æ–‡ä»¶ä¸å­˜åœ¨: {self.credentials_path}")
            return False, None

    def analyze_video(
        self,
        video_path: Optional[str] = None,
        video_uri: Optional[str] = None,
        features: List[str] = None,
        progress_callback: Optional[callable] = None,
        auto_cleanup_storage: bool = False,
        bucket_name: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        åˆ†æè§†é¢‘å†…å®¹

        Args:
            video_path: æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„
            video_uri: äº‘ç«¯è§†é¢‘URIï¼ˆå¦‚gs://bucket/video.mp4ï¼‰
            features: è¦åˆ†æçš„åŠŸèƒ½åˆ—è¡¨
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            auto_cleanup_storage: æ˜¯å¦åœ¨åˆ†æå®Œæˆåè‡ªåŠ¨åˆ é™¤ä¸Šä¼ çš„æ–‡ä»¶
            bucket_name: Cloud Storageæ¡¶åï¼ˆå¦‚æœä¸æä¾›ä¼šä½¿ç”¨é»˜è®¤çš„ai-video-masterï¼‰

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.client:
            raise Exception("Google Cloudå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        # æ£€æŸ¥ç½‘ç»œè¿æ¥
        if progress_callback:
            progress_callback(5, "æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒæœåŠ¡å¯ç”¨æ€§...")

        try:
            import requests
            # æ£€æŸ¥åŸºæœ¬ç½‘ç»œè¿æ¥
            requests.get("https://www.google.com", timeout=5)

            # å¿«é€Ÿæ£€æŸ¥Google CloudæœåŠ¡å¯ç”¨æ€§
            response = requests.get("https://videointelligence.googleapis.com", timeout=10)
            logger.info("Google Cloud Video IntelligenceæœåŠ¡è¿æ¥æ­£å¸¸")
        except requests.exceptions.ProxyError as e:
            error_msg = f"ä»£ç†æœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä»£ç†è®¾ç½®: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
        except requests.exceptions.ConnectTimeout as e:
            error_msg = f"è¿æ¥è¶…æ—¶ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
        except requests.exceptions.ConnectionError as e:
            error_msg = f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}
        except Exception as e:
            error_msg = f"æ— æ³•è¿æ¥åˆ°Google CloudæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥: {str(e)}"
            logger.error(error_msg)
            return {"success": False, "error": error_msg}

        uploaded_blob_name = None  # è®°å½•ä¸Šä¼ çš„æ–‡ä»¶åï¼Œç”¨äºåç»­åˆ é™¤
        bucket = None

        try:
            from google.cloud import videointelligence_v1 as vi

            # é»˜è®¤åŠŸèƒ½
            if not features:
                features = ["shot_detection", "label_detection"]

            # è½¬æ¢åŠŸèƒ½åç§°ä¸ºAPIæšä¸¾
            feature_map = {
                "shot_detection": vi.Feature.SHOT_CHANGE_DETECTION,
                "label_detection": vi.Feature.LABEL_DETECTION,
                "text_detection": vi.Feature.TEXT_DETECTION,
                "face_detection": vi.Feature.FACE_DETECTION,
                "object_tracking": vi.Feature.OBJECT_TRACKING
            }

            api_features = [feature_map[f] for f in features if f in feature_map]

            # æ„å»ºè¯·æ±‚
            if video_path and os.path.exists(video_path):
                # æ£€æŸ¥æ–‡ä»¶å¤§å°
                file_size = os.path.getsize(video_path)
                file_size_mb = file_size / (1024 * 1024)

                if progress_callback:
                    progress_callback(15, f"å‡†å¤‡å¤„ç†è§†é¢‘æ–‡ä»¶ ({file_size_mb:.1f}MB)...")

                # å¤§æ–‡ä»¶è­¦å‘Š
                if file_size_mb > 200:
                    logger.warning(f"è§†é¢‘æ–‡ä»¶è¾ƒå¤§ ({file_size_mb:.1f}MB)ï¼Œåˆ†æå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´")
                    if progress_callback:
                        progress_callback(20, f"è§†é¢‘æ–‡ä»¶è¾ƒå¤§ ({file_size_mb:.1f}MB)ï¼Œé¢„è®¡éœ€è¦5-15åˆ†é’Ÿ...")
                elif file_size_mb > 50:
                    if progress_callback:
                        progress_callback(20, f"è§†é¢‘æ–‡ä»¶å¤§å°é€‚ä¸­ ({file_size_mb:.1f}MB)ï¼Œé¢„è®¡éœ€è¦2-5åˆ†é’Ÿ...")
                else:
                    if progress_callback:
                        progress_callback(20, f"è§†é¢‘æ–‡ä»¶è¾ƒå° ({file_size_mb:.1f}MB)ï¼Œé¢„è®¡1-2åˆ†é’Ÿå®Œæˆ...")

                # å¦‚æœéœ€è¦è‡ªåŠ¨æ¸…ç†ï¼Œæˆ–è€…æ–‡ä»¶è¾ƒå¤§ï¼Œåˆ™ä¸Šä¼ åˆ°Cloud Storage
                if auto_cleanup_storage or file_size_mb > 50:
                    if progress_callback:
                        progress_callback(22, "ä¸Šä¼ è§†é¢‘åˆ°Cloud Storage...")
                    
                    # å‡†å¤‡Cloud Storageæ¡¶
                    if not bucket_name:
                        bucket_name = "ai-video-master"
                    
                    bucket = self._ensure_bucket_exists(bucket_name)
                    if not bucket:
                        raise Exception(f"æ— æ³•åˆ›å»ºæˆ–è®¿é—®å­˜å‚¨æ¡¶: {bucket_name}")
                    
                    # ç”Ÿæˆå”¯ä¸€çš„äº‘ç«¯æ–‡ä»¶å
                    import time
                    timestamp = int(time.time())
                    file_name = f"single_analysis_{timestamp}_{uuid.uuid4().hex[:8]}_{Path(video_path).name}"
                    uploaded_blob_name = f"video-analysis/{file_name}"
                    
                    # ä¸Šä¼ æ–‡ä»¶åˆ°Cloud Storage
                    gs_uri = self._upload_to_cloud_storage(bucket, video_path, uploaded_blob_name)
                    if not gs_uri:
                        raise Exception("ä¸Šä¼ è§†é¢‘åˆ°Cloud Storageå¤±è´¥")
                    
                    logger.info(f"è§†é¢‘å·²ä¸Šä¼ åˆ°Cloud Storage: {gs_uri}")
                    request = {"features": api_features, "input_uri": gs_uri}
                    
                    if progress_callback:
                        progress_callback(25, f"è§†é¢‘å·²ä¸Šä¼ åˆ°äº‘ç«¯ï¼Œå¼€å§‹åˆ†æ...")
                else:
                    # å°æ–‡ä»¶ç›´æ¥é€šè¿‡å†…å®¹ä¸Šä¼ 
                    with open(video_path, "rb") as f:
                        input_content = f.read()
                    request = {"features": api_features, "input_content": input_content}
                    
            elif video_uri:
                # äº‘ç«¯æ–‡ä»¶
                request = {"features": api_features, "input_uri": video_uri}
            else:
                raise ValueError("å¿…é¡»æä¾›video_pathæˆ–video_uri")

            # æ‰§è¡Œåˆ†æ
            if progress_callback:
                progress_callback(30, "æ­£åœ¨æäº¤åˆ†æè¯·æ±‚åˆ°Google Cloud...")

            # æ·»åŠ é‡è¯•æœºåˆ¶
            max_retries = 3
            retry_count = 0
            operation = None

            while retry_count < max_retries:
                try:
                    operation = self.client.annotate_video(request=request)
                    break  # æˆåŠŸå°±é€€å‡ºå¾ªç¯
                except Exception as e:
                    retry_count += 1
                    error_str = str(e)

                    if "503" in error_str or "failed to connect" in error_str:
                        if retry_count < max_retries:
                            if progress_callback:
                                progress_callback(30, f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•... ({retry_count}/{max_retries})")
                            time.sleep(5)  # ç­‰å¾…5ç§’åé‡è¯•
                            continue
                        else:
                            raise Exception(f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œå·²é‡è¯•{max_retries}æ¬¡: {error_str}")
                    else:
                        raise e

            if not operation:
                raise Exception("æ— æ³•æäº¤åˆ†æè¯·æ±‚åˆ°Google Cloud")

            if progress_callback:
                progress_callback(35, f"åˆ†æè¯·æ±‚å·²æäº¤ï¼Œæ“ä½œID: {operation.operation.name}")

            # ç­‰å¾…å®Œæˆ
            start_time = time.time()
            timeout = 1200  # å¢åŠ åˆ°20åˆ†é’Ÿè¶…æ—¶
            check_interval = 10  # æ¯10ç§’æ£€æŸ¥ä¸€æ¬¡

            if progress_callback:
                progress_callback(40, "åˆ†æä»»åŠ¡å·²æäº¤åˆ°Google Cloudï¼Œæ­£åœ¨å¤„ç†...")

            while not operation.done():
                elapsed = time.time() - start_time
                if elapsed > timeout:
                    error_msg = f"åˆ†æè¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰ï¼Œè§†é¢‘å¯èƒ½å¤ªå¤§æˆ–ç½‘ç»œè¾ƒæ…¢"
                    logger.error(error_msg)
                    raise TimeoutError(error_msg)

                if progress_callback:
                    # éçº¿æ€§è¿›åº¦è®¡ç®—ï¼Œå‰æœŸæ…¢åæœŸå¿«
                    progress_ratio = min(elapsed / timeout, 0.8)
                    progress = 40 + int(progress_ratio * 50)  # 40-90%

                    # ä¼°ç®—å‰©ä½™æ—¶é—´
                    if elapsed > 30:  # 30ç§’åå¼€å§‹ä¼°ç®—
                        estimated_total = elapsed / progress_ratio if progress_ratio > 0 else timeout
                        remaining = max(0, estimated_total - elapsed)
                        progress_callback(
                            progress,
                            f"åˆ†æè¿›è¡Œä¸­... å·²ç”¨æ—¶ {elapsed:.0f}ç§’ï¼Œé¢„è®¡è¿˜éœ€ {remaining:.0f}ç§’"
                        )
                    else:
                        progress_callback(progress, f"åˆ†æè¿›è¡Œä¸­... å·²ç”¨æ—¶ {elapsed:.0f}ç§’")

                time.sleep(check_interval)

            result = operation.result()

            if progress_callback:
                progress_callback(95, "åˆ†æå®Œæˆï¼Œæ­£åœ¨å¤„ç†ç»“æœ...")

            # åˆ†æå®Œæˆåæ¸…ç†Cloud Storageæ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if auto_cleanup_storage and uploaded_blob_name and bucket:
                try:
                    if progress_callback:
                        progress_callback(97, "æ¸…ç†ä¸´æ—¶äº‘ç«¯æ–‡ä»¶...")
                    
                    blob = bucket.blob(uploaded_blob_name)
                    blob.delete()
                    logger.info(f"å·²åˆ é™¤Cloud Storageæ–‡ä»¶: {uploaded_blob_name}")
                    
                except Exception as e:
                    logger.warning(f"åˆ é™¤Cloud Storageæ–‡ä»¶å¤±è´¥ {uploaded_blob_name}: {str(e)}")

            if progress_callback:
                progress_callback(100, "åˆ†æå®Œæˆï¼")

            return {
                "success": True,
                "result": result,
                "features": features,
                "video_path": video_path,
                "video_uri": video_uri,
                "cleanup_performed": auto_cleanup_storage and uploaded_blob_name is not None
            }

        except Exception as e:
            logger.error(f"Google Cloudè§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            
            # å‡ºé”™æ—¶ä¹Ÿå°è¯•æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
            if auto_cleanup_storage and uploaded_blob_name and bucket:
                try:
                    blob = bucket.blob(uploaded_blob_name)
                    blob.delete()
                    logger.info(f"åˆ†æå¤±è´¥ï¼Œå·²æ¸…ç†Cloud Storageæ–‡ä»¶: {uploaded_blob_name}")
                except Exception as cleanup_e:
                    logger.warning(f"æ¸…ç†å¤±è´¥çš„ä¸Šä¼ æ–‡ä»¶æ—¶å‡ºé”™: {str(cleanup_e)}")
            
            return {
                "success": False,
                "error": str(e),
                "features": features
            }

    def extract_shots(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»åˆ†æç»“æœä¸­æå–é•œå¤´ä¿¡æ¯"""
        shots = []

        if not analysis_result.get("success") or not analysis_result.get("result"):
            return shots

        result = analysis_result["result"]
        if not result.annotation_results:
            return shots

        annotation = result.annotation_results[0]

        if hasattr(annotation, 'shot_annotations') and annotation.shot_annotations:
            for i, shot in enumerate(annotation.shot_annotations):
                try:
                    start_time = self._get_time_seconds(shot.start_time_offset)
                    end_time = self._get_time_seconds(shot.end_time_offset)

                    shots.append({
                        'index': i + 1,
                        'start_time': start_time,
                        'end_time': end_time,
                        'duration': end_time - start_time,
                        'type': f"é•œå¤´{i+1}",
                        'confidence': 1.0
                    })
                except Exception as e:
                    logger.warning(f"å¤„ç†é•œå¤´ {i+1} æ—¶å‡ºé”™: {e}")

        return shots

    def extract_labels(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»åˆ†æç»“æœä¸­æå–æ ‡ç­¾ä¿¡æ¯"""
        labels = []

        if not analysis_result.get("success") or not analysis_result.get("result"):
            return labels

        result = analysis_result["result"]
        if not result.annotation_results:
            return labels

        annotation = result.annotation_results[0]

        if hasattr(annotation, 'segment_label_annotations') and annotation.segment_label_annotations:
            for label in annotation.segment_label_annotations:
                label_name = label.entity.description

                for segment in label.segments:
                    try:
                        start_time = self._get_time_seconds(segment.segment.start_time_offset)
                        end_time = self._get_time_seconds(segment.segment.end_time_offset)
                        confidence = segment.confidence

                        labels.append({
                            'label': label_name,
                            'start_time': start_time,
                            'end_time': end_time,
                            'duration': end_time - start_time,
                            'confidence': confidence,
                            'type': f"æ ‡ç­¾_{label_name}"
                        })
                    except Exception as e:
                        logger.warning(f"å¤„ç†æ ‡ç­¾ {label_name} æ—¶å‡ºé”™: {e}")

        return labels

    def extract_faces(self, analysis_result: Dict[str, Any]) -> List[Dict[str, Any]]:
        """ä»åˆ†æç»“æœä¸­æå–äººè„¸ä¿¡æ¯"""
        faces = []

        if not analysis_result.get("success") or not analysis_result.get("result"):
            return faces

        result = analysis_result["result"]
        if not result.annotation_results:
            return faces

        annotation = result.annotation_results[0]

        if hasattr(annotation, 'face_annotations') and annotation.face_annotations:
            for i, face in enumerate(annotation.face_annotations):
                for j, segment in enumerate(face.segments):
                    try:
                        start_time = self._get_time_seconds(segment.segment.start_time_offset)
                        end_time = self._get_time_seconds(segment.segment.end_time_offset)

                        faces.append({
                            'face_id': i + 1,
                            'segment_id': j + 1,
                            'start_time': start_time,
                            'end_time': end_time,
                            'duration': end_time - start_time,
                            'type': f"äººè„¸{i+1}_ç‰‡æ®µ{j+1}",
                            'confidence': 1.0
                        })
                    except Exception as e:
                        logger.warning(f"å¤„ç†äººè„¸ {i+1} ç‰‡æ®µ {j+1} æ—¶å‡ºé”™: {e}")

        return faces

    def _get_time_seconds(self, time_offset) -> float:
        """å®‰å…¨åœ°è·å–æ—¶é—´åç§»çš„ç§’æ•°"""
        try:
            if hasattr(time_offset, 'total_seconds'):
                return time_offset.total_seconds()
            elif hasattr(time_offset, 'seconds'):
                # å¤„ç† protobuf Duration å¯¹è±¡
                return time_offset.seconds + time_offset.nanos / 1e9
            else:
                # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥è¿”å›
                return float(time_offset)
        except Exception as e:
            logger.warning(f"æ—¶é—´è§£æé”™è¯¯: {e}")
            return 0.0

    def validate_shot_continuity(self, shots: List[Dict[str, Any]]) -> Dict[str, Any]:
        """éªŒè¯é•œå¤´çš„æ—¶é—´è¿è´¯æ€§"""
        if not shots:
            return {"valid": True, "gaps": [], "overlaps": []}

        gaps = []
        overlaps = []

        # æ£€æŸ¥æ˜¯å¦ä»0å¼€å§‹
        first_start = shots[0]['start_time']
        if first_start > 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
            gaps.append(f"è§†é¢‘å¼€å¤´æœ‰ç©ºéš™: 0.00s - {first_start:.2f}s")

        # æ£€æŸ¥ç›¸é‚»é•œå¤´ä¹‹é—´çš„è¿è´¯æ€§
        for i in range(len(shots) - 1):
            current_end = shots[i]['end_time']
            next_start = shots[i+1]['start_time']

            gap = next_start - current_end
            if abs(gap) > 0.1:  # å…è®¸0.1ç§’çš„è¯¯å·®
                if gap > 0:
                    gaps.append(f"é•œå¤´{i+1}å’Œ{i+2}ä¹‹é—´æœ‰ç©ºéš™: {gap:.2f}s")
                else:
                    overlaps.append(f"é•œå¤´{i+1}å’Œ{i+2}æœ‰é‡å : {abs(gap):.2f}s")

        return {
            "valid": len(gaps) == 0 and len(overlaps) == 0,
            "gaps": gaps,
            "overlaps": overlaps,
            "total_shots": len(shots),
            "total_duration": shots[-1]['end_time'] - shots[0]['start_time'] if shots else 0
        }

    def analyze_videos_batch(
        self,
        video_paths: List[str],
        features: List[str] = None,
        bucket_name: Optional[str] = None,
        progress_callback: Optional[callable] = None,
        cleanup_cloud_files: bool = True
    ) -> Dict[str, Any]:
        """
        æ‰¹é‡åˆ†æå¤šä¸ªè§†é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨åŸç”Ÿæ‰¹å¤„ç†APIï¼‰

        Args:
            video_paths: æœ¬åœ°è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            features: è¦åˆ†æçš„åŠŸèƒ½åˆ—è¡¨
            bucket_name: Cloud Storageæ¡¶åï¼ˆå¦‚æœä¸æä¾›ä¼šä½¿ç”¨é»˜è®¤çš„ai-video-masterï¼‰
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°
            cleanup_cloud_files: åˆ†æå®Œæˆåæ˜¯å¦æ¸…ç†äº‘ç«¯æ–‡ä»¶

        Returns:
            æ‰¹å¤„ç†åˆ†æç»“æœå­—å…¸
        """
        if not self.client or not self.storage_client:
            raise Exception("Google Cloudå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")

        if not video_paths:
            return {"success": False, "error": "æ²¡æœ‰æä¾›è§†é¢‘æ–‡ä»¶"}

        try:
            # 1. å‡†å¤‡Cloud Storageæ¡¶
            if progress_callback:
                progress_callback(5, "å‡†å¤‡Cloud Storageå­˜å‚¨æ¡¶...")

            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·å·²åˆ›å»ºçš„å­˜å‚¨æ¡¶
            if not bucket_name:
                bucket_name = "ai-video-master"  # ä½¿ç”¨ç”¨æˆ·å·²åˆ›å»ºçš„å­˜å‚¨æ¡¶

            bucket = self._ensure_bucket_exists(bucket_name)
            if not bucket:
                return {"success": False, "error": f"æ— æ³•åˆ›å»ºæˆ–è®¿é—®å­˜å‚¨æ¡¶: {bucket_name}"}

            # 2. ä¸Šä¼ è§†é¢‘æ–‡ä»¶åˆ°Cloud Storage
            if progress_callback:
                progress_callback(10, f"å¼€å§‹ä¸Šä¼  {len(video_paths)} ä¸ªè§†é¢‘æ–‡ä»¶åˆ°Cloud Storage ({bucket_name})...")

            uploaded_uris = []
            upload_info = []

            for i, video_path in enumerate(video_paths):
                if not os.path.exists(video_path):
                    logger.warning(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {video_path}")
                    continue

                # ç”Ÿæˆå”¯ä¸€çš„äº‘ç«¯æ–‡ä»¶åï¼Œæ·»åŠ æ—¶é—´æˆ³é¿å…å†²çª
                import time
                timestamp = int(time.time())
                file_name = f"batch_{timestamp}_{uuid.uuid4().hex[:8]}_{Path(video_path).name}"
                blob_name = f"video-analysis/{file_name}"  # ä½¿ç”¨æ›´æ¸…æ™°çš„æ–‡ä»¶å¤¹ç»“æ„

                if progress_callback:
                    upload_progress = 10 + (i / len(video_paths)) * 30  # 10-40%
                    progress_callback(int(upload_progress), f"ä¸Šä¼ æ–‡ä»¶ {i+1}/{len(video_paths)}: {Path(video_path).name}")

                try:
                    gs_uri = self._upload_to_cloud_storage(bucket, video_path, blob_name)
                    if gs_uri:
                        uploaded_uris.append(gs_uri)
                        upload_info.append({
                            'local_path': video_path,
                            'gs_uri': gs_uri,
                            'blob_name': blob_name,
                            'file_name': Path(video_path).name
                        })
                        logger.info(f"æˆåŠŸä¸Šä¼ : {video_path} -> {gs_uri}")
                    else:
                        logger.error(f"ä¸Šä¼ å¤±è´¥: {video_path}")
                except Exception as e:
                    logger.error(f"ä¸Šä¼ æ–‡ä»¶å¤±è´¥ {video_path}: {str(e)}")
                    continue

            if not uploaded_uris:
                return {"success": False, "error": "æ²¡æœ‰æˆåŠŸä¸Šä¼ ä»»ä½•è§†é¢‘æ–‡ä»¶"}

            # 3. æ‰§è¡Œæ‰¹é‡åˆ†æ
            if progress_callback:
                progress_callback(45, f"å¼€å§‹æ‰¹é‡åˆ†æ {len(uploaded_uris)} ä¸ªè§†é¢‘...")

            batch_result = self._execute_batch_analysis(uploaded_uris, features, progress_callback)

            # 4. å¤„ç†åˆ†æç»“æœ
            if batch_result.get("success"):
                if progress_callback:
                    progress_callback(90, "å¤„ç†åˆ†æç»“æœ...")

                # æ‰¹å¤„ç†ç»“æœå·²ç»æ˜¯è§£æå¥½çš„ä¸ªåˆ«ç»“æœ
                individual_results = []
                api_individual_results = batch_result.get("individual_results", [])

                for i, api_result in enumerate(api_individual_results):
                    if i < len(upload_info):
                        upload_item = upload_info[i]

                        if api_result.get("success") and api_result.get("result"):
                            # è§£æå•ä¸ªè§†é¢‘çš„ç»“æœ
                            annotation = api_result["result"].annotation_results[0]

                            video_result = {
                                "file_name": upload_item["file_name"],
                                "local_path": upload_item["local_path"],
                                "gs_uri": upload_item["gs_uri"],
                                "success": True,
                                "labels": [],
                                "shots": [],
                                "faces": [],
                                "texts": []
                            }

                            # æå–æ ‡ç­¾
                            if hasattr(annotation, 'segment_label_annotations') and annotation.segment_label_annotations:
                                for label in annotation.segment_label_annotations:
                                    label_name = label.entity.description
                                    confidence = 0.0

                                    if label.segments:
                                        confidence = label.segments[0].confidence

                                    video_result["labels"].append({
                                        "name": label_name,
                                        "confidence": confidence
                                    })

                            individual_results.append(video_result)
                        else:
                            # åˆ†æå¤±è´¥çš„è§†é¢‘
                            individual_results.append({
                                "file_name": upload_item["file_name"],
                                "local_path": upload_item["local_path"],
                                "gs_uri": upload_item["gs_uri"],
                                "success": False,
                                "error": api_result.get("error", "åˆ†æå¤±è´¥"),
                                "labels": [],
                                "shots": [],
                                "faces": [],
                                "texts": []
                            })

                result = {
                    "success": True,
                    "batch_operation_name": batch_result.get("operation_name"),
                    "total_videos": len(uploaded_uris),
                    "successful_uploads": len(uploaded_uris),
                    "individual_results": individual_results,
                    "upload_info": upload_info,
                    "bucket_name": bucket_name,
                    "features": features
                }
            else:
                result = {
                    "success": False,
                    "error": batch_result.get("error", "æ‰¹é‡åˆ†æå¤±è´¥"),
                    "upload_info": upload_info,
                    "bucket_name": bucket_name
                }

            # 5. æ¸…ç†äº‘ç«¯æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
            if cleanup_cloud_files:
                if progress_callback:
                    progress_callback(95, "æ¸…ç†ä¸´æ—¶äº‘ç«¯æ–‡ä»¶...")
                self._cleanup_cloud_files(bucket, upload_info)

            if progress_callback:
                progress_callback(100, "æ‰¹é‡åˆ†æå®Œæˆï¼")

            return result

        except Exception as e:
            logger.error(f"æ‰¹é‡è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "features": features
            }

    def _ensure_bucket_exists(self, bucket_name: str):
        """ç¡®ä¿Cloud Storageæ¡¶å­˜åœ¨"""
        try:
            # å°è¯•è·å–ç°æœ‰æ¡¶
            bucket = self.storage_client.bucket(bucket_name)
            if bucket.exists():
                logger.info(f"ä½¿ç”¨ç°æœ‰å­˜å‚¨æ¡¶: {bucket_name}")
                return bucket

            # åˆ›å»ºæ–°æ¡¶
            bucket = self.storage_client.create_bucket(bucket_name)
            logger.info(f"åˆ›å»ºæ–°å­˜å‚¨æ¡¶: {bucket_name}")
            return bucket

        except Exception as e:
            logger.error(f"å­˜å‚¨æ¡¶æ“ä½œå¤±è´¥: {str(e)}")
            return None

    def _upload_to_cloud_storage(self, bucket, local_path: str, blob_name: str) -> Optional[str]:
        """ä¸Šä¼ æ–‡ä»¶åˆ°Cloud Storage"""
        try:
            blob = bucket.blob(blob_name)

            # ä¸Šä¼ æ–‡ä»¶
            with open(local_path, 'rb') as f:
                blob.upload_from_file(f)

            # è¿”å›gs://æ ¼å¼çš„URI
            gs_uri = f"gs://{bucket.name}/{blob_name}"
            return gs_uri

        except Exception as e:
            logger.error(f"ä¸Šä¼ æ–‡ä»¶åˆ°Cloud Storageå¤±è´¥: {str(e)}")
            return None

    def _execute_batch_analysis(
        self,
        video_uris: List[str],
        features: List[str],
        progress_callback: Optional[callable] = None
    ) -> Dict[str, Any]:
        """æ‰§è¡Œæ‰¹é‡è§†é¢‘åˆ†æ"""
        try:
            from google.cloud import videointelligence_v1 as vi

            # é»˜è®¤åŠŸèƒ½
            if not features:
                features = ["label_detection"]

            # è½¬æ¢åŠŸèƒ½åç§°ä¸ºAPIæšä¸¾
            feature_map = {
                "shot_detection": vi.Feature.SHOT_CHANGE_DETECTION,
                "label_detection": vi.Feature.LABEL_DETECTION,
                "text_detection": vi.Feature.TEXT_DETECTION,
                "face_detection": vi.Feature.FACE_DETECTION,
                "object_tracking": vi.Feature.OBJECT_TRACKING
            }

            api_features = [feature_map[f] for f in features if f in feature_map]

            # Google Cloud Video Intelligence API ä¸æ”¯æŒçœŸæ­£çš„æ‰¹å¤„ç†
            # æˆ‘ä»¬éœ€è¦é€ä¸ªåˆ†æè§†é¢‘ï¼Œä½†å¯ä»¥å¹¶è¡Œå¤„ç†
            if progress_callback:
                progress_callback(50, f"å¼€å§‹åˆ†æ {len(video_uris)} ä¸ªè§†é¢‘...")

            individual_results = []

            for i, video_uri in enumerate(video_uris):
                if progress_callback:
                    progress = 50 + int((i / len(video_uris)) * 40)  # 50-90%
                    progress_callback(progress, f"åˆ†æè§†é¢‘ {i+1}/{len(video_uris)}: {video_uri.split('/')[-1]}")

                # æ„å»ºå•ä¸ªè§†é¢‘çš„è¯·æ±‚
                request = {
                    "input_uri": video_uri,  # å•ä¸ªè§†é¢‘URI
                    "features": api_features,
                }

                try:
                    # åˆ†æå•ä¸ªè§†é¢‘
                    operation = self.client.annotate_video(request=request)

                    # ç­‰å¾…å®Œæˆ
                    result = operation.result(timeout=300)  # 5åˆ†é’Ÿè¶…æ—¶

                    individual_results.append({
                        "video_uri": video_uri,
                        "result": result,
                        "success": True
                    })

                except Exception as e:
                    logger.error(f"åˆ†æè§†é¢‘å¤±è´¥ {video_uri}: {str(e)}")
                    individual_results.append({
                        "video_uri": video_uri,
                        "result": None,
                        "success": False,
                        "error": str(e)
                    })

            return {
                "success": True,
                "individual_results": individual_results,
                "operation_name": f"batch_{len(video_uris)}_videos",
                "video_count": len(video_uris)
            }

        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def _parse_batch_results(self, batch_result, upload_info: List[Dict]) -> List[Dict[str, Any]]:
        """è§£ææ‰¹å¤„ç†ç»“æœä¸ºå•ä¸ªè§†é¢‘çš„ç»“æœ"""
        individual_results = []

        try:
            # æ‰¹å¤„ç†ç»“æœåŒ…å«å¤šä¸ªè§†é¢‘çš„annotation_results
            if not batch_result.annotation_results:
                logger.warning("æ‰¹å¤„ç†ç»“æœä¸­æ²¡æœ‰annotation_results")
                return individual_results

            # æ¯ä¸ªannotation_resultå¯¹åº”ä¸€ä¸ªè¾“å…¥è§†é¢‘
            for i, annotation in enumerate(batch_result.annotation_results):
                if i < len(upload_info):
                    upload_item = upload_info[i]

                    # åˆ›å»ºå•ä¸ªè§†é¢‘çš„åˆ†æç»“æœ
                    video_result = {
                        "file_name": upload_item["file_name"],
                        "local_path": upload_item["local_path"],
                        "gs_uri": upload_item["gs_uri"],
                        "success": True,
                        "labels": [],
                        "shots": [],
                        "faces": [],
                        "texts": []
                    }

                    # æå–æ ‡ç­¾
                    if hasattr(annotation, 'segment_label_annotations') and annotation.segment_label_annotations:
                        for label in annotation.segment_label_annotations:
                            label_name = label.entity.description
                            confidence = 0.0

                            if label.segments:
                                confidence = label.segments[0].confidence

                            video_result["labels"].append({
                                "name": label_name,
                                "confidence": confidence
                            })

                    # æå–é•œå¤´ä¿¡æ¯
                    if hasattr(annotation, 'shot_annotations') and annotation.shot_annotations:
                        for j, shot in enumerate(annotation.shot_annotations):
                            try:
                                start_time = self._get_time_seconds(shot.start_time_offset)
                                end_time = self._get_time_seconds(shot.end_time_offset)

                                video_result["shots"].append({
                                    "index": j + 1,
                                    "start_time": start_time,
                                    "end_time": end_time,
                                    "duration": end_time - start_time
                                })
                            except Exception as e:
                                logger.warning(f"å¤„ç†é•œå¤´ {j+1} æ—¶å‡ºé”™: {e}")

                    # æå–äººè„¸ä¿¡æ¯
                    if hasattr(annotation, 'face_annotations') and annotation.face_annotations:
                        video_result["faces"] = len(annotation.face_annotations)

                    # æå–æ–‡æœ¬ä¿¡æ¯
                    if hasattr(annotation, 'text_annotations') and annotation.text_annotations:
                        for text_annotation in annotation.text_annotations:
                            video_result["texts"].append(text_annotation.text)

                    individual_results.append(video_result)
                else:
                    logger.warning(f"ä¸Šä¼ ä¿¡æ¯ç´¢å¼• {i} è¶…å‡ºèŒƒå›´")

        except Exception as e:
            logger.error(f"è§£ææ‰¹å¤„ç†ç»“æœå¤±è´¥: {str(e)}")

        return individual_results

    def _cleanup_cloud_files(self, bucket, upload_info: List[Dict]):
        """æ¸…ç†äº‘ç«¯ä¸´æ—¶æ–‡ä»¶"""
        try:
            for item in upload_info:
                blob_name = item.get("blob_name")
                if blob_name:
                    try:
                        blob = bucket.blob(blob_name)
                        blob.delete()
                        logger.info(f"å·²åˆ é™¤äº‘ç«¯æ–‡ä»¶: {blob_name}")
                    except Exception as e:
                        logger.warning(f"åˆ é™¤äº‘ç«¯æ–‡ä»¶å¤±è´¥ {blob_name}: {str(e)}")
        except Exception as e:
            logger.error(f"æ¸…ç†äº‘ç«¯æ–‡ä»¶å¤±è´¥: {str(e)}")