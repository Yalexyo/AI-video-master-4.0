"""
åƒé—®2.5è§†è§‰åˆ†æå™¨

ä¸“é—¨å¤„ç†åƒé—®2.5å¤šæ¨¡æ€è§†é¢‘åˆ†æåŠŸèƒ½çš„æ¨¡å—
"""

import os
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path

logger = logging.getLogger(__name__)


class QwenVideoAnalyzer:
    """åƒé—®2.5è§†è§‰åˆ†æå™¨"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–åƒé—®2.5åˆ†æå™¨
        
        Args:
            api_key: DashScope APIå¯†é’¥
        """
        self.api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
        self.analyzer = None
        
        if not self.api_key:
            logger.warning("æœªè®¾ç½®DASHSCOPE_API_KEYï¼Œåƒé—®2.5åˆ†æå™¨ä¸å¯ç”¨")
        else:
            self._initialize_analyzer()
    
    def _initialize_analyzer(self):
        """åˆå§‹åŒ–åƒé—®2.5åˆ†æå™¨"""
        try:
            # ç›´æ¥å†…ç½®åƒé—®åˆ†æåŠŸèƒ½ï¼Œä¸ä¾èµ–å¤–éƒ¨æ¨¡å—
            import dashscope
            dashscope.api_key = self.api_key
            self.analyzer = True  # æ ‡è®°ä¸ºå¯ç”¨
            logger.info("åƒé—®2.5è§†è§‰åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥DashScope: {str(e)}")
            self.analyzer = None
        except Exception as e:
            logger.error(f"åƒé—®2.5åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.analyzer = None
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self.analyzer is not None and self.api_key is not None
    
    def analyze_video_segment(
        self,
        video_path: str,
        tag_language: str = "ä¸­æ–‡",
        frame_rate: float = 2.0
    ) -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªè§†é¢‘ç‰‡æ®µ
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            tag_language: æ ‡ç­¾è¯­è¨€ï¼ˆ"ä¸­æ–‡" æˆ– "è‹±æ–‡"ï¼‰
            frame_rate: å¸§ç‡ï¼ˆæ¯ç§’å‡ å¸§ï¼‰
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        if not self.is_available():
            return {
                "success": False,
                "error": "åƒé—®2.5åˆ†æå™¨ä¸å¯ç”¨",
                "objects": [],
                "scenes": [],
                "people": [],
                "emotions": [],
                "all_tags": []
            }
        
        if not os.path.exists(video_path):
            return {
                "success": False,
                "error": f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}",
                "objects": [],
                "scenes": [],
                "people": [],
                "emotions": [],
                "all_tags": []
            }
        
        try:
            # æ„å»ºåˆ†ææç¤ºè¯
            prompt = self._build_analysis_prompt(tag_language)
            
            # è°ƒç”¨åƒé—®2.5åˆ†æ
            result = self._analyze_video_file(
                video_path,
                frame_rate=frame_rate,
                prompt=prompt
            )
            
            if result and 'analysis' in result:
                # è§£æåˆ†æç»“æœ
                analysis_result = self._parse_analysis_result(
                    result['analysis'], tag_language
                )
                analysis_result["success"] = True
                return analysis_result
            else:
                return {
                    "success": False,
                    "error": "åƒé—®2.5åˆ†æè¿”å›ç©ºç»“æœ",
                    "objects": [],
                    "scenes": [],
                    "people": [],
                    "emotions": [],
                    "all_tags": []
                }
                
        except Exception as e:
            logger.error(f"åƒé—®2.5è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "objects": [],
                "scenes": [],
                "people": [],
                "emotions": [],
                "all_tags": []
            }
    
    def _build_analysis_prompt(self, tag_language: str) -> str:
        """æ„å»ºåˆ†ææç¤ºè¯"""
        if tag_language == "ä¸­æ–‡":
            return """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æåŠ©æ‰‹ï¼Œæ“…é•¿è¯†åˆ«è§†é¢‘ç‰‡æ®µä¸­çš„è§†è§‰å…ƒç´ ã€‚è¯·æ ¹æ®æä¾›çš„è§†é¢‘ç‰‡æ®µï¼Œæå–ä»¥ä¸‹ä¸‰ç±»æ ‡ç­¾ï¼š

1. ğŸ¼ å¯¹è±¡æ£€æµ‹ï¼ˆObjectï¼‰ï¼šè¯†åˆ«ç”»é¢ä¸­å‡ºç°çš„ä¸»è¦ç‰©ä½“æˆ–äººç‰©è§’è‰²
   - äººç‰©ï¼šå©´å„¿ã€å®å®ã€å¦ˆå¦ˆã€çˆ¸çˆ¸ã€å„¿ç«¥ã€æˆäººã€è€äºº
   - å¥¶ç²‰ç›¸å…³ï¼šå¥¶ç“¶ã€å¥¶ç²‰ç½ã€å¥¶å˜´ã€å­¦é¥®æ¯ã€å›´å˜´ã€å¥¶ç²‰å‹ºã€å‚¨å¥¶è¢‹
   - å©´å„¿ç”¨å“ï¼šå©´å„¿åºŠã€å©´å„¿è½¦ã€å°¿å¸ƒã€ç©å…·ã€å®‰å…¨åº§æ¤…ã€å©´å„¿èƒŒå¸¦
   - æ—¥å¸¸ç‰©å“ï¼šæ¡Œå­ã€æ¤…å­ã€æ²™å‘ã€æ‰‹æœºã€æ¯å­ã€ç¢—ã€å‹ºå­ã€é£Ÿç‰©
   - å…¶ä»–é‡è¦ç‰©ä½“

2. ğŸ  åœºæ™¯è¯†åˆ«ï¼ˆSceneï¼‰ï¼šåˆ¤æ–­å½“å‰ç‰‡æ®µçš„æ‹æ‘„åœºæ™¯æˆ–ç¯å¢ƒ
   - å®¤å†…åœºæ™¯ï¼šå®¢å…ã€å¨æˆ¿ã€å§å®¤ã€å©´å„¿æˆ¿ã€æµ´å®¤ã€ä¹¦æˆ¿
   - å®¤å¤–åœºæ™¯ï¼šå…¬å›­ã€èŠ±å›­ã€è¡—é“ã€å•†åœºã€åŒ»é™¢ã€æ¸¸ä¹åœº
   - ç‰¹æ®Šåœºæ™¯ï¼šå·¥ä½œå®¤ã€è¶…å¸‚ã€æ¯å©´åº—ã€è½¦å†…ã€åŠå…¬å®¤
   - ç¯å¢ƒæè¿°ï¼šæ˜äº®çš„ã€æ¸©é¦¨çš„ã€æ•´æ´çš„ã€èˆ’é€‚çš„

3. ğŸ˜Š è¡¨æƒ…/æƒ…ç»ªï¼ˆExpressionï¼‰ï¼šæ£€æµ‹ç”»é¢ä¸­äººç‰©æ˜æ˜¾çš„æƒ…ç»ªå’Œè¡¨æƒ…
   - æ­£é¢æƒ…ç»ªï¼šå¼€å¿ƒã€å¾®ç¬‘ã€å¤§ç¬‘ã€æ»¡è¶³ã€å…´å¥‹ã€æ„‰æ‚¦
   - è´Ÿé¢æƒ…ç»ªï¼šå“­æ³£ã€éš¾è¿‡ã€ç”Ÿæ°”ã€ç„¦è™‘ã€æ‹…å¿ƒã€ç–²å€¦
   - ä¸­æ€§çŠ¶æ€ï¼šä¸“æ³¨ã€å¹³é™ã€è®¤çœŸã€æ€è€ƒã€è§‚å¯Ÿã€è¯´è¯
   - äº’åŠ¨æƒ…ç»ªï¼šäº²å¯†ã€å…³çˆ±ã€é€—å¼„ã€å®‰æŠšã€é™ªä¼´

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¿”å›åˆ†æç»“æœï¼Œæ¯ä¸ªç±»åˆ«ç”¨"|"åˆ†éš”æ ‡ç­¾ï¼Œæ ‡ç­¾è¦ç®€æ´ï¼ˆ2-4ä¸ªå­—ï¼‰ï¼š
ç‰©ä½“ï¼šæ ‡ç­¾1|æ ‡ç­¾2|æ ‡ç­¾3
åœºæ™¯ï¼šæ ‡ç­¾1|æ ‡ç­¾2
æƒ…ç»ªï¼šæ ‡ç­¾1|æ ‡ç­¾2

ç¤ºä¾‹è¾“å‡ºï¼š
ç‰©ä½“ï¼šå¥¶ç“¶|å®å®|å¦ˆå¦ˆ
åœºæ™¯ï¼šå®¢å…|æ¸©é¦¨
æƒ…ç»ªï¼šå¼€å¿ƒ|å¾®ç¬‘

å¦‚æœæŸä¸€ç±»åˆ«æ— æ³•ç¡®å®šï¼Œè¯·è¾“å‡º"æ— "ã€‚è¯·ç¡®ä¿æ ‡ç­¾ç®€æ´æ˜äº†ï¼Œä¾¿äºåç»­å¤„ç†ã€‚"""
        else:
            return """You are a professional video content analysis assistant, skilled at identifying visual elements in video segments. Please analyze the provided video segment and extract the following three types of tags:

1. ğŸ¼ Object Detection: Identify main objects or characters in the frame
   - People: baby, infant, mother, father, child, adult, elderly
   - Formula-related: bottle, formula can, pacifier, sippy cup, bib, formula spoon, milk storage bag
   - Baby items: crib, stroller, diaper, toys, car seat, baby carrier
   - Daily items: table, chair, sofa, phone, cup, bowl, spoon, food
   - Other important objects

2. ğŸ  Scene Recognition: Determine the filming scene or environment
   - Indoor scenes: living room, kitchen, bedroom, nursery, bathroom, study
   - Outdoor scenes: park, garden, street, mall, hospital, playground
   - Special scenes: studio, supermarket, baby store, car interior, office
   - Environment: bright, warm, tidy, comfortable

3. ğŸ˜Š Expression/Emotion: Detect obvious emotions and expressions of people
   - Positive emotions: happy, smiling, laughing, satisfied, excited, joyful
   - Negative emotions: crying, sad, angry, anxious, worried, tired
   - Neutral states: focused, calm, serious, thinking, observing, talking
   - Interactive emotions: intimate, caring, teasing, soothing, accompanying

Please return results in this format, separating tags with "|", keep tags concise (2-4 words):
Objects: tag1|tag2|tag3
Scenes: tag1|tag2
Expressions: tag1|tag2

Example output:
Objects: bottle|baby|mother
Scenes: living room|cozy
Expressions: happy|smiling

If a category cannot be determined, output "none". Ensure tags are concise and clear for processing."""
    
    def _parse_analysis_result(
        self, 
        analysis_text, 
        tag_language: str
    ) -> Dict[str, Any]:
        """è§£æåˆ†æç»“æœ"""
        analysis_result = {
            'objects': [],
            'scenes': [],
            'people': [],
            'emotions': [],
            'all_tags': []
        }
        
        try:
            # ç¡®ä¿analysis_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
            if isinstance(analysis_text, list):
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œå°è¯•è¿æ¥ä¸ºå­—ç¬¦ä¸²
                analysis_text = '\n'.join(str(item) for item in analysis_text)
                logger.warning("åˆ†æç»“æœæ˜¯åˆ—è¡¨ç±»å‹ï¼Œå·²è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
            elif not isinstance(analysis_text, str):
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯åˆ—è¡¨ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                analysis_text = str(analysis_text)
                logger.warning(f"åˆ†æç»“æœç±»å‹å¼‚å¸¸({type(analysis_text)})ï¼Œå·²è½¬æ¢ä¸ºå­—ç¬¦ä¸²")
            
            lines = analysis_text.split('\n')
            for line in lines:
                line = line.strip()
                if ':' in line or 'ï¼š' in line:
                    # æ”¯æŒä¸­è‹±æ–‡å†’å·
                    separator = 'ï¼š' if 'ï¼š' in line else ':'
                    parts = line.split(separator, 1)
                    if len(parts) == 2:
                        category = parts[0].strip().lower()
                        tags_str = parts[1].strip()
                        
                        if tags_str and tags_str != '-' and tags_str != 'none':
                            # ç”¨|åˆ†éš”æ ‡ç­¾
                            tags = [tag.strip() for tag in tags_str.split('|') if tag.strip()]
                            
                            # åˆ†ç±»å­˜å‚¨æ ‡ç­¾
                            if 'object' in category or 'ç‰©ä½“' in category:
                                analysis_result['objects'].extend(tags)
                            elif 'scene' in category or 'åœºæ™¯' in category:
                                analysis_result['scenes'].extend(tags)
                            elif 'people' in category or 'äººç‰©' in category:
                                analysis_result['people'].extend(tags)
                            elif 'emotion' in category or 'æƒ…ç»ª' in category or 'expression' in category or 'è¡¨æƒ…' in category:
                                analysis_result['emotions'].extend(tags)
                            else:
                                # å¦‚æœæ— æ³•å½’ç±»ï¼Œæ ¹æ®å†…å®¹æ¨æµ‹åˆ†ç±»
                                for tag in tags:
                                    if any(keyword in tag for keyword in ['å®å®', 'å©´å„¿', 'å¦ˆå¦ˆ', 'çˆ¸çˆ¸', 'å„¿ç«¥', 'æˆäºº', 'è€äºº', 'ç”·æ€§', 'å¥³æ€§']):
                                        analysis_result['people'].append(tag)
                                    elif any(keyword in tag for keyword in ['å¼€å¿ƒ', 'å¾®ç¬‘', 'å“­æ³£', 'éš¾è¿‡', 'ç”Ÿæ°”', 'æƒŠè®¶', 'å¹³é™', 'ä¸“æ³¨']):
                                        analysis_result['emotions'].append(tag)
                                    elif any(keyword in tag for keyword in ['å®¢å…', 'å¨æˆ¿', 'å§å®¤', 'å…¬å›­', 'å®¤å†…', 'å®¤å¤–']):
                                        analysis_result['scenes'].append(tag)
                                    else:
                                        analysis_result['objects'].append(tag)
            
            # åˆå¹¶æ‰€æœ‰æ ‡ç­¾
            all_tags = (analysis_result['objects'] + 
                      analysis_result['scenes'] + 
                      analysis_result['people'] + 
                      analysis_result['emotions'])
            analysis_result['all_tags'] = list(set(all_tags))  # å»é‡
            
        except Exception as e:
            logger.error(f"è§£æåƒé—®2.5åˆ†æç»“æœå¤±è´¥: {str(e)}")
            
        return analysis_result
    
    def batch_analyze_videos(
        self,
        video_paths: List[str],
        tag_language: str = "ä¸­æ–‡",
        frame_rate: float = 2.0,
        progress_callback: Optional[callable] = None
    ) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡åˆ†æè§†é¢‘
        
        Args:
            video_paths: è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            tag_language: æ ‡ç­¾è¯­è¨€
            frame_rate: å¸§ç‡
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°ï¼Œæ¥å—(current, total, message)å‚æ•°
            
        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        results = []
        total_videos = len(video_paths)
        
        logger.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {total_videos} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        for i, video_path in enumerate(video_paths):
            try:
                # æ›´æ–°è¿›åº¦
                if progress_callback:
                    progress_callback(i + 1, total_videos, f"æ­£åœ¨åˆ†æè§†é¢‘ {i+1}/{total_videos}: {os.path.basename(video_path)}")
                
                # åˆ†æå•ä¸ªè§†é¢‘
                result = self.analyze_video_segment(
                    video_path, tag_language, frame_rate
                )
                
                # æ·»åŠ è§†é¢‘è·¯å¾„ä¿¡æ¯åˆ°ç»“æœä¸­
                result["video_path"] = video_path
                result["video_name"] = os.path.basename(video_path)
                
                results.append(result)
                
                # è®°å½•æˆåŠŸ/å¤±è´¥çŠ¶æ€
                if result.get("success"):
                    logger.info(f"è§†é¢‘ {i+1}/{total_videos} åˆ†ææˆåŠŸ: {os.path.basename(video_path)}")
                else:
                    logger.warning(f"è§†é¢‘ {i+1}/{total_videos} åˆ†æå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
            except Exception as e:
                error_msg = f"è§†é¢‘ {i+1}/{total_videos} åˆ†æå¼‚å¸¸: {str(e)}"
                logger.error(error_msg)
                
                # åˆ›å»ºé”™è¯¯ç»“æœ
                error_result = {
                    "success": False,
                    "error": str(e),
                    "objects": [],
                    "scenes": [],
                    "people": [],
                    "emotions": [],
                    "all_tags": [],
                    "video_path": video_path,
                    "video_name": os.path.basename(video_path)
                }
                results.append(error_result)
        
        # æœ€ç»ˆè¿›åº¦æ›´æ–°
        if progress_callback:
            successful_count = sum(1 for r in results if r.get("success"))
            progress_callback(total_videos, total_videos, 
                            f"æ‰¹é‡åˆ†æå®Œæˆï¼æˆåŠŸ: {successful_count}/{total_videos}")
        
        logger.info(f"æ‰¹é‡åˆ†æå®Œæˆï¼ŒæˆåŠŸåˆ†æ {sum(1 for r in results if r.get('success'))}/{total_videos} ä¸ªè§†é¢‘")
        return results
    
    def get_top_tags_by_category(
        self, 
        analysis_results: List[Dict[str, Any]],
        top_n: int = 5
    ) -> Dict[str, List[tuple]]:
        """
        è·å–å„ç±»åˆ«çš„é«˜é¢‘æ ‡ç­¾
        
        Args:
            analysis_results: åˆ†æç»“æœåˆ—è¡¨
            top_n: è¿”å›å‰Nä¸ªé«˜é¢‘æ ‡ç­¾
            
        Returns:
            å„ç±»åˆ«çš„é«˜é¢‘æ ‡ç­¾å­—å…¸
        """
        from collections import Counter
        
        all_objects = []
        all_scenes = []
        all_people = []
        all_emotions = []
        
        for result in analysis_results:
            if result.get("success"):
                all_objects.extend(result.get('objects', []))
                all_scenes.extend(result.get('scenes', []))
                all_people.extend(result.get('people', []))
                all_emotions.extend(result.get('emotions', []))
        
        return {
            'objects': Counter(all_objects).most_common(top_n),
            'scenes': Counter(all_scenes).most_common(top_n),
            'people': Counter(all_people).most_common(top_n),
            'emotions': Counter(all_emotions).most_common(top_n)
        }
    
    def _analyze_video_file(
        self,
        video_path: str,
        frame_rate: float = 2.0,
        prompt: str = ""
    ) -> Dict[str, Any]:
        """
        å†…ç½®çš„è§†é¢‘æ–‡ä»¶åˆ†ææ–¹æ³•
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_rate: å¸§ç‡
            prompt: åˆ†ææç¤ºè¯
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            import cv2
            import base64
            import tempfile
            import os
            from dashscope import MultiModalConversation
            
            # æå–å…³é”®å¸§
            frames = self._extract_frames(video_path, frame_rate)
            if not frames:
                return {"error": "æ— æ³•æå–è§†é¢‘å¸§"}
            
            # ç¼–ç å¸§ä¸ºbase64
            encoded_frames = []
            for frame in frames:
                # å°†å¸§ä¿å­˜ä¸ºä¸´æ—¶å›¾åƒæ–‡ä»¶
                with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as tmp:
                    cv2.imwrite(tmp.name, frame)
                    
                    # è¯»å–å¹¶ç¼–ç ä¸ºbase64
                    with open(tmp.name, 'rb') as f:
                        img_data = f.read()
                        encoded = base64.b64encode(img_data).decode()
                        encoded_frames.append(f"data:image/jpeg;base64,{encoded}")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(tmp.name)
            
            # æ„å»ºæ¶ˆæ¯
            content = [{"text": prompt}]
            
            # æ·»åŠ å›¾åƒï¼ˆé™åˆ¶æ•°é‡ä»¥é¿å…tokenè¶…é™ï¼‰
            max_frames = min(len(encoded_frames), 10)  # æœ€å¤š10å¸§
            for i in range(0, max_frames):
                content.append({"image": encoded_frames[i]})
            
            messages = [{"role": "user", "content": content}]
            
            # è°ƒç”¨åƒé—®2.5è§†è§‰åˆ†æ
            try:
                response = MultiModalConversation.call(
                    model='qwen-vl-plus',
                    messages=messages
                )
                
                if response.status_code == 200:
                    # å®‰å…¨åœ°æå–åˆ†æå†…å®¹
                    try:
                        content = response.output.choices[0].message.content
                        return {
                            "analysis": content,
                            "frames_analyzed": max_frames
                        }
                    except (AttributeError, IndexError, TypeError) as e:
                        logger.error(f"APIå“åº”ç»“æ„å¼‚å¸¸: {e}")
                        return {"error": f"APIå“åº”æ ¼å¼é”™è¯¯: {e}"}
                else:
                    return {"error": f"APIè°ƒç”¨å¤±è´¥: çŠ¶æ€ç  {response.status_code}"}
                    
            except Exception as api_error:
                # å¤„ç†ç½‘ç»œè¿æ¥ã€ä»£ç†ç­‰é”™è¯¯
                error_msg = str(api_error)
                if "ProxyError" in error_msg or "Max retries exceeded" in error_msg:
                    return {"error": f"ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®å’Œä»£ç†é…ç½®: {error_msg}"}
                elif "HTTPSConnectionPool" in error_msg:
                    return {"error": f"HTTPSè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥: {error_msg}"}
                else:
                    return {"error": f"APIè°ƒç”¨å¼‚å¸¸: {error_msg}"}
                
        except ImportError as e:
            logger.error(f"ç¼ºå°‘å¿…è¦çš„ä¾èµ–åº“: {e}")
            return {"error": f"ç¼ºå°‘ä¾èµ–åº“: {e}"}
        except Exception as e:
            logger.error(f"è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return {"error": str(e)}
    
    def _extract_frames(self, video_path: str, frame_rate: float) -> List:
        """
        ä»è§†é¢‘ä¸­æå–å…³é”®å¸§
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            frame_rate: å¸§ç‡ï¼ˆæ¯ç§’å‡ å¸§ï¼‰
            
        Returns:
            å¸§åˆ—è¡¨
        """
        try:
            import cv2
            
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                logger.error(f"æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
                return []
            
            # è·å–è§†é¢‘ä¿¡æ¯
            fps = cap.get(cv2.CAP_PROP_FPS)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            
            if fps <= 0:
                logger.error("æ— æ³•è·å–è§†é¢‘å¸§ç‡")
                cap.release()
                return []
            
            # è®¡ç®—é‡‡æ ·é—´éš”
            interval = max(1, int(fps / frame_rate))
            
            frames = []
            frame_count = 0
            
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æŒ‰é—´éš”é‡‡æ ·å¸§
                if frame_count % interval == 0:
                    frames.append(frame)
                
                frame_count += 1
                
                # é™åˆ¶æœ€å¤§å¸§æ•°
                if len(frames) >= 20:  # æœ€å¤š20å¸§
                    break
            
            cap.release()
            logger.info(f"ä»è§†é¢‘ {video_path} æå–äº† {len(frames)} å¸§")
            return frames
            
        except Exception as e:
            logger.error(f"æå–è§†é¢‘å¸§å¤±è´¥: {str(e)}")
            return [] 