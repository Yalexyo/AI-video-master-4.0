"""
åƒé—®2.5è§†è§‰åˆ†æå™¨

ä¸“é—¨å¤„ç†åƒé—®2.5å¤šæ¨¡æ€è§†é¢‘åˆ†æåŠŸèƒ½çš„æ¨¡å—ï¼ŒåŒ…å«è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶
åº”ç”¨äº†qwen_optimization_guide.mdä¸­çš„å…¨éƒ¨ä¼˜åŒ–ç­–ç•¥
"""

import os
import logging
from typing import Dict, Any, List, Optional
from pathlib import Path
from collections import Counter
from http import HTTPStatus
import re
import json

# å¯¼å…¥éŸ³é¢‘åˆ†æå™¨
from .dashscope_audio_analyzer import DashScopeAudioAnalyzer
from .deepseek_analyzer import DeepSeekAnalyzer

from utils.config_manager import get_config_manager

logger = logging.getLogger(__name__)


class QwenVideoAnalyzer:
    """åƒé—®2.5è§†è§‰åˆ†æå™¨ï¼ˆåŒ…å«è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶ + å…¨é¢ä¼˜åŒ–ç­–ç•¥ï¼‰"""
    
    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–åƒé—®2.5åˆ†æå™¨
        
        Args:
            api_key: DashScope APIå¯†é’¥
        """
        self.api_key = api_key or os.environ.get("DASHSCOPE_API_KEY")
        self.analyzer = None
        
        # åˆå§‹åŒ–éŸ³é¢‘åˆ†æå™¨ - è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶
        self.audio_analyzer = DashScopeAudioAnalyzer(api_key=self.api_key)
        
        # åˆå§‹åŒ–DeepSeekåˆ†æå™¨ - æ–‡æœ¬åˆ†æ
        self.deepseek_analyzer = DeepSeekAnalyzer()
        
        if not self.api_key:
            logger.warning("æœªè®¾ç½®DASHSCOPE_API_KEYï¼Œåƒé—®2.5åˆ†æå™¨ä¸å¯ç”¨")
        else:
            self._initialize_analyzer()
    
    def _initialize_analyzer(self):
        """åˆå§‹åŒ–åƒé—®2.5åˆ†æå™¨"""
        try:
            import dashscope
            dashscope.api_key = self.api_key
            self.analyzer = True
            logger.info("åƒé—®2.5è§†è§‰åˆ†æå™¨åˆå§‹åŒ–æˆåŠŸ")
        except ImportError as e:
            logger.error(f"æ— æ³•å¯¼å…¥DashScope: {str(e)}")
            self.analyzer = None
        except Exception as e:
            logger.error(f"åƒé—®2.5åˆ†æå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.analyzer = None
            
        # ğŸ”§ ä¼˜åŒ–çš„æ¨¡å‹å‚æ•°é…ç½®
        self.model_config = {
            'model': 'qwen-vl-max-latest',   # ä½¿ç”¨æœ€æ–°æœ€å¼ºæ¨¡å‹
            'temperature': 0.1,              # é™ä½éšæœºæ€§
            'top_p': 0.8,                   # æ§åˆ¶ç”Ÿæˆè´¨é‡
            'max_tokens': 1500,             # å¢åŠ è¾“å‡ºé•¿åº¦
            'seed': 1234                    # ç¡®ä¿å¯é‡å¤æ€§
        }
        
        # ğŸ”§ è´¨é‡æ§åˆ¶å‚æ•°
        self.quality_config = {
            'min_quality_threshold': 0.6,   # è´¨é‡åˆ†é˜ˆå€¼
            'max_retry_count': 1,            # æœ€å¤§é‡è¯•æ¬¡æ•° (ä»2æ”¹ä¸º0ä»¥æé«˜é€Ÿåº¦)
            'confidence_threshold': 0.6      # ç½®ä¿¡åº¦é˜ˆå€¼
        }
        
        # ğŸ¯ NEW: çŸ­è§†é¢‘ä¼˜åŒ–é…ç½®
        self.short_video_config = {
            'file_size_threshold_mb': 1.0,    # å°äº1MBè§†ä¸ºçŸ­è§†é¢‘
            'duration_threshold_sec': 5.0,    # å°äº5ç§’è§†ä¸ºçŸ­è§†é¢‘
            'quality_threshold_reduction': 0.15, # çŸ­è§†é¢‘è´¨é‡é˜ˆå€¼é™ä½0.15
            'frame_rate_boost': 2.0,           # çŸ­è§†é¢‘å¸§ç‡æå‡å€æ•°
            'max_frame_rate': 8.0,             # çŸ­è§†é¢‘æœ€å¤§å¸§ç‡é™åˆ¶
            'min_file_size_mb': 0.5            # å°äºæ­¤å¤§å°çš„æ–‡ä»¶å°†è¢«è¿‡æ»¤
        }
        
        logger.info(f"åƒé—®2.5åˆ†æå™¨åˆå§‹åŒ–å®Œæˆï¼Œæ¨¡å‹: {self.model_config['model']}")
    
    def is_available(self) -> bool:
        """æ£€æŸ¥åˆ†æå™¨æ˜¯å¦å¯ç”¨"""
        return self.analyzer is not None and self.api_key is not None
    
    def analyze_video_segment(
        self,
        video_path: str,
        tag_language: str = "ä¸­æ–‡",
        frame_rate: float = 2.0
    ) -> Dict[str, Any]:
        """
        è§†é¢‘ç‰‡æ®µåˆ†æï¼ˆåŒ…å«è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶ + å…¨é¢ä¼˜åŒ–ç­–ç•¥ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            tag_language: æ ‡ç­¾è¯­è¨€
            frame_rate: å¸§ç‡
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logger.info(f"ğŸ¯ å¼€å§‹åˆ†æè§†é¢‘: {video_path}")

        if not self.is_available():
            return self._get_default_result("åƒé—®2.5åˆ†æå™¨ä¸å¯ç”¨")
        
        if not os.path.exists(video_path):
            return self._get_default_result(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
        
        # ğŸ¯ NEW: çŸ­è§†é¢‘æ™ºèƒ½ä¼˜åŒ–
        optimized_params = self._optimize_for_short_video(video_path, frame_rate)
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡å¤„ç†
        if optimized_params.get("should_skip", False):
            return self._get_default_result(f"æ–‡ä»¶è¿‡å°ï¼Œå·²è·³è¿‡: {optimized_params.get('reason', 'æœªçŸ¥')}")
        
        optimized_frame_rate = optimized_params['frame_rate']
        optimized_quality_threshold = optimized_params['quality_threshold']
        
        try:
            # ğŸ¯ ç¬¬ä¸€æ­¥ï¼šå°è¯•è§†è§‰åˆ†æï¼ˆå¸¦é‡è¯•æœºåˆ¶ï¼‰
            logger.info("ğŸ¯ å¼€å§‹è§†è§‰åˆ†æ...")
            visual_result = self._analyze_with_retry(video_path, optimized_frame_rate, tag_language, optimized_quality_threshold)
            
            if visual_result and visual_result.get('success'):
                # ğŸ” æ£€æŸ¥æ˜¯å¦éœ€è¦å¯ç”¨è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶
                if self._needs_audio_fallback(visual_result):
                    logger.warning("ğŸ¤ è§†è§‰åˆ†æå­˜åœ¨æœªè¯†åˆ«å†…å®¹ï¼Œå¯ç”¨DeepSeekéŸ³é¢‘è½¬å½•å…œåº•åˆ†æ...")
                    
                    # ğŸ¯ ä½¿ç”¨é’ˆå¯¹æ€§åˆ†æè€Œä¸æ˜¯å®Œæ•´é‡æ–°åˆ†æ
                    enhanced_result = self._targeted_audio_fallback_analysis(video_path, visual_result, tag_language)
                    
                    if enhanced_result.get("success"):
                        logger.info("ğŸ¯ é’ˆå¯¹æ€§DeepSeekè¯­éŸ³å…œåº•åˆ†æå®Œæˆ")
                        return enhanced_result
                    else:
                        logger.warning("ğŸ¯ é’ˆå¯¹æ€§åˆ†æå¤±è´¥ï¼Œè¿”å›åŸå§‹visualç»“æœ")
                        return visual_result
                
                return visual_result
            else:
                # ğŸ¤ è§†è§‰åˆ†æå¤±è´¥ï¼Œç›´æ¥å¯ç”¨è¯­éŸ³è½¬å½•ä¿åº•
                logger.warning("ğŸ¤ Qwenè§†è§‰åˆ†æå¤±è´¥ï¼Œå¯ç”¨DeepSeekéŸ³é¢‘è½¬å½•å…œåº•åˆ†æ...")
                return self._audio_fallback_analysis(video_path, tag_language)
                
        except Exception as e:
            logger.error(f"è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            # ğŸ¤ å¼‚å¸¸æƒ…å†µä¸‹å°è¯•è¯­éŸ³è½¬å½•ä¿åº•
            try:
                return self._audio_fallback_analysis(video_path, tag_language)
            except Exception as fallback_error:
                logger.error(f"è¯­éŸ³è½¬å½•ä¿åº•ä¹Ÿå¤±è´¥: {str(fallback_error)}")
                return self._get_default_result(f"åˆ†æå¤±è´¥: {str(e)}")
    
    def _analyze_with_retry(self, video_path: str, frame_rate: float, tag_language: str, quality_threshold: float) -> Dict[str, Any]:
        """
        ğŸ”§ å¸¦é‡è¯•æœºåˆ¶çš„è§†è§‰åˆ†æï¼ˆæ–°å¢åŒæ¨¡å‹åˆ†å·¥æœºåˆ¶ï¼‰
        """
        max_retry = self.quality_config['max_retry_count']
        
        for attempt in range(max_retry + 1):
            try:
                # ğŸ¯ ç¬¬ä¸€é˜¶æ®µï¼šé€šç”¨ç‰©ä½“è¯†åˆ«ï¼ˆAI-Bï¼‰
                general_prompt = self._build_general_detection_prompt(tag_language)
                general_result = self._analyze_video_file(video_path, frame_rate, general_prompt)
                
                if general_result and 'analysis' in general_result:
                    # è§£æé€šç”¨è¯†åˆ«ç»“æœ
                    general_analysis = self._parse_analysis_result(
                        general_result['analysis'], tag_language
                    )
                    
                    # ğŸ•µï¸â€â™‚ï¸ [ä¾¦æŸ¥æ—¥å¿—] æ‰“å°é€šç”¨è¯†åˆ«ç»“æœ
                    logger.info("ğŸ•µï¸â€â™‚ï¸ [ä¾¦æŸ¥æ—¥å¿—] ====== é€šç”¨è¯†åˆ«é˜¶æ®µ (AI-B) ======")
                    logger.info(f"   - åŸå§‹è¿”å›: {general_result['analysis']}")
                    logger.info(f"   - è§£æå: {general_analysis}")
                    logger.info("ğŸ•µï¸â€â™‚ï¸ =======================================")
                    
                    # ğŸ¯ ç¬¬äºŒé˜¶æ®µï¼šå“ç‰Œæ£€æµ‹è§¦å‘å™¨
                    if self._should_trigger_brand_detection(general_analysis):
                        logger.info("ğŸ” æ£€æµ‹åˆ°äº§å“ç›¸å…³ç‰©ä½“ï¼Œå¯åŠ¨æ ¸å¿ƒå“ç‰Œæ£€æµ‹...")
                        brand_result = self._detect_core_brands(video_path, frame_rate)
                        if brand_result:
                            general_analysis['brand_elements'] = brand_result
                        logger.info(f"ğŸ¯ å“ç‰Œæ£€æµ‹å®Œæˆï¼Œç»“æœ: {brand_result or 'æœªæ£€æµ‹åˆ°æ ¸å¿ƒå“ç‰Œ'}")
                    else:
                        # éäº§å“ç›¸å…³åœºæ™¯ï¼Œç¡®ä¿brand_elementsä¸ºç©º
                        general_analysis['brand_elements'] = ""
                    
                    # åº”ç”¨è´Ÿé¢å…³é”®è¯è¿‡æ»¤
                    general_analysis = self._apply_negative_keywords_filter(general_analysis)
                    
                    general_analysis["success"] = True
                    general_analysis["quality_score"] = general_result.get('quality_score', 0.8)
                    general_analysis["analysis_method"] = "dual_model_workflow"
                    general_analysis["retry_count"] = attempt
                    
                    # æ£€æµ‹äººè„¸ç‰¹å†™
                    face_close_up_detected = self._detect_face_close_up(general_analysis, video_path)
                    if face_close_up_detected:
                        logger.warning(f"ğŸš« æ£€æµ‹åˆ°äººè„¸ç‰¹å†™ç‰‡æ®µï¼Œæ ‡è®°ä¸ºä¸å¯ç”¨: {video_path}")
                        general_analysis["is_face_close_up"] = True
                        general_analysis["unusable"] = True
                        general_analysis["unusable_reason"] = "äººè„¸ç‰¹å†™ç‰‡æ®µ"
                        # é™ä½è´¨é‡åˆ†ï¼Œç¡®ä¿åœ¨åŒ¹é…æ—¶è¢«è¿‡æ»¤
                        general_analysis["quality_score"] = 0.1
                    else:
                        general_analysis["is_face_close_up"] = False
                        general_analysis["unusable"] = False
                    
                    # æ£€æŸ¥è´¨é‡
                    if general_analysis["quality_score"] >= quality_threshold:
                        logger.info(f"âœ… åˆ†ææˆåŠŸï¼Œè´¨é‡åˆ†: {general_analysis['quality_score']:.2f}")
                        return general_analysis
                    elif attempt < max_retry:
                        logger.warning(f"âš ï¸ è´¨é‡åˆ†è¿‡ä½ ({general_analysis['quality_score']:.2f})ï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                    else:
                        # æœ€åä¸€æ¬¡é‡è¯•ï¼Œè¿›è¡Œåå¤„ç†ä¼˜åŒ–
                        general_analysis = self._enhance_poor_result(general_analysis, video_path)
                        logger.info(f"ğŸ”§ åº”ç”¨åå¤„ç†ä¼˜åŒ–ï¼Œæœ€ç»ˆè´¨é‡åˆ†: {general_analysis['quality_score']:.2f}")
                        return general_analysis
                else:
                    if attempt < max_retry:
                        logger.warning(f"âš ï¸ åˆ†æè¿”å›ç©ºç»“æœï¼Œå‡†å¤‡é‡è¯•...")
                        continue
                    else:
                        return self._get_default_result("é‡è¯•åä»æ— æ³•è·å–åˆ†æç»“æœ")
                        
            except Exception as e:
                if attempt < max_retry:
                    logger.warning(f"âš ï¸ åˆ†æå¼‚å¸¸: {str(e)}ï¼Œå‡†å¤‡é‡è¯•...")
                    continue
                else:
                    logger.error(f"âŒ é‡è¯•{max_retry}æ¬¡åä»å¤±è´¥: {str(e)}")
                    return self._get_default_result(f"é‡è¯•å¤±è´¥: {str(e)}")
        
        return self._get_default_result("é‡è¯•æœºåˆ¶å¼‚å¸¸")
    
    def _build_professional_prompt(self, tag_language: str) -> str:
        """
        ğŸ”§ æ„å»ºQwenè§†è§‰åˆ†æä¸“ç”¨æç¤ºè¯ï¼ˆå¼ºè°ƒè§†é¢‘å¸§è§†è§‰å…ƒç´ è¯†åˆ«ï¼‰
        """
        try:
            from utils.keyword_config import get_qwen_visual_prompt
            prompt = get_qwen_visual_prompt()
            return prompt if prompt else self._get_fallback_visual_prompt()
        except Exception as e:
            logger.warning(f"æ— æ³•å¯¼å…¥Qwenè§†è§‰promptç”Ÿæˆé€»è¾‘ï¼Œä½¿ç”¨å…œåº•é…ç½®: {e}")
            return self._get_fallback_visual_prompt()

    def _build_enhanced_retry_prompt(self, tag_language: str) -> str:
        """
        ğŸ”§ æ„å»ºQwenè§†è§‰åˆ†æé‡è¯•æç¤ºè¯ï¼ˆåŒæ ·ä¸“æ³¨äºè§†è§‰è¯†åˆ«ï¼‰
        """
        try:
            from utils.keyword_config import get_qwen_visual_prompt
            prompt = get_qwen_visual_prompt()
            return prompt if prompt else self._get_fallback_retry_prompt()
        except Exception as e:
            logger.warning(f"æ— æ³•å¯¼å…¥Qwenè§†è§‰promptç”Ÿæˆé€»è¾‘ï¼Œä½¿ç”¨å…œåº•é…ç½®: {e}")
            return self._get_fallback_retry_prompt()
    
    def _get_fallback_visual_prompt(self) -> str:
        """
        è·å–ä¸€ä¸ªåŸºäºé…ç½®çš„ã€å¥å£®çš„å¯è§†åŒ–åˆ†æå…œåº•Promptã€‚
        ä¸å†ç¡¬ç¼–ç å…³é”®è¯ï¼Œè€Œæ˜¯ä»ç»Ÿä¸€é…ç½®ä¸­å¿ƒåŠ¨æ€ç”Ÿæˆã€‚
        """
        try:
            config_manager = get_config_manager()
            vocab = config_manager.get_ai_vocabulary()
            
            objects = list(vocab.get("object", []))
            scenes = list(vocab.get("scene", []))
            emotions = list(vocab.get("emotion", []))
            brands = list(vocab.get("brand", []))

            # ä¸ºç©ºæ—¶æä¾›é»˜è®¤å€¼ï¼Œé¿å…Promptæ ¼å¼é”™è¯¯
            if not objects: objects = ["å¥¶ç²‰ç½", "å®å®"]
            if not scenes: scenes = ["å®¤å†…", "æˆ·å¤–"]
            if not emotions: emotions = ["å¼€å¿ƒ", "æ¸©é¦¨"]
            if not brands: brands = ["å¯èµ‹", "A2"]

            prompt = f"""
è¯·ä½ ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ¯å©´è¡Œä¸šè§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œä¸¥æ ¼ã€è¯¦ç»†ã€å®¢è§‚åœ°åˆ†æç»™ä½ çš„è§†é¢‘å¸§ã€‚

**åˆ†æç»´åº¦**:
1.  **`object` (ç‰©ä½“è¯†åˆ«)**: è¯†åˆ«è§†é¢‘ä¸­ä¸æ¯å©´ã€å–‚å…»ã€ç”Ÿæ´»ç›¸å…³çš„ç‰©ä½“ã€‚
    -   å‚è€ƒè¯æ±‡: {str(objects)}
2.  **`scene` (åœºæ™¯è¯†åˆ«)**: æè¿°è§†é¢‘å‘ç”Ÿçš„åœºæ™¯ã€‚
    -   å‚è€ƒè¯æ±‡: {str(scenes)}
3.  **`emotion` (æƒ…ç»ªè¯†åˆ«)**: åˆ†æè§†é¢‘ä¼ è¾¾çš„æ ¸å¿ƒæƒ…ç»ªæ°›å›´ã€‚
    -   å‚è€ƒè¯æ±‡: {str(emotions)}
4.  **`brand_elements` (å“ç‰Œå…ƒç´ )**: **å¦‚æœèƒ½æ˜ç¡®è¯†åˆ«**å‡ºä»¥ä¸‹å“ç‰Œç›¸å…³çš„logoã€åŒ…è£…æˆ–æ–‡å­—ï¼Œè¯·åˆ—å‡ºã€‚å¦åˆ™ç•™ç©ºã€‚
    -   æ ¸å¿ƒå“ç‰Œåˆ—è¡¨: {str(brands)}

**è¾“å‡ºè¦æ±‚**:
-   å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜æˆ–markdownæ ‡è®°ã€‚
-   æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å­˜åœ¨ï¼Œå³ä½¿æ²¡æœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œä¹Ÿè¦è¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸² `""`ã€‚
-   è¯†åˆ«çš„å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚

```json
{{
  "object": "è¯†åˆ«å‡ºçš„ç‰©ä½“ï¼Œç”¨é€—å·åˆ†éš”",
  "scene": "è¯†åˆ«å‡ºçš„åœºæ™¯ï¼Œç”¨é€—å·åˆ†éš”",
  "emotion": "è¯†åˆ«å‡ºçš„æƒ…ç»ªï¼Œç”¨é€—å·åˆ†éš”",
  "brand_elements": "æ˜ç¡®è¯†åˆ«å‡ºçš„å“ç‰Œï¼Œç”¨é€—å·åˆ†éš”"
}}
```
"""
            logger.info("æˆåŠŸä»ConfigManageråŠ¨æ€ç”ŸæˆQwenè§†è§‰Promptã€‚")
            return prompt

        except Exception as e:
            logger.error(f"ä»ConfigManagerç”ŸæˆQwen Promptå¤±è´¥: {e}ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„æ—§ç‰ˆPromptã€‚")
            # åœ¨æ­¤ä¿ç•™ä¸€ä¸ªç¡¬ç¼–ç çš„ã€åŠŸèƒ½æ€§çš„å…œåº•Prompt
            return """
è¯·ä½ ä½œä¸ºä¸€ä½ä¸“ä¸šçš„æ¯å©´è¡Œä¸šè§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œä¸¥æ ¼ã€è¯¦ç»†ã€å®¢è§‚åœ°åˆ†æç»™ä½ çš„è§†é¢‘å¸§ã€‚

**åˆ†æç»´åº¦**:
1.  **`object` (ç‰©ä½“è¯†åˆ«)**: è¯†åˆ«è§†é¢‘ä¸­ä¸æ¯å©´ã€å–‚å…»ã€ç”Ÿæ´»ç›¸å…³çš„ç‰©ä½“ã€‚
    -   å‚è€ƒè¯æ±‡: ['å¥¶ç²‰ç½', 'å¥¶ç“¶', 'å®å®', 'å¦ˆå¦ˆ', 'æˆåˆ†è¡¨', 'åŒ…è£…']
2.  **`scene` (åœºæ™¯è¯†åˆ«)**: æè¿°è§†é¢‘å‘ç”Ÿçš„åœºæ™¯ã€‚
    -   å‚è€ƒè¯æ±‡: ['å¨æˆ¿', 'å®¢å…', 'åŒ»é™¢', 'æˆ·å¤–', 'è¯„æµ‹']
3.  **`emotion` (æƒ…ç»ªè¯†åˆ«)**: åˆ†æè§†é¢‘ä¼ è¾¾çš„æ ¸å¿ƒæƒ…ç»ªæ°›å›´ã€‚
    -   å‚è€ƒè¯æ±‡: ['å¼€å¿ƒ', 'æ¸©é¦¨', 'ç„¦è™‘', 'ä¸“ä¸š']
4.  **`brand_elements` (å“ç‰Œå…ƒç´ )**: **å¦‚æœèƒ½æ˜ç¡®è¯†åˆ«**å‡ºä»¥ä¸‹å“ç‰Œç›¸å…³çš„logoã€åŒ…è£…æˆ–æ–‡å­—ï¼Œè¯·åˆ—å‡ºã€‚å¦åˆ™ç•™ç©ºã€‚
    -   æ ¸å¿ƒå“ç‰Œåˆ—è¡¨: ['å¯èµ‹', 'illuma', 'æƒ æ°', 'A2', 'HMO']

**è¾“å‡ºè¦æ±‚**:
-   å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–è¯´æ˜æˆ–markdownæ ‡è®°ã€‚
-   æ‰€æœ‰å­—æ®µéƒ½å¿…é¡»å­˜åœ¨ï¼Œå³ä½¿æ²¡æœ‰è¯†åˆ«åˆ°å†…å®¹ï¼Œä¹Ÿè¦è¿”å›ä¸€ä¸ªç©ºå­—ç¬¦ä¸² `""`ã€‚
-   è¯†åˆ«çš„å†…å®¹è¯·ç”¨ä¸­æ–‡è¾“å‡ºã€‚

```json
{{
  "object": "è¯†åˆ«å‡ºçš„ç‰©ä½“ï¼Œç”¨é€—å·åˆ†éš”",
  "scene": "è¯†åˆ«å‡ºçš„åœºæ™¯ï¼Œç”¨é€—å·åˆ†éš”",
  "emotion": "è¯†åˆ«å‡ºçš„æƒ…ç»ªï¼Œç”¨é€—å·åˆ†éš”",
  "brand_elements": "æ˜ç¡®è¯†åˆ«å‡ºçš„å“ç‰Œï¼Œç”¨é€—å·åˆ†éš”"
}}
```
"""
    
    def _get_fallback_retry_prompt(self) -> str:
        """è·å–é‡è¯•è§†è§‰åˆ†æçš„å…œåº•Promptï¼Œé£æ ¼æ›´æ¿€è¿›ï¼ˆä½¿ç”¨åŠ¨æ€é…ç½®ï¼‰"""
        try:
            # åŠ¨æ€åŠ è½½æ ¸å¿ƒå“ç‰Œåˆ—è¡¨
            core_brands_text = "æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼š['illuma', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³', 'Wyeth', 'A2', 'ATWO', 'HMO']"
            try:
                from utils.keyword_config import get_brands
                brands = get_brands()
                if brands:
                    core_brands_text = f"æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼š{brands}"
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨: {e}")

            # å…³é”®ä¼˜åŒ–ï¼šåœ¨é‡è¯•Promptä¸­åŒæ ·æ˜ç¡®å“ç‰ŒèŒƒå›´
            return f"""
# **èº«ä»½**
ä½ æ˜¯ä¸€ä½é¡¶çº§çš„è§†è§‰åˆ†æä¸“å®¶ï¼Œæ‹¥æœ‰ç«çœ¼é‡‘ç›ï¼Œèƒ½å¤Ÿä»è§†é¢‘å¸§ä¸­ç²¾å‡†è¯†åˆ«è¥é”€è¦ç´ ã€‚

# **ä»»åŠ¡**
åˆ†æç»™å®šçš„è§†é¢‘å¸§ï¼Œ**åª**ä»æä¾›çš„"å…³é”®è¯è¯åº“"ä¸­é€‰æ‹©æœ€ç›¸å…³çš„è¯æ±‡æ¥æè¿°å†…å®¹ã€‚

# **æ ¸å¿ƒæŒ‡ä»¤**
1.  **å…³é”®è¯åŒ¹é…**: ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯åœ¨å›¾åƒä¸­å¯»æ‰¾ä¸"å…³é”®è¯è¯åº“"åŒ¹é…çš„å…ƒç´ ã€‚
2.  **å“ç‰Œè¯†åˆ«é“å¾‹**: `brand_elements`å­—æ®µ**åªèƒ½**ä»ä¸‹æ–¹"æ ¸å¿ƒå“ç‰Œåˆ—è¡¨"ä¸­é€‰æ‹©ã€‚å¦‚æœç”»é¢ä¸­æ²¡æœ‰æ˜ç¡®å‡ºç°è¿™äº›æ ¸å¿ƒå“ç‰Œï¼Œè¯¥å­—æ®µå¿…é¡»ä¸º"æ— "ã€‚**ç»å¯¹ç¦æ­¢**è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œã€‚
3.  **å“ç‰Œè¯†åˆ«é‡ç‚¹**: é‡ç‚¹å¯»æ‰¾åŒ…è£…ä¸Šçš„å“ç‰Œlogoã€äº§å“åç§°ã€å“ç‰Œæ ‡è¯†æ–‡å­—ï¼Œç‰¹åˆ«å…³æ³¨å¥¶ç²‰ç½ã€åŒ…è£…ç›’ä¸Šçš„å“ç‰Œä¿¡æ¯ã€‚
4.  **å…³é”®ç‰©ä½“**: å¯¹ "å¥¶ç²‰ç½"ã€"å¥¶ç“¶" è¿™ç±»å…³é”®ç‰©ä½“è¦è¿›è¡Œæœ€ä¼˜å…ˆè¯†åˆ«ã€‚
5.  **æ‹’ç»æ¨¡ç³Š**: ä¸è¦ä½¿ç”¨"ç–‘ä¼¼"ã€"å¯èƒ½"ç­‰ä»»ä½•ä¸ç¡®å®šçš„æè¿°ã€‚å¦‚æœæ— æ³•ç¡®å®šï¼Œè¯·å°†è¯¥å­—æ®µç•™ç©ºæˆ–æ ‡è®°ä¸º"æ— "ã€‚
6.  **ç»“æ„åŒ–**: ä¸¥æ ¼æŒ‰ç…§ä¸‹é¢çš„"è¾“å‡ºæ ¼å¼"è¿”å›ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•å¤šä½™çš„è§£é‡Šã€‚

# **å…³é”®è¯è¯åº“**
- **æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼ˆä»…é™è¯†åˆ«ä»¥ä¸‹å“ç‰Œï¼‰**: {brand_vocab}
âš ï¸ **å“ç‰Œè¯†åˆ«é“å¾‹**: brand_elementså­—æ®µåªèƒ½ä»ä¸Šè¿°æ ¸å¿ƒå“ç‰Œåˆ—è¡¨é€‰æ‹©ï¼Œä¸å¾—è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œï¼
- **ç‰©ä½“è¯åº“**: {product_vocab}
- **åœºæ™¯è¯åº“**: {scene_vocab}
- **æƒ…ç»ªè¯åº“**: {emotion_vocab}

# **è¾“å‡ºæ ¼å¼** (ä¸¥æ ¼éµå®ˆï¼Œä½¿ç”¨'{tag_language}'è¯­è¨€)
object: [ä»"ç‰©ä½“è¯åº“"ä¸­é€‰æ‹©çš„è¯ï¼Œç”¨é€—å·åˆ†éš”]
scene: [ä»"åœºæ™¯è¯åº“"ä¸­é€‰æ‹©çš„è¯ï¼Œç”¨é€—å·åˆ†éš”]
emotion: [ä»"æƒ…ç»ªè¯åº“"ä¸­é€‰æ‹©çš„è¯ï¼Œç”¨é€—å·åˆ†éš”]  
brand_elements: [ä»"å“ç‰Œè¯åº“"ä¸­é€‰æ‹©çš„è¯ï¼Œç”¨é€—å·åˆ†éš”]
confidence: [0.0-1.0]

# **ç¤ºä¾‹**
- **è¾“å…¥**: ä¸€å¼ åŒ…å«å¯èµ‹å¥¶ç²‰ç½å’Œå¾®ç¬‘å®å®çš„å›¾ç‰‡
- **è¾“å‡º**:
object: å¥¶ç²‰ç½,å®å®
scene: äº§å“ç‰¹å†™,æ¸©é¦¨
emotion: å¼€å¿ƒ,å¹¸ç¦
brand_elements: å¯èµ‹
confidence: 0.9

# **å¼€å§‹åˆ†æ**
"""
        except Exception as e:
            logger.error(f"æ„å»ºé‡è¯•è§†è§‰Promptå¤±è´¥: {e}")
            return "è¯·ä¸¥æ ¼é‡æ–°åˆ†æç”»é¢ï¼Œå¹¶æŒ‰Object, Sence, Emotion, Brand_Elements, Confidenceçš„æ ¼å¼è¾“å‡ºã€‚"
    
    def _get_fallback_audio_prompt(self) -> str:
        """
        è·å–ä¸€ä¸ªåŸºäºé…ç½®çš„ã€å¥å£®çš„éŸ³é¢‘è½¬å½•åˆ†æå…œåº•Promptã€‚
        åŠ¨æ€ä»ç»Ÿä¸€é…ç½®ä¸­å¿ƒç”Ÿæˆã€‚
        """
        try:
            config_manager = get_config_manager()
            vocab = config_manager.get_ai_vocabulary()
            
            objects = list(vocab.get("object", []))
            scenes = list(vocab.get("scene", []))
            emotions = list(vocab.get("emotion", []))
            brands = list(vocab.get("brand", []))

            # ä¸ºç©ºæ—¶æä¾›é»˜è®¤å€¼
            if not objects: objects = ["å¥¶ç²‰ç½", "å®å®"]
            if not scenes: scenes = ["å®¤å†…", "æˆ·å¤–"]
            if not emotions: emotions = ["å¼€å¿ƒ", "æ¸©é¦¨"]
            if not brands: brands = ["å¯èµ‹", "A2"]

            prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å½•éŸ³æ–‡æœ¬ï¼Œæå–å†…å®¹æ ‡ç­¾ã€‚

**åˆ†æç»´åº¦**:
1.  **`object` (æåŠç‰©ä½“)**: æ–‡æœ¬ä¸­æåˆ°çš„å…·ä½“äº‹ç‰©ã€‚
    -   å‚è€ƒè¯æ±‡: {str(objects)}
2.  **`scene` (æåŠåœºæ™¯)**: æ–‡æœ¬ä¸­æè¿°çš„åœºæ™¯ã€‚
    -   å‚è€ƒè¯æ±‡: {str(scenes)}
3.  **`emotion` (è¡¨è¾¾æƒ…ç»ª)**: æ–‡æœ¬ä¸­ä¼ è¾¾çš„æƒ…æ„Ÿã€‚
    -   å‚è€ƒè¯æ±‡: {str(emotions)}
4.  **`brand_elements` (æåŠå“ç‰Œ)**: æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„å“ç‰Œåç§°ã€‚
    -   æ ¸å¿ƒå“ç‰Œåˆ—è¡¨: {str(brands)}

**å“ç‰Œè¯†åˆ«é“å¾‹**:
âš ï¸ **ä¸¥æ ¼é™åˆ¶**: brand_elementså­—æ®µåªèƒ½ä»ä¸Šè¿°æ ¸å¿ƒå“ç‰Œåˆ—è¡¨é€‰æ‹©ï¼Œä¸å¾—è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œï¼
ğŸ¯ **è¯†åˆ«é‡ç‚¹**: é‡ç‚¹è¯†åˆ«è¯­éŸ³ä¸­ç›´æ¥è¯´å‡ºçš„å“ç‰Œåç§°ï¼Œæ³¨æ„å“ç‰Œçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚

**è¾“å‡ºè¦æ±‚**:
-   ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰é¢å¤–è¯´æ˜ã€‚
-   æ‰€æœ‰å­—æ®µå¿…é¡»å­˜åœ¨ï¼Œæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚

```json
{{
  "object": "æåŠçš„ç‰©ä½“ï¼Œç”¨é€—å·åˆ†éš”",
  "scene": "æåŠçš„åœºæ™¯ï¼Œç”¨é€—å·åˆ†éš”",
  "emotion": "è¡¨è¾¾çš„æƒ…ç»ªï¼Œç”¨é€—å·åˆ†éš”",
  "brand_elements": "æ˜ç¡®æåŠçš„å“ç‰Œï¼Œç”¨é€—å·åˆ†éš”"
}}
```
"""
            logger.info("æˆåŠŸä»ConfigManageråŠ¨æ€ç”ŸæˆDeepSeekéŸ³é¢‘Promptã€‚")
            return prompt

        except Exception as e:
            logger.error(f"ä»ConfigManagerç”ŸæˆDeepSeek Promptå¤±è´¥: {e}ï¼Œä½¿ç”¨ç¡¬ç¼–ç çš„æ—§ç‰ˆPromptã€‚")
            return """
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å½•éŸ³æ–‡æœ¬ï¼Œæå–å†…å®¹æ ‡ç­¾ã€‚

**åˆ†æç»´åº¦**:
1.  **`object` (æåŠç‰©ä½“)**: æ–‡æœ¬ä¸­æåˆ°çš„å…·ä½“äº‹ç‰©ã€‚
    -   å‚è€ƒè¯æ±‡: ['å¥¶ç²‰', 'å¥¶ç“¶', 'å®å®', 'å¦ˆå¦ˆ']
2.  **`scene` (æåŠåœºæ™¯)**: æ–‡æœ¬ä¸­æè¿°çš„åœºæ™¯ã€‚
    -   å‚è€ƒè¯æ±‡: ['å–‚å…»', 'ç¡è§‰', 'ç©è€']
3.  **`emotion` (è¡¨è¾¾æƒ…ç»ª)**: æ–‡æœ¬ä¸­ä¼ è¾¾çš„æƒ…æ„Ÿã€‚
    -   å‚è€ƒè¯æ±‡: ['å¼€å¿ƒ', 'å“­é—¹', 'å¥åº·']
4.  **`brand_elements` (æåŠå“ç‰Œ)**: æ–‡æœ¬ä¸­æ˜ç¡®æåˆ°çš„å“ç‰Œåç§°ã€‚
    -   æ ¸å¿ƒå“ç‰Œåˆ—è¡¨: ['å¯èµ‹', 'A2', 'illuma']

**å“ç‰Œè¯†åˆ«é“å¾‹**:
âš ï¸ **ä¸¥æ ¼é™åˆ¶**: brand_elementså­—æ®µåªèƒ½ä»ä¸Šè¿°æ ¸å¿ƒå“ç‰Œåˆ—è¡¨é€‰æ‹©ï¼Œä¸å¾—è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œï¼
ğŸ¯ **è¯†åˆ«é‡ç‚¹**: é‡ç‚¹è¯†åˆ«è¯­éŸ³ä¸­ç›´æ¥è¯´å‡ºçš„å“ç‰Œåç§°ï¼Œæ³¨æ„å“ç‰Œçš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§ã€‚

**è¾“å‡ºè¦æ±‚**:
-   ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œä¸è¦æœ‰é¢å¤–è¯´æ˜ã€‚
-   æ‰€æœ‰å­—æ®µå¿…é¡»å­˜åœ¨ï¼Œæ²¡æœ‰åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ã€‚

```json
{{
  "object": "æåŠçš„ç‰©ä½“ï¼Œç”¨é€—å·åˆ†éš”",
  "scene": "æåŠçš„åœºæ™¯ï¼Œç”¨é€—å·åˆ†éš”",
  "emotion": "è¡¨è¾¾çš„æƒ…ç»ªï¼Œç”¨é€—å·åˆ†éš”",
  "brand_elements": "æ˜ç¡®æåŠçš„å“ç‰Œï¼Œç”¨é€—å·åˆ†éš”"
}}
```
"""
    
    def _get_default_result(self, error_msg: str) -> Dict[str, Any]:
        """è·å–é»˜è®¤é”™è¯¯ç»“æœ"""
        return {
            "success": False,
            "error": error_msg,
            "object": "",
            "scene": "",
            "emotion": "",
            "brand_elements": "",
            "confidence": 0.0,
            "all_tags": []
        }
        
    def _analyze_video_file(self, video_path: str, frame_rate: float, prompt: str) -> Dict[str, Any]:
        """åˆ†æè§†é¢‘æ–‡ä»¶"""
        try:
            import cv2
            import dashscope
            
            # æå–å¸§
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return None
            
            # è·å–è§†é¢‘æ—¶é•¿
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps if fps > 0 else 0
            
            # ğŸ”§ æä¿å®ˆçš„å¸§é‡‡æ ·ç­–ç•¥
            frames = self._ultra_conservative_frame_sampling(cap, duration)
            cap.release()
            
            if not frames:
                return None
            
            # è°ƒç”¨åƒé—®API
            messages = [
                {
                    'role': 'user',
                    'content': [
                        {'text': prompt},
                        *[{'image': frame_data} for frame_data in frames]
                    ]
                }
            ]
            
            response = dashscope.MultiModalConversation.call(
                model=self.model_config['model'],
                messages=messages,
                temperature=self.model_config['temperature'],
                top_p=self.model_config['top_p'],
                max_tokens=self.model_config['max_tokens']
            )
            
            if response.status_code == HTTPStatus.OK:
                # ğŸ”§ ä¿®å¤ï¼šå¤„ç†contentå¯èƒ½æ˜¯listçš„æƒ…å†µ
                content = response.output.choices[0].message.content
                if isinstance(content, list):
                    # å¦‚æœcontentæ˜¯åˆ—è¡¨ï¼Œæå–textéƒ¨åˆ†
                    result_text = ""
                    for item in content:
                        if isinstance(item, dict) and 'text' in item:
                            result_text += item['text']
                        elif isinstance(item, str):
                            result_text += item
                else:
                    result_text = str(content) if content else ""
                
                logger.info(f"ğŸ” åƒé—®APIè¿”å›å†…å®¹: {result_text[:200]}...")
                quality_score = self._assess_result_quality(result_text)
                return {'analysis': result_text, 'quality_score': quality_score}
            else:
                logger.error(f"åƒé—®APIè°ƒç”¨å¤±è´¥: {response.message}")
                return None
                
        except Exception as e:
            logger.error(f"è§†é¢‘æ–‡ä»¶åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def _ultra_conservative_frame_sampling(self, cap, duration: float) -> List[str]:
        """
        ğŸ”§ æä¿å®ˆçš„å¸§é‡‡æ ·ç­–ç•¥ - ç¬¦åˆAPIæœ€ä¸¥æ ¼è¦æ±‚
        """
        import cv2
        import base64
        from io import BytesIO
        from PIL import Image
        
        frames = []
        
        # ğŸ”§ æä¿å®ˆç­–ç•¥ - åªé‡‡æ ·1å¸§ï¼Œé¿å…å†…å®¹é•¿åº¦è¶…é™
        cap.set(cv2.CAP_PROP_POS_MSEC, duration * 0.5 * 1000)
        ret, frame = cap.read()
        
        if ret:
            try:
                # è½¬æ¢ä¸ºPILå›¾åƒ
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                pil_image = Image.fromarray(frame_rgb)
                
                # ğŸ”§ æåº¦å‹ç¼©å›¾åƒ
                processed_image = self._ultra_compress_image(pil_image)
                
                # è½¬æ¢ä¸ºbase64
                buffered = BytesIO()
                processed_image.save(buffered, format='JPEG', quality=60)
                img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')
                frames.append(f"data:image/jpeg;base64,{img_base64}")
                
                logger.info(f"ğŸ”§ æä¿å®ˆå¸§é‡‡æ ·å®Œæˆï¼Œå›¾åƒå°ºå¯¸: {processed_image.size}")
                
            except Exception as e:
                logger.warning(f"å¤„ç†å¸§æ—¶å‡ºé”™: {str(e)}")
        
        return frames
    
    def _ultra_compress_image(self, pil_image):
        """
        ğŸ”§ æåº¦å‹ç¼©å›¾åƒ - ç¬¦åˆAPIæœ€ä¸¥æ ¼è¦æ±‚
        """
        from PIL import Image
        
        # ğŸ”§ æä¿å®ˆçš„å°ºå¯¸ç­–ç•¥ - 224x224 (8x28 = 224)
        target_width = 224   # 28çš„å€æ•°
        target_height = 224  # 28çš„å€æ•°
        
        # å¼ºåˆ¶è°ƒæ•´åˆ°ç›®æ ‡å°ºå¯¸
        compressed_image = pil_image.resize((target_width, target_height), Image.Resampling.LANCZOS)
        return compressed_image
    
    def _assess_result_quality(self, result_text: str) -> float:
        """
        ğŸ”§ ä¼˜åŒ–çš„ç»“æœè´¨é‡è¯„ä¼°
        """
        if not result_text or len(result_text.strip()) < 10:
            return 0.0
        
        quality_score = 0.5  # åŸºç¡€åˆ†
        
        # å¿…è¦å­—æ®µå®Œæ•´æ€§ (30%)
        required_fields = ['object:', 'scene:', 'emotion:', 'brand_elements:', 'confidence:']
        field_count = sum(1 for field in required_fields if field in result_text)
        quality_score += (field_count / len(required_fields)) * 0.3
        
        # é¿å…"æ— "å›ç­” (15%)
        if 'æ— ' not in result_text or result_text.count('æ— ') <= 1:
            quality_score += 0.15
        
        # å†…å®¹ä¸°å¯Œåº¦ (5%)
        if len(result_text) > 100:
            quality_score += 0.05
        
        return min(quality_score, 1.0)
    
    def _enhance_poor_result(self, result: Dict[str, Any], video_path: str) -> Dict[str, Any]:
        """
        ğŸ”§ æ™ºèƒ½åå¤„ç†ä¼˜åŒ– - å¢å¼ºä½è´¨é‡ç»“æœ
        """
        logger.info("ğŸ”§ å¼€å§‹åå¤„ç†ä¼˜åŒ–...")
        
        enhanced_result = result.copy()
        
        # ğŸš¨ ä¸¥æ ¼éµå¾ªæ–°ç­–ç•¥ï¼šä¸å†å¡«å……ä»»ä½•"ç–‘ä¼¼..."å ä½ç¬¦
        # æ‰€æœ‰æ— æ•ˆå†…å®¹ä¸€å¾‹ä¿æŒä¸ºç©ºï¼Œè®©AIæ¨¡å‹å’Œç”¨æˆ·æ˜ç¡®çŸ¥é“è¿™äº›å†…å®¹æœªè¢«è¯†åˆ«
        
        # æ¸…ç†æ— æ•ˆå ä½ç¬¦
        invalid_values = ['æ— ', 'ç”»é¢ä¸æ¸…æ™°', 'ä¸ç¡®å®š', '']
        
        for field in ['object', 'scene', 'emotion']:
            if enhanced_result.get(field) in invalid_values:
                enhanced_result[field] = ''  # ä¿æŒä¸ºç©ºï¼Œä¸å¡«å……å ä½ç¬¦
        
        # ğŸš¨ å“ç‰Œå­—æ®µä¸¥æ ¼è¿‡æ»¤ï¼šç»ä¸å¡«å……ä»»ä½•å†…å®¹ï¼Œä¿æŒä¸ºç©º
        if enhanced_result.get('brand_elements') in invalid_values:
            enhanced_result['brand_elements'] = ''  # ä¿æŒä¸ºç©ºï¼Œä¸¥æ ¼éµå®ˆå“ç‰Œè¿‡æ»¤è§„åˆ™
        
        # é‡å»ºall_tagsï¼ˆä¸åŒ…å«æ— æ•ˆå ä½ç¬¦ï¼‰
        enhanced_result['all_tags'] = self._rebuild_tags(enhanced_result)
        
        # è½»å¾®æå‡è´¨é‡åˆ†ï¼Œä½†ä¸è¿‡åº¦ä¼˜åŒ–
        enhanced_result['quality_score'] = min(enhanced_result.get('quality_score', 0.0) + 0.05, 0.6)
        
        logger.info(f"ğŸ”§ åå¤„ç†ä¼˜åŒ–å®Œæˆï¼Œè´¨é‡åˆ†: {enhanced_result['quality_score']:.2f}")
        return enhanced_result
    
    def _extract_video_info(self, video_path: str) -> Dict[str, Any]:
        """æå–è§†é¢‘åŸºæœ¬ä¿¡æ¯"""
        try:
            import cv2
            cap = cv2.VideoCapture(video_path)
            if cap.isOpened():
                fps = cap.get(cv2.CAP_PROP_FPS)
                frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                duration = frame_count / fps if fps > 0 else 0
                cap.release()
                return {'duration': duration, 'fps': fps, 'frame_count': frame_count}
        except:
            pass
        return {'duration': 0, 'fps': 0, 'frame_count': 0}
    
    def _rebuild_tags(self, result: Dict[str, Any]) -> List[str]:
        """é‡å»ºall_tagså­—æ®µï¼Œä¸¥æ ¼è¿‡æ»¤æ— æ•ˆå’Œå ä½ç¬¦æ ‡ç­¾"""
        all_tags = []
        
        # å®šä¹‰æ— æ•ˆæ ‡ç­¾åˆ—è¡¨
        invalid_tags = [
            'æ— ', 'ç”»é¢ä¸æ¸…æ™°', 'ä¸ç¡®å®š', '',
            'ç–‘ä¼¼å®¤å†…ç¯å¢ƒ', 'ç–‘ä¼¼æ¸©é¦¨æ°›å›´', 'ç–‘ä¼¼äº§å“å±•ç¤º', 'ç–‘ä¼¼äººç‰©æ´»åŠ¨',
            'ç–‘ä¼¼å“ç‰Œè¦ç´ ', 'ç–‘ä¼¼'
        ]
        
        for field in ['object', 'scene', 'emotion', 'brand_elements']:
            value = result.get(field, '')
            if value and value not in invalid_tags:
                tags = [tag.strip() for tag in value.split(',') if tag.strip()]
                all_tags.extend(tags)
        
        # å»é‡å¹¶ä¸¥æ ¼è¿‡æ»¤
        unique_tags = []
        for tag in all_tags:
            # ç§»é™¤ä»»ä½•"ç–‘ä¼¼"å‰ç¼€
            tag_clean = tag.replace('ç–‘ä¼¼', '').strip()
            
            # è·³è¿‡æ— æ•ˆæ ‡ç­¾
            if (tag_clean and 
                tag_clean not in invalid_tags and 
                tag_clean not in unique_tags and
                len(tag_clean) > 1):  # è‡³å°‘2ä¸ªå­—ç¬¦çš„æœ‰æ•ˆæ ‡ç­¾
                unique_tags.append(tag_clean)
        
        return unique_tags
    
    def _parse_analysis_result(self, analysis_text, tag_language: str) -> Dict[str, Any]:
        """
        è§£æAIæ¨¡å‹è¿”å›çš„æ–‡æœ¬ç»“æœï¼Œå¹¶è¿›è¡Œä¸¥æ ¼çš„åå¤„ç†è¿‡æ»¤ã€‚
        """
        # ğŸ”§ é‡ç”¨çš„æ ¼å¼æ¸…ç†å‡½æ•°
        def clean_field_value(value: str) -> str:
            """æ¸…ç†å­—æ®µå€¼ï¼Œç¡®ä¿è¾“å‡ºç®€æ´çš„å•è¯çŸ­è¯­"""
            if not value:
                return ''
            
            # åŸºç¡€æ¸…ç†
            cleaned = value.strip()
            
            # ğŸ”§ é‡è¦ä¿®å¤ï¼šç§»é™¤å­—æ®µæ ‡è¯†ç¬¦å¹²æ‰°
            field_markers = ['object:', 'scene:', 'emotion:', 'brand_elements:', 'confidence:']
            for marker in field_markers:
                if marker in cleaned:
                    # å¦‚æœåœ¨å¼€å¤´ï¼Œç§»é™¤å®ƒ
                    if cleaned.startswith(marker):
                        cleaned = cleaned[len(marker):].strip()
                    else:
                        # å¦‚æœåœ¨ä¸­é—´ï¼Œåªå–å‰é¢éƒ¨åˆ†
                        cleaned = cleaned.split(marker)[0].strip()
            
            # å»é™¤Markdownå’Œç‰¹æ®Šç¬¦å·
            cleaned = cleaned.replace('**', '').replace('*', '')
            cleaned = cleaned.replace('- ', '').replace('+ ', '')
            cleaned = cleaned.replace('# ', '').replace('[', '').replace(']', '')
            cleaned = cleaned.replace('(', '').replace(')', '')
            cleaned = cleaned.replace('"', '').replace("'", '')
            cleaned = cleaned.replace('ï¼š', ':').replace('ã€‚', '').replace('ï¼›', '')
            
            # å»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            cleaned = re.sub(r'[,ï¼Œ]+', ',', cleaned)
            cleaned = cleaned.strip(',')
            
            # è¿‡æ»¤æ— æ„ä¹‰å†…å®¹
            meaningless = ['æ— ', 'ä¸ç¡®å®š', 'ç”»é¢ä¸æ¸…æ™°', 'è§£æå¤±è´¥', 
                          '', 'none', 'n/a', 'ä¸æ˜ç¡®', 'ç›¸å…³']
            if cleaned.lower() in meaningless:
                return ''
            
            # ğŸ”§ æ–°å¢ï¼šè¿‡æ»¤çº¯æ•°å­—å†…å®¹ï¼ˆconfidenceå€¼è¯¯å…¥å…¶ä»–å­—æ®µï¼‰
            if re.match(r'^[0-9.]+$', cleaned):
                return ''
            
            # ğŸ”§ å¼ºåŒ–ï¼šè¿‡æ»¤åŒ…å«çº¯æ•°å­—çš„ç‰‡æ®µï¼ˆå¦‚"0.5"è¯¯å…¥å“ç‰Œå­—æ®µï¼‰
            if re.match(r'^[0-9]+\.?[0-9]*$', cleaned):
                return ''
            
            # ğŸ”§ æ–°å¢ï¼šè¿‡æ»¤è¿‡çŸ­çš„æ— æ„ä¹‰å†…å®¹ï¼ˆ1-2å­—ç¬¦ï¼‰
            if len(cleaned) <= 2 and cleaned.lower() in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.']:
                return ''
            
            return cleaned
        
        try:
            result = {
                'interaction': '', # æ–°å¢
                'object': '',      # ä¿ç•™
                'scene': '', 
                'emotion': '',
                'brand_elements': '',
                'confidence': 0.8
            }
            
            logger.info(f"ğŸ¯ å¼€å§‹è§£æç®€åŒ–åˆ†ææ–‡æœ¬:")
            logger.info(f"åŸå§‹æ–‡æœ¬: {analysis_text}")
            
            # ğŸ”§ æ”¯æŒä¸¤ç§æ ¼å¼ï¼šæ ‡å‡†å­—æ®µæ ¼å¼ å’Œ ç®€å•æ–‡æœ¬æ ¼å¼
            lines = analysis_text.strip().split('\n')
            has_field_markers = any(':' in line for line in lines)
            
            if has_field_markers:
                # æ ¼å¼1ï¼šæ ‡å‡†å­—æ®µæ ¼å¼ï¼ˆobject: xxxï¼‰
                for line in lines:
                    line = line.strip()
                    if not line:
                        continue
                        
                    logger.debug(f"å¤„ç†è¡Œ: '{line}'")
                    
                    # ğŸ”§ ä¿®å¤ï¼šå¤„ç†ç«–çº¿åˆ†éš”ç¬¦æ ¼å¼å’Œè¡Œå†…æ ¼å¼
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”çš„å•è¡Œæ ¼å¼ï¼šobject: ... | scene: ... | emotion: ... | brand: ...
                    if '|' in line and any(marker in line.lower() for marker in ['object:', 'scene:', 'emotion:', 'brand']):
                        # å¤„ç†ç«–çº¿åˆ†éš”æ ¼å¼
                        segments = line.split('|')
                        for segment in segments:
                            segment = segment.strip()
                            if segment.lower().startswith('object:'):
                                raw_value = segment[7:].strip()
                                result['object'] = clean_field_value(raw_value)
                                logger.debug(f"[ç«–çº¿æ ¼å¼] æå–object: '{raw_value}' -> '{result['object']}'")
                            elif segment.lower().startswith('scene:'):
                                raw_value = segment[6:].strip()
                                result['scene'] = clean_field_value(raw_value)
                                logger.debug(f"[ç«–çº¿æ ¼å¼] æå–scene: '{raw_value}' -> '{result['scene']}'")
                            elif segment.lower().startswith('emotion:'):
                                raw_value = segment[8:].strip()
                                result['emotion'] = clean_field_value(raw_value)
                                logger.debug(f"[ç«–çº¿æ ¼å¼] æå–emotion: '{raw_value}' -> '{result['emotion']}'")
                            elif segment.lower().startswith('brand:') or segment.lower().startswith('brand_elements:'):
                                if segment.lower().startswith('brand:'):
                                    raw_value = segment[6:].strip()
                                else:
                                    raw_value = segment[15:].strip()
                                cleaned_brand = clean_field_value(raw_value)
                                if cleaned_brand:
                                    brand_parts = [part.strip() for part in cleaned_brand.split(',')]
                                    clean_parts = [part for part in brand_parts if part and not re.match(r'^[0-9]+\.?[0-9]*$', part)]
                                    result['brand_elements'] = ','.join(clean_parts) if clean_parts else ''
                                else:
                                    result['brand_elements'] = ''
                                logger.debug(f"[ç«–çº¿æ ¼å¼] æå–brand: '{raw_value}' -> '{result['brand_elements']}'")
                    
                    # æ ‡å‡†å•è¡Œæ ¼å¼å¤„ç†
                    elif line.lower().startswith('object:'):
                        raw_value = line[7:].strip()
                        # ç§»é™¤å¯èƒ½çš„ç«–çº¿åç¼€
                        if '|' in raw_value:
                            raw_value = raw_value.split('|')[0].strip()
                        result['object'] = clean_field_value(raw_value)
                        logger.debug(f"æå–object: '{raw_value}' -> '{result['object']}'")
                        
                    elif line.lower().startswith('scene:'):
                        raw_value = line[6:].strip()
                        if '|' in raw_value:
                            raw_value = raw_value.split('|')[0].strip()
                        result['scene'] = clean_field_value(raw_value)
                        logger.debug(f"æå–scene: '{raw_value}' -> '{result['scene']}'")
                        
                    elif line.lower().startswith('emotion:'):
                        raw_value = line[8:].strip()
                        if '|' in raw_value:
                            raw_value = raw_value.split('|')[0].strip()
                        result['emotion'] = clean_field_value(raw_value)
                        logger.debug(f"æå–emotion: '{raw_value}' -> '{result['emotion']}'")
                        
                    elif line.lower().startswith('brand_elements:') or line.lower().startswith('brand:'):
                        if line.lower().startswith('brand:'):
                            raw_value = line[6:].strip()
                        else:
                            raw_value = line[15:].strip()
                        # ç§»é™¤å¯èƒ½çš„ç«–çº¿åç¼€
                        if '|' in raw_value:
                            raw_value = raw_value.split('|')[0].strip()
                        # ğŸ”§ ç‰¹æ®Šå¤„ç†brand_elementsï¼šè¿‡æ»¤æ•°å­—æ±¡æŸ“
                        cleaned_brand = clean_field_value(raw_value)
                        if cleaned_brand:
                            # è¿›ä¸€æ­¥æ¸…ç†ï¼šç§»é™¤çº¯æ•°å­—ç‰‡æ®µ
                            brand_parts = [part.strip() for part in cleaned_brand.split(',')]
                            clean_parts = [part for part in brand_parts if part and not re.match(r'^[0-9]+\.?[0-9]*$', part)]
                            result['brand_elements'] = ','.join(clean_parts) if clean_parts else ''
                        else:
                            result['brand_elements'] = ''
                        logger.debug(f"æå–brand_elements: '{raw_value}' -> '{result['brand_elements']}'")
                        
                    elif line.lower().startswith('confidence:'):
                        confidence_text = line[11:].strip()
                        if '|' in confidence_text:
                            confidence_text = confidence_text.split('|')[0].strip()
                        try:
                            confidence_match = re.search(r'([0-9.]+)', confidence_text)
                            if confidence_match:
                                result['confidence'] = float(confidence_match.group(1))
                                logger.debug(f"æå–confidence: '{confidence_text}' -> {result['confidence']}")
                        except:
                            result['confidence'] = 0.8
                    
                    elif line.lower().startswith('interaction:'):
                        raw_value = line[12:].strip()
                        result['interaction'] = clean_field_value(raw_value)
                        logger.debug(f"æå–interaction: '{raw_value}' -> '{result['interaction']}'")
            
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œå°†interactionå†…å®¹åŒæ­¥åˆ°object
            if result.get('interaction'):
                result['object'] = result['interaction']
            
            # ğŸ”§ åˆ›å»ºall_tags - åŒ…å«æ‰€æœ‰æœ‰æ„ä¹‰çš„å†…å®¹ï¼ˆå¼ºåŒ–æ•°å­—è¿‡æ»¤ï¼‰
            all_tags = []
            for field_name, value in result.items():
                if field_name == 'confidence':
                    continue
                # å…¼å®¹æ€§ï¼šä¸å°†interactioné‡å¤æ·»åŠ åˆ°all_tags
                if field_name == 'interaction':
                    continue
                if value:  # åªè¦ä¸ä¸ºç©ºå°±å¤„ç†
                    # åˆ†å‰²é€—å·åˆ†éš”çš„æ ‡ç­¾
                    tags = [tag.strip() for tag in value.split(',') if tag.strip()]
                    for tag in tags:
                        cleaned_tag = clean_field_value(tag)
                        # ğŸ”§ å¼ºåŒ–æ•°å­—è¿‡æ»¤ï¼šå†æ¬¡æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ•°å­—
                        if cleaned_tag and not re.match(r'^[0-9]+\.?[0-9]*$', cleaned_tag):
                            all_tags.append(cleaned_tag)
            
            # å»é‡å¹¶è¿‡æ»¤
            result['all_tags'] = list(set(filter(None, all_tags)))
            
            # ğŸš¨ æœ€åä¸€æ­¥ï¼šä¸¥æ ¼è¿‡æ»¤å“ç‰Œå…ƒç´ ï¼Œåªä¿ç•™é…ç½®ä¸­çš„å“ç‰Œ
            try:
                from utils.keyword_config import get_brands
                allowed_brands = [b.lower() for b in get_brands()]
            except Exception as e:
                logger.error(f"æ— æ³•åŠ è½½å“ç‰Œé…ç½®ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨: {e}")
                allowed_brands = ['illuma', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³', 'wyeth', 'a2', 'atwo', 'hmo']
            
            if result['brand_elements']:
                detected_brands_raw = result['brand_elements']
                detected_brands_list = [b.strip() for b in detected_brands_raw.split(',') if b.strip()]
                
                final_brands = []
                for brand in detected_brands_list:
                    # å¿…é¡»æ˜¯é…ç½®åˆ—è¡¨ä¸­çš„å“ç‰Œï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
                    if brand.lower() in allowed_brands:
                        final_brands.append(brand)
                    else:
                        logger.debug(f"ğŸš« [å“ç‰Œè¿‡æ»¤] å·²ç§»é™¤ä¸åœ¨é…ç½®ä¸­çš„å“ç‰Œ: '{brand}'")
                
                # å»é‡å¹¶æ›´æ–°
                if final_brands:
                    result['brand_elements'] = ','.join(list(dict.fromkeys(final_brands)))
                else:
                    result['brand_elements'] = ''
            
            logger.info(f"ğŸ¯ ç®€åŒ–è§£ææœ€ç»ˆç»“æœ:")
            logger.info(f"   äº¤äº’è¡Œä¸º: '{result.get('interaction', '')}'") # æ–°å¢æ—¥å¿—
            logger.info(f"   ç‰©ä½“: '{result['object']}'")
            logger.info(f"   åœºæ™¯: '{result['scene']}'")
            logger.info(f"   æƒ…ç»ª: '{result['emotion']}'")
            logger.info(f"   å“ç‰Œ: '{result['brand_elements']}'")
            logger.info(f"   ç½®ä¿¡åº¦: {result['confidence']}")
            logger.info(f"   å…¨éƒ¨æ ‡ç­¾: {result['all_tags']}")
            
            return result
            
        except Exception as e:
            logger.error(f"è§£æåˆ†æç»“æœå¤±è´¥: {str(e)}")
            return {
                'interaction': '', # æ–°å¢
                'object': '',
                'scene': '',
                'emotion': '',
                'brand_elements': '',
                'confidence': 0.1,
                'all_tags': []
            }
    
    def _needs_audio_fallback(self, visual_result: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦å¯ç”¨è¯­éŸ³è½¬å½•ä¿åº•æœºåˆ¶"""
        all_tags = visual_result.get('all_tags', [])
        
        # æƒ…å†µ1ï¼šall_tagså®Œå…¨ä¸ºç©º
        if not all_tags:
            return True
        
        # æƒ…å†µ2ï¼šall_tagsåªåŒ…å«æ— æ„ä¹‰å†…å®¹
        meaningless_tags = {'ä¸ç¡®å®š', 'æ— ', 'ç”»é¢ä¸æ¸…æ™°', 'è§£æå¤±è´¥', ''}
        if all(tag in meaningless_tags for tag in all_tags):
            return True
        
        # æƒ…å†µ3ï¼šè´¨é‡åˆ†è¿‡ä½
        quality_score = visual_result.get('quality_score', 1.0)
        if quality_score < 0.5:
            return True
        
        # æƒ…å†µ4ï¼šå…³é”®å­—æ®µä¸ºç©ºæ—¶å¯ç”¨éŸ³é¢‘å…œåº•
        def is_field_empty(field_value):
            """åˆ¤æ–­å­—æ®µæ˜¯å¦ä¸ºç©ºæˆ–æ— æ„ä¹‰"""
            if not field_value:
                return True
            cleaned = str(field_value).strip()
            return cleaned in ['', 'æ— ', 'ä¸ç¡®å®š', 'è§£æå¤±è´¥', 'ç–‘ä¼¼å“ç‰Œè¦ç´ ', 'ç–‘ä¼¼äººç‰©æ´»åŠ¨', 'ç–‘ä¼¼å®¤å†…ç¯å¢ƒ', 'ç–‘ä¼¼æ¸©é¦¨æ°›å›´']
        
        object_empty = is_field_empty(visual_result.get('object'))
        brand_empty = is_field_empty(visual_result.get('brand_elements'))
        scene_empty = is_field_empty(visual_result.get('scene'))
        emotion_empty = is_field_empty(visual_result.get('emotion'))
        
        # å¦‚æœç‰©ä½“å’Œå“ç‰Œéƒ½ä¸ºç©ºï¼Œå¯ç”¨éŸ³é¢‘å…œåº•
        if object_empty and brand_empty:
            logger.info("ğŸ¤ æ£€æµ‹åˆ°å…³é”®å­—æ®µä¸ºç©º(ç‰©ä½“+å“ç‰Œ)ï¼Œå¯ç”¨éŸ³é¢‘å…œåº•åˆ†æ")
            return True
        
        # å¦‚æœç‰©ä½“ã€åœºæ™¯ã€å“ç‰Œä¸‰è€…ä¸­æœ‰ä¸¤ä¸ªä¸ºç©ºï¼Œä¹Ÿå¯ç”¨éŸ³é¢‘åˆ†æ
        empty_count = sum([object_empty, brand_empty, scene_empty])
        if empty_count >= 2:
            logger.info(f"ğŸ¤ æ£€æµ‹åˆ°{empty_count}ä¸ªå…³é”®å­—æ®µä¸ºç©ºï¼Œå¯ç”¨éŸ³é¢‘å…œåº•åˆ†æ")
            return True
        
        # å¦‚æœå››ä¸ªä¸»è¦å­—æ®µä¸­æœ‰3ä¸ªä¸ºç©ºï¼Œå¼ºåˆ¶å¯ç”¨éŸ³é¢‘åˆ†æ
        total_empty = sum([object_empty, brand_empty, scene_empty, emotion_empty])
        if total_empty >= 3:
            logger.info(f"ğŸ¤ æ£€æµ‹åˆ°{total_empty}ä¸ªå­—æ®µä¸ºç©º(å…±4ä¸ª)ï¼Œå¼ºåˆ¶å¯ç”¨éŸ³é¢‘å…œåº•åˆ†æ")
            return True
        
        return False
    
    def _get_targeted_analysis_prompt(self, transcription: str, visual_result: Dict[str, Any]) -> str:
        """ä¸ºç›®æ ‡æ€§éŸ³é¢‘åˆ†æç”ŸæˆPromptï¼Œç»“åˆè§†è§‰å’ŒéŸ³é¢‘ä¿¡æ¯ï¼ŒæŒ‰æ–°ä¼˜å…ˆçº§æ’åº"""
        try:
            # åŠ¨æ€åŠ è½½æ ¸å¿ƒå“ç‰Œåˆ—è¡¨
            core_brands_text = "æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼š['illuma', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³', 'Wyeth', 'A2', 'ATWO', 'HMO']"
            try:
                from utils.keyword_config import get_brands
                brands = get_brands()
                if brands:
                    core_brands_text = f"æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼š{brands}"
            except Exception as e:
                logger.warning(f"æ— æ³•åŠ è½½æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ï¼Œå°†ä½¿ç”¨é»˜è®¤åˆ—è¡¨: {e}")

            visual_summary = (
                f"- **ç”»é¢ç‰©ä½“**: {visual_result.get('object', 'æœªçŸ¥')}\n"
                f"- **ç”»é¢åœºæ™¯**: {visual_result.get('scene', 'æœªçŸ¥')}\n"
                f"- **ç”»é¢æƒ…ç»ª**: {visual_result.get('emotion', 'æœªçŸ¥')}"
            )

            # æŒ‰æ–°ä¼˜å…ˆçº§é‡æ–°æ„å»ºæç¤ºè¯
            return f"""
# **èº«ä»½**
ä½ æ˜¯ä¸€ä½ç»“åˆå¤šæ¨¡æ€ä¿¡æ¯ï¼ˆè§†è§‰+è¯­éŸ³ï¼‰çš„é«˜çº§åˆ†æä¸“å®¶ã€‚

# **ä»»åŠ¡**
ä½ çš„ä»»åŠ¡æ˜¯ç»“åˆ"åˆæ­¥è§†è§‰åˆ†ææ‘˜è¦"å’Œ"è¯­éŸ³è½¬å½•æ–‡æœ¬"ï¼Œå¯¹å†…å®¹è¿›è¡Œä¸€æ¬¡å…¨é¢ã€ç²¾ç¡®çš„è¡¥å……åˆ†æã€‚è¯­éŸ³ä¿¡æ¯æ˜¯ä¸»è¦åˆ¤æ–­ä¾æ®ï¼Œè§†è§‰ä¿¡æ¯ä¸ºè¾…åŠ©ã€‚

# **ğŸ¯ è¯†åˆ«ä¼˜å…ˆçº§é¡ºåºï¼ˆæŒ‰é‡è¦æ€§æ’åºï¼‰**
1ï¸âƒ£ **æœ€é«˜ä¼˜å…ˆçº§ - å“ç‰Œè¯†åˆ«å’Œå“ç‰Œç›¸å…³å†…å®¹**
2ï¸âƒ£ **ç¬¬äºŒä¼˜å…ˆçº§ - æƒ…ç»ªè¡¨è¾¾å®šä½**
3ï¸âƒ£ **ç¬¬ä¸‰ä¼˜å…ˆçº§ - å…¶ä»–ç‰©ä½“å’Œåœºæ™¯**

# **ğŸ·ï¸ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šå“ç‰Œè¯†åˆ«å’Œå“ç‰Œç›¸å…³å†…å®¹è¯†åˆ«**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- **å“ç‰Œè¯†åˆ«é“å¾‹**: å“ç‰Œ(brand_elements)çš„è¯†åˆ«å¿…é¡»éµå®ˆé“å¾‹ï¼š**åªèƒ½**ä»"{core_brands_text}"ä¸­é€‰æ‹©ã€‚å¦‚æœåœ¨è¯­éŸ³æˆ–è§†è§‰ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°è¿™äº›æ ¸å¿ƒå“ç‰Œï¼Œè¯¥å­—æ®µå¿…é¡»ä¸º"æ— "ã€‚**ç»å¯¹ç¦æ­¢**è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œã€‚
- **å“ç‰Œè¯†åˆ«é‡ç‚¹**: ç‰¹åˆ«å…³æ³¨è¯­éŸ³ä¸­ç›´æ¥æåŠçš„å“ç‰Œåç§°ï¼Œä»¥åŠè§†è§‰ä¸­çš„å“ç‰Œlogoã€åŒ…è£…æ ‡è¯†ã€‚

ğŸ¥› **å“ç‰Œç›¸å…³å†…å®¹ï¼ˆä¼˜å…ˆè¯†åˆ«ï¼‰**:
- **äº§å“ç‰©ä½“**: å¥¶ç²‰ã€å¥¶ç²‰ç½ã€å¥¶ç“¶ã€äº§å“åŒ…è£…ã€å¥¶ç²‰ç‰¹å†™ç­‰
- **è¥å…»æˆåˆ†**: A2å¥¶æºã€DHAã€HMOã€sn-2ã€æˆåˆ†ã€é…æ–¹ã€è‡ªå¾¡åŠ›ã€ä¿æŠ¤åŠ›ç­‰
- **å“ç‰Œæ ‡è¯†**: å“ç‰Œlogoã€Logoç‰¹å†™ã€å“ç‰Œæ ‡è¯†ã€å®˜æ–¹æ ‡è¯†ç­‰
- **ä½¿ç”¨åœºæ™¯**: å†²å¥¶ã€å–‚å…»ã€äº§å“å±•ç¤ºã€ä¸“å®¶æ¨èç­‰
- **åŠŸæ•ˆæè¿°**: å…ç–«åŠ›ã€å¸æ”¶ã€æ¶ˆåŒ–ã€å¥åº·æˆé•¿ã€è¥å…»æˆåˆ†ç­‰

âš ï¸ **ä¸¥æ ¼é™åˆ¶**: Brand_Elementså­—æ®µåªèƒ½ä»æ ¸å¿ƒå“ç‰Œåˆ—è¡¨é€‰æ‹©ï¼Œä¸å¾—è¯†åˆ«ä»»ä½•å…¶ä»–å“ç‰Œï¼
ğŸ¯ **è¯†åˆ«é‡ç‚¹**: 
- è¯­éŸ³ä¸­ç›´æ¥è¯´å‡ºçš„å“ç‰Œåç§°
- è§†è§‰ä¸­çš„å“ç‰Œlogoã€äº§å“åŒ…è£…æ ‡è¯†
- ä¸æ ¸å¿ƒå“ç‰Œç›¸å…³çš„äº§å“ç‰¹å¾æè¿°

# **ğŸ˜Š ç¬¬äºŒä¼˜å…ˆçº§ï¼šæƒ…ç»ªè¡¨è¾¾å®šä½**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¨ **æƒ…ç»ªè¯†åˆ«æŒ‡å¼•**:
- **è¯­éŸ³æƒ…ç»ª**: é‡ç‚¹è¯†åˆ«è¯­éŸ³ä¸­ç›´æ¥è¡¨è¾¾çš„æƒ…æ„Ÿè¯æ±‡å’Œè¯­æ°”å˜åŒ–
- **è§†è§‰æƒ…ç»ª**: ç»“åˆç”»é¢æ°›å›´ã€äººç‰©è¡¨æƒ…ä¼ è¾¾çš„æƒ…æ„Ÿ
- **æ•´ä½“æƒ…ç»ª**: ç»¼åˆè¯­éŸ³å’Œè§†è§‰ä¿¡æ¯åˆ¤æ–­æ•´ä½“æƒ…æ„Ÿæ°›å›´
- **éšå«æƒ…ç»ª**: ä»æè¿°çš„æƒ…å¢ƒå’Œå†…å®¹ä¸­æ¨æ–­éšå«çš„æƒ…æ„ŸçŠ¶æ€

# **ğŸ” ç¬¬ä¸‰ä¼˜å…ˆçº§ï¼šå…¶ä»–ç‰©ä½“å’Œåœºæ™¯**
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
- **å…¶ä»–ç‰©ä½“**: åœ¨å®Œæˆå“ç‰Œç›¸å…³ç‰©ä½“è¯†åˆ«åï¼Œè¡¥å……è¯†åˆ«å…¶ä»–ç›¸å…³ç‰©ä½“
- **åœºæ™¯ç¯å¢ƒ**: ç†è§£å’Œæè¿°è¯­éŸ³ä¸­æåŠæˆ–è§†è§‰ä¸­å±•ç°çš„åœºæ™¯ç¯å¢ƒ

# **æ ¸å¿ƒæŒ‡ä»¤**
- **è¯­éŸ³ä¼˜å…ˆ**: ä¸»è¦ä¾èµ–"è¯­éŸ³è½¬å½•æ–‡æœ¬"è¿›è¡Œåˆ¤æ–­ã€‚
- **å“ç‰Œè¯†åˆ«ä¼˜å…ˆçº§æœ€é«˜**: å‘ç°æ ¸å¿ƒå“ç‰ŒæåŠæ—¶å¿…é¡»å‡†ç¡®è¯†åˆ«
- **å“ç‰Œç›¸å…³å†…å®¹é‡ç‚¹å…³æ³¨**: è¥å…»æˆåˆ†ã€äº§å“åŠŸæ•ˆç­‰è¦ç‰¹åˆ«ç•™æ„
- **æƒ…ç»ªå®šä½å¾ˆé‡è¦**: å‡†ç¡®åˆ¤æ–­è¯­éŸ³å’Œè§†è§‰ä¼ è¾¾çš„æƒ…æ„ŸçŠ¶æ€
- **è¡¥å……åˆ†æ**: ä½ çš„ç›®æ ‡æ˜¯è¡¥å……æˆ–ä¿®æ­£åˆæ­¥çš„è§†è§‰åˆ†æï¼Œç‰¹åˆ«æ˜¯é‚£äº›åœ¨è¯­éŸ³ä¸­æ‰æ˜ç¡®ä½“ç°çš„ä¿¡æ¯ï¼ˆå¦‚å…·ä½“åŠŸæ•ˆã€ç”¨æˆ·åé¦ˆç­‰ï¼‰ã€‚

# **å·²çŸ¥ä¿¡æ¯**
## åˆæ­¥è§†è§‰åˆ†ææ‘˜è¦
{visual_summary}

## è¯­éŸ³è½¬å½•æ–‡æœ¬
"{transcription}"

# **è¾“å‡ºæ ¼å¼** (ä¸¥æ ¼éµå®ˆï¼Œåªéœ€è¾“å‡ºè¡¥å……ä¿¡æ¯)
- **Object_Supplement**: [è¯­éŸ³ä¸­æåˆ°çš„ã€å¯è¡¥å……çš„ç‰©ä½“ä¿¡æ¯ï¼Œä¼˜å…ˆè¯†åˆ«å“ç‰Œç›¸å…³ç‰©ä½“]
- **Sence_Supplement**: [è¯­éŸ³ä¸­æåˆ°çš„ã€å¯è¡¥å……çš„åœºæ™¯ä¿¡æ¯]
- **Emotion_Supplement**: [è¯­éŸ³ä¸­æåˆ°çš„ã€å¯è¡¥å……çš„æƒ…ç»ªä¿¡æ¯]
- **Brand_Elements**: [åªèƒ½æ¥è‡ªä¸Šè¿°å“ç‰Œé“å¾‹ä¸­æåˆ°çš„åˆ—è¡¨]
- **Confidence**: [0.0-1.0]

# **å¼€å§‹åˆ†æ**
è¯·æ ¹æ®ä¸Šè¿°æ‰€æœ‰ä¿¡æ¯å’Œä¼˜å…ˆçº§é¡ºåºï¼Œå¼€å§‹ä½ çš„è¡¥å……åˆ†æã€‚
"""
        except Exception as e:
            logger.error(f"æ„å»ºç›®æ ‡æ€§åˆ†æPromptå¤±è´¥: {e}")
            return f"è¯·åŸºäºä»¥ä¸‹æ–‡æœ¬è¿›è¡Œè¡¥å……åˆ†æï¼š{transcription}"
    
    def _audio_fallback_analysis(self, video_path: str, tag_language: str = "ä¸­æ–‡") -> Dict[str, Any]:
        """è¯­éŸ³è½¬å½•ä¿åº•åˆ†ææœºåˆ¶"""
        try:
            logger.info("ğŸ¤ å¼€å§‹è¯­éŸ³è½¬å½•åˆ†æ...")
            
            # æ­¥éª¤1ï¼šæå–éŸ³é¢‘å¹¶è½¬å½•
            transcription = self._extract_and_transcribe_audio(video_path)
            
            if not transcription or transcription.strip() == "":
                logger.warning("ğŸ¤ è¯­éŸ³è½¬å½•ç»“æœä¸ºç©º")
                return self._get_default_result("è¯­éŸ³è½¬å½•ç»“æœä¸ºç©º")
            
            logger.info(f"ğŸ¤ è½¬å½•æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(transcription)} å­—ç¬¦")
            
            # æ­¥éª¤2ï¼šä½¿ç”¨DeepSeekåˆ†æè½¬å½•æ–‡æœ¬
            audio_analysis = self._analyze_transcription_with_deepseek(transcription, tag_language)
            
            if audio_analysis.get("success"):
                audio_analysis["analysis_method"] = "audio_only"
                audio_analysis["transcription"] = transcription
                logger.info("ğŸ¤ è¯­éŸ³è½¬å½•åˆ†ææˆåŠŸ")
                return audio_analysis
            else:
                logger.warning("ğŸ¤ DeepSeekæ–‡æœ¬åˆ†æå¤±è´¥")
                return self._get_default_result("DeepSeekæ–‡æœ¬åˆ†æå¤±è´¥")
                
        except Exception as e:
            logger.error(f"è¯­éŸ³è½¬å½•ä¿åº•åˆ†æå¤±è´¥: {str(e)}")
            return self._get_default_result(f"è¯­éŸ³è½¬å½•åˆ†æå¤±è´¥: {str(e)}")
    
    def _targeted_audio_fallback_analysis(self, video_path: str, visual_result: Dict[str, Any], tag_language: str = "ä¸­æ–‡") -> Dict[str, Any]:
        """
        ğŸ¯ é’ˆå¯¹æ€§è¯­éŸ³è½¬å½•ä¿åº•åˆ†æ - åªè¡¥å¼ºvisualç¼ºå¤±å­—æ®µ
        """
        try:
            logger.info("ğŸ¯ å¼€å§‹é’ˆå¯¹æ€§è¯­éŸ³è½¬å½•åˆ†æ...")
            
            # æ­¥éª¤1ï¼šæå–éŸ³é¢‘å¹¶è½¬å½•
            transcription = self._extract_and_transcribe_audio(video_path)
            
            if not transcription or transcription.strip() == "":
                logger.warning("ğŸ¤ è¯­éŸ³è½¬å½•ç»“æœä¸ºç©º")
                return visual_result  # è¿”å›åŸå§‹visualç»“æœ
            
            logger.info(f"ğŸ¤ è½¬å½•æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(transcription)} å­—ç¬¦")
            
            # æ­¥éª¤2ï¼šä½¿ç”¨é’ˆå¯¹æ€§DeepSeekåˆ†æ
            audio_supplement = self._targeted_deepseek_analysis(transcription, visual_result, tag_language)
            
            if audio_supplement.get("success"):
                # æ­¥éª¤3ï¼šæ™ºèƒ½åˆå¹¶ç»“æœ
                merged_result = self._merge_targeted_results(visual_result, audio_supplement)
                merged_result["analysis_method"] = "visual_targeted_audio_fusion"
                merged_result["transcription"] = transcription
                logger.info("ğŸ¯ é’ˆå¯¹æ€§è§†è§‰+è¯­éŸ³èåˆå®Œæˆ")
                return merged_result
            else:
                logger.warning("ğŸ¤ é’ˆå¯¹æ€§DeepSeekåˆ†æå¤±è´¥ï¼Œè¿”å›visualç»“æœ")
                return visual_result
                
        except Exception as e:
            logger.error(f"é’ˆå¯¹æ€§è¯­éŸ³è½¬å½•åˆ†æå¤±è´¥: {str(e)}")
            return visual_result
    
    def _targeted_deepseek_analysis(self, transcription: str, visual_result: Dict[str, Any], tag_language: str) -> Dict[str, Any]:
        """
        ğŸ¯ é’ˆå¯¹æ€§DeepSeekåˆ†æ - åªåˆ†æç¼ºå¤±å­—æ®µ
        """
        try:
            if not self.deepseek_analyzer.is_available():
                logger.warning("ğŸ¤– DeepSeekåˆ†æå™¨ä¸å¯ç”¨")
                return {"success": False}
            
            logger.info("ğŸ¯ å¼€å§‹é’ˆå¯¹æ€§DeepSeekéŸ³é¢‘åˆ†æ...")
            
            # ç”Ÿæˆé’ˆå¯¹æ€§prompt
            targeted_prompt = self._get_targeted_analysis_prompt(transcription, visual_result)
            
            # ä½¿ç”¨DeepSeekåˆ†æå™¨
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ¯å©´äº§å“è¯­éŸ³å†…å®¹åˆ†æå¸ˆï¼Œä¸“é—¨è¡¥å……visualåˆ†æçš„ç¼ºå¤±å­—æ®µã€‚åªåˆ†ææŒ‡å®šçš„ç¼ºå¤±å­—æ®µï¼Œä¸è¦é‡å¤å·²æœ‰ç»“æœã€‚"},
                {"role": "user", "content": targeted_prompt}
            ]
            
            response = self.deepseek_analyzer._chat_completion(messages)
            
            if response and "choices" in response and response["choices"]:
                result_text = response["choices"][0].get("message", {}).get("content", "")
                logger.info(f"ğŸ¯ é’ˆå¯¹æ€§DeepSeekåˆ†æç»“æœ: {result_text}")
                
                # è§£æé’ˆå¯¹æ€§åˆ†æç»“æœ
                parsed_result = self._parse_targeted_deepseek_analysis(result_text, visual_result)
                
                if parsed_result:
                    parsed_result["success"] = True
                    return parsed_result
                else:
                    return {"success": False}
            else:
                logger.warning("ğŸ¤– é’ˆå¯¹æ€§DeepSeek APIè°ƒç”¨å¤±è´¥")
                return {"success": False}
                
        except Exception as e:
            logger.error(f"é’ˆå¯¹æ€§DeepSeekåˆ†æå¤±è´¥: {str(e)}")
            return {"success": False}
    
    def _parse_targeted_deepseek_analysis(self, analysis_text: str, visual_result: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """
        ğŸ¯ è§£æé’ˆå¯¹æ€§DeepSeekåˆ†æç»“æœ - åªå¤„ç†ç¼ºå¤±å­—æ®µ
        """
        try:
            result = {
                'object': visual_result.get('object', ''),  # ä¿ç•™visualç»“æœ
                'scene': visual_result.get('scene', ''),
                'emotion': visual_result.get('emotion', ''),
                'brand_elements': visual_result.get('brand_elements', ''),
                'confidence': visual_result.get('confidence', 0.7)
            }
            
            logger.info(f"ğŸ¯ å¼€å§‹è§£æé’ˆå¯¹æ€§åˆ†æç»“æœ:")
            logger.info(f"åŸå§‹æ–‡æœ¬: {analysis_text}")
            
            # æ¸…ç†å‡½æ•°
            def clean_field_value(value):
                if not value:
                    return ''
                cleaned = str(value).strip()
                # ç§»é™¤å¸¸è§çš„æ— æ„ä¹‰å€¼
                if cleaned in ['æ— ', 'ä¸ç¡®å®š', 'è§£æå¤±è´¥', 'N/A', 'null', 'None', '']:
                    return ''
                # ç§»é™¤æ–¹æ‹¬å·ç­‰
                cleaned = cleaned.replace('[', '').replace(']', '').replace('**', '')
                return cleaned.strip()
            
            # é€è¡Œå¤„ç†ï¼Œåªæ›´æ–°æœ‰å†…å®¹çš„å­—æ®µ
            lines = analysis_text.strip().split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                logger.info(f"å¤„ç†è¡Œ: '{line}'")
                
                # è§£æå„ç§æ ¼å¼çš„å­—æ®µ
                if line.lower().startswith('object_supplement:') or line.lower().startswith('- **object_supplement**:'):
                    # é’ˆå¯¹æ€§åˆ†æè¡¥å……æ ¼å¼
                    raw_value = line.split(':', 1)[1].strip() if ':' in line else ''
                    new_value = clean_field_value(raw_value)
                    if new_value and not visual_result.get('object'):
                        result['object'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……object: '{new_value}'")
                        
                elif line.lower().startswith('object:') and not visual_result.get('object'):
                    raw_value = line[7:].strip()
                    new_value = clean_field_value(raw_value)
                    if new_value:  # åªæœ‰éç©ºæ—¶æ‰æ›´æ–°
                        result['object'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……object: '{new_value}'")
                
                elif line.lower().startswith('scene_supplement:') or line.lower().startswith('- **scene_supplement**:'):
                    raw_value = line.split(':', 1)[1].strip() if ':' in line else ''
                    new_value = clean_field_value(raw_value)
                    if new_value and not visual_result.get('scene'):
                        result['scene'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……scene: '{new_value}'")
                    
                elif line.lower().startswith('scene:') and not visual_result.get('scene'):
                    raw_value = line[6:].strip()
                    new_value = clean_field_value(raw_value)
                    if new_value:
                        result['scene'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……scene: '{new_value}'")
                
                elif line.lower().startswith('emotion_supplement:') or line.lower().startswith('- **emotion_supplement**:'):
                    raw_value = line.split(':', 1)[1].strip() if ':' in line else ''
                    new_value = clean_field_value(raw_value)
                    if new_value and not visual_result.get('emotion'):
                        result['emotion'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……emotion: '{new_value}'")
                    
                elif line.lower().startswith('emotion:') and not visual_result.get('emotion'):
                    raw_value = line[8:].strip()
                    new_value = clean_field_value(raw_value)
                    if new_value:
                        result['emotion'] = new_value
                        logger.info(f"ğŸ¯ è¡¥å……emotion: '{new_value}'")
                    
                elif line.lower().startswith('brand_elements:') or line.lower().startswith('- **brand_elements**:'):
                    # ğŸ”§ ä¿®å¤ï¼šå®‰å…¨åœ°æå–brand_elementsçš„å€¼
                    if '- **brand_elements**:' in line.lower():
                        raw_value = line.split(':', 1)[1].strip() if ':' in line else ''
                    else:
                        raw_value = line[15:].strip()
                    
                    new_value = clean_field_value(raw_value)
                    # ğŸ”§ é‡è¦ä¿®å¤ï¼šå¦‚æœvisualæ˜¯"ç–‘ä¼¼å“ç‰Œè¦ç´ "æˆ–ç©ºï¼Œä¸”DeepSeekæœ‰æ­£ç¡®è¯†åˆ«ï¼Œåˆ™è¦†ç›–
                    visual_brand = visual_result.get('brand_elements', '')
                    if new_value and (not visual_brand or visual_brand in ['ç–‘ä¼¼å“ç‰Œè¦ç´ ', 'æ— ', '']):
                        # ğŸš¨ ä¸¥æ ¼å“ç‰Œè¿‡æ»¤ï¼šåªæ¥å—é…ç½®åˆ—è¡¨ä¸­çš„å“ç‰Œ
                        try:
                            from utils.keyword_config import get_brands
                            allowed_brands = [b.lower() for b in get_brands()]
                        except Exception as e:
                            logger.error(f"æ— æ³•åŠ è½½å“ç‰Œé…ç½®: {e}")
                            allowed_brands = ['illuma', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³', 'wyeth', 'a2', 'atwo', 'hmo']
                        
                        # è¿‡æ»¤å¹¶éªŒè¯å“ç‰Œ
                        detected_brands = [b.strip() for b in new_value.split(',') if b.strip()]
                        valid_brands = []
                        for brand in detected_brands:
                            if brand.lower() in allowed_brands:
                                valid_brands.append(brand)
                            else:
                                logger.debug(f"ğŸš« [å“ç‰Œè¿‡æ»¤] å·²ç§»é™¤ä¸åœ¨é…ç½®ä¸­çš„å“ç‰Œ: '{brand}'")
                        
                        if valid_brands:
                            result['brand_elements'] = ','.join(valid_brands)
                            logger.info(f"ğŸ¯ è¦†ç›–brand_elements: '{result['brand_elements']}' (æ›¿æ¢äº†: '{visual_brand}')")
                        else:
                            result['brand_elements'] = ''
                            logger.info(f"ğŸ¯ å“ç‰Œè¿‡æ»¤åä¸ºç©ºï¼Œæ¸…é™¤brand_elements")
                        
                elif line.lower().startswith('confidence:'):
                    confidence_text = line[11:].strip()
                    try:
                        import re
                        confidence_match = re.search(r'([0-9.]+)', confidence_text)
                        if confidence_match:
                            result['confidence'] = float(confidence_match.group(1))
                    except:
                        pass  # ä¿æŒåŸæœ‰confidence
            
            # æ›´æ–°all_tags
            all_tags = []
            for value in [result['object'], result['scene'], result['emotion'], result['brand_elements']]:
                if value:
                    tags = [tag.strip() for tag in value.split(',') if tag.strip()]
                    for tag in tags:
                        cleaned_tag = clean_field_value(tag)
                        if cleaned_tag and cleaned_tag not in all_tags:
                            all_tags.append(cleaned_tag)
            
            result['all_tags'] = all_tags
            
            logger.info(f"ğŸ¯ é’ˆå¯¹æ€§åˆ†æå®Œæˆ:")
            logger.info(f"   ç‰©ä½“: '{result['object']}'")
            logger.info(f"   åœºæ™¯: '{result['scene']}'")
            logger.info(f"   æƒ…ç»ª: '{result['emotion']}'")
            logger.info(f"   å“ç‰Œ: '{result['brand_elements']}'")
            
            return result
            
        except Exception as e:
            logger.error(f"è§£æé’ˆå¯¹æ€§DeepSeekç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def _merge_targeted_results(self, visual_result: Dict[str, Any], audio_supplement: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ¯ åˆå¹¶é’ˆå¯¹æ€§ç»“æœ - é«˜æ•ˆèåˆ
        """
        try:
            logger.info("ğŸ¯ å¼€å§‹åˆå¹¶é’ˆå¯¹æ€§åˆ†æç»“æœ...")
            
            # ä»¥visualä¸ºåŸºç¡€ï¼Œç”¨audioè¡¥å……
            merged_result = visual_result.copy()
            
            # åªè¦†ç›–visualä¸­çš„ç©ºå­—æ®µ
            for field in ['object', 'scene', 'emotion', 'brand_elements']:
                visual_value = visual_result.get(field, '')
                audio_value = audio_supplement.get(field, '')
                
                # å¦‚æœvisualä¸ºç©ºä¸”audioæœ‰å€¼ï¼Œåˆ™ä½¿ç”¨audioçš„å€¼
                if not visual_value and audio_value:
                    merged_result[field] = audio_value
                    logger.info(f"ğŸ¯ å­—æ®µè¡¥å……: {field} = '{audio_value}'")
            
            # åˆå¹¶all_tags
            visual_tags = visual_result.get('all_tags', [])
            audio_tags = audio_supplement.get('all_tags', [])
            merged_tags = list(set(visual_tags + audio_tags))  # å»é‡
            merged_result['all_tags'] = merged_tags
            
            # æ›´æ–°è´¨é‡åˆ† - å¦‚æœæœ‰è¡¥å……ï¼Œè´¨é‡åˆ†æå‡
            supplemented_count = sum(1 for field in ['object', 'scene', 'emotion', 'brand_elements'] 
                                   if not visual_result.get(field) and audio_supplement.get(field))
            
            if supplemented_count > 0:
                original_quality = visual_result.get('quality_score', 0.5)
                boost = supplemented_count * 0.1  # æ¯è¡¥å……ä¸€ä¸ªå­—æ®µæå‡0.1
                merged_result['quality_score'] = min(1.0, original_quality + boost)
                logger.info(f"ğŸ¯ è´¨é‡åˆ†æå‡: {original_quality:.2f} â†’ {merged_result['quality_score']:.2f} (è¡¥å……äº†{supplemented_count}ä¸ªå­—æ®µ)")
            
            merged_result['success'] = True
            merged_result['targeted_supplement_count'] = supplemented_count
            
            return merged_result
            
        except Exception as e:
            logger.error(f"é’ˆå¯¹æ€§ç»“æœåˆå¹¶å¤±è´¥: {str(e)}")
            return visual_result  # å¤±è´¥æ—¶è¿”å›original visualç»“æœ
    
    def _extract_and_transcribe_audio(self, video_path: str) -> str:
        """ä½¿ç”¨DashScopeAudioAnalyzeræå–éŸ³é¢‘å¹¶è½¬å½•"""
        try:
            if not self.audio_analyzer.is_available():
                logger.warning("ğŸ¤ DashScopeéŸ³é¢‘åˆ†æå™¨ä¸å¯ç”¨")
                return ""
            
            logger.info(f"ğŸ¤ å¼€å§‹è½¬å½•è§†é¢‘éŸ³é¢‘: {video_path}")
            
            # ä½¿ç”¨éŸ³é¢‘åˆ†æå™¨è¿›è¡Œè½¬å½• - ğŸ”§ å¯ç”¨é»˜è®¤çƒ­è¯ä¼˜åŒ–
            result = self.audio_analyzer.transcribe_video(
                video_path=video_path,
                extract_audio_first=True,
                preset_vocabulary_id="default"  # ğŸ”§ ä½¿ç”¨é»˜è®¤çƒ­è¯ID
            )
            
            if result.get("success") and result.get("transcript"):
                transcription = result["transcript"]
                logger.info(f"ğŸ¤ è½¬å½•æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(transcription)} å­—ç¬¦")
                return transcription
            else:
                error_msg = result.get("error", "æœªçŸ¥é”™è¯¯")
                logger.warning(f"ğŸ¤ è½¬å½•å¤±è´¥: {error_msg}")
                return ""
                
        except Exception as e:
            logger.error(f"éŸ³é¢‘è½¬å½•å¤±è´¥: {str(e)}")
            return ""
    
    def _analyze_transcription_with_deepseek(self, transcription: str, tag_language: str) -> Dict[str, Any]:
        """ä½¿ç”¨DeepSeekAnalyzeråˆ†æè½¬å½•æ–‡æœ¬ï¼ˆä¸“ä¸ºè¯­éŸ³å†…å®¹å®šåˆ¶ï¼‰"""
        try:
            if not self.deepseek_analyzer.is_available():
                logger.warning("ğŸ¤– DeepSeekåˆ†æå™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•æ–‡æœ¬åˆ†æ")
                return self._simple_text_analysis(transcription)
            
            logger.info("ğŸ¤– å¼€å§‹DeepSeekéŸ³é¢‘è½¬å½•æ–‡æœ¬åˆ†æ...")
                
            # æ„å»ºéŸ³é¢‘è½¬å½•åˆ†ææç¤ºè¯ï¼ˆä½¿ç”¨ä¸“é—¨çš„è¯­éŸ³åˆ†æPromptï¼‰
            try:
                from utils.keyword_config import get_deepseek_audio_prompt
                analysis_prompt = get_deepseek_audio_prompt()
                
                # åœ¨Promptä¸­æ·»åŠ å®é™…è½¬å½•æ–‡æœ¬
                analysis_prompt += f"\n\nğŸ“ éœ€è¦åˆ†æçš„è½¬å½•æ–‡æœ¬ï¼š\n{transcription}"
                
            except Exception as e:
                logger.warning(f"æ— æ³•å¯¼å…¥DeepSeekè¯­éŸ³promptç”Ÿæˆé€»è¾‘ï¼Œä½¿ç”¨å…œåº•é…ç½®: {e}")
                analysis_prompt = self._get_fallback_audio_prompt() + f"\n\nè½¬å½•æ–‡æœ¬ï¼š{transcription}"

            # ä½¿ç”¨DeepSeekåˆ†æå™¨
            messages = [
                {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„æ¯å©´äº§å“è¯­éŸ³å†…å®¹åˆ†æå¸ˆï¼Œä¸“é—¨ä»è¯­éŸ³è½¬å½•æ–‡æœ¬ä¸­æå–è¯­ä¹‰ä¿¡æ¯ã€‚è¯·åŸºäºè½¬å½•å†…å®¹çš„è¯­ä¹‰ç†è§£è¿›è¡Œåˆ†æï¼Œä¸¥æ ¼ä»ä¸šåŠ¡è¯è¡¨ä¸­é€‰æ‹©åŒ¹é…çš„æ ‡ç­¾ã€‚"},
                {"role": "user", "content": analysis_prompt}
            ]
            
            response = self.deepseek_analyzer._chat_completion(messages)
            
            if response and "choices" in response and response["choices"]:
                result_text = response["choices"][0].get("message", {}).get("content", "")
                logger.info(f"ğŸ¤– DeepSeekéŸ³é¢‘åˆ†æç»“æœ: {result_text}")
                
                # è§£æDeepSeekçš„åˆ†æç»“æœ
                parsed_result = self._parse_deepseek_analysis(result_text)
                
                if parsed_result:
                    parsed_result["success"] = True
                    return parsed_result
                else:
                    return self._simple_text_analysis(transcription)
            else:
                logger.warning("ğŸ¤– DeepSeek APIè°ƒç”¨å¤±è´¥")
                return self._simple_text_analysis(transcription)
                    
        except Exception as e:
            logger.error(f"DeepSeekæ–‡æœ¬åˆ†æå¤±è´¥: {str(e)}")
            return self._simple_text_analysis(transcription)
    
    def _parse_deepseek_analysis(self, analysis_text: str) -> Optional[Dict[str, Any]]:
        """
        è§£æDeepSeekè¿”å›çš„æ–‡æœ¬ç»“æœï¼Œå¹¶è¿›è¡Œä¸¥æ ¼çš„åå¤„ç†è¿‡æ»¤ã€‚
        """
        # ğŸ”§ é‡ç”¨Qwençš„æ ¼å¼æ¸…ç†å‡½æ•°
        def clean_field_value(value: str) -> str:
            """æ¸…ç†å­—æ®µå€¼ï¼Œç¡®ä¿è¾“å‡ºç®€æ´çš„å•è¯çŸ­è¯­"""
            if not value:
                return ''
            
            # åŸºç¡€æ¸…ç†
            cleaned = value.strip()
            
            # ğŸ”§ é‡è¦ä¿®å¤ï¼šç§»é™¤å­—æ®µæ ‡è¯†ç¬¦å¹²æ‰°
            field_markers = ['object:', 'scene:', 'emotion:', 'brand_elements:', 'confidence:']
            for marker in field_markers:
                if marker in cleaned:
                    # å¦‚æœåœ¨å¼€å¤´ï¼Œç§»é™¤å®ƒ
                    if cleaned.startswith(marker):
                        cleaned = cleaned[len(marker):].strip()
                    else:
                        # å¦‚æœåœ¨ä¸­é—´ï¼Œåªå–å‰é¢éƒ¨åˆ†
                        cleaned = cleaned.split(marker)[0].strip()
            
            # å»é™¤Markdownå’Œç‰¹æ®Šç¬¦å·
            cleaned = cleaned.replace('**', '').replace('*', '')
            cleaned = cleaned.replace('- ', '').replace('+ ', '')
            cleaned = cleaned.replace('# ', '').replace('[', '').replace(']', '')
            cleaned = cleaned.replace('(', '').replace(')', '')
            cleaned = cleaned.replace('"', '').replace("'", '')
            cleaned = cleaned.replace('ï¼š', ':').replace('ã€‚', '').replace('ï¼›', '')
            
            # å»é™¤"ç–‘ä¼¼"ç­‰è¯æ±‡
            cleaned = cleaned.replace('ç–‘ä¼¼', '').replace('å¯èƒ½', '')
            cleaned = cleaned.replace('åº”è¯¥', '').replace('ä¼¼ä¹', '')
            
            # å»é™¤é•¿å¥æè¿°ï¼ˆè¶…è¿‡20å­—çš„å†…å®¹æˆªå–å…³é”®è¯ï¼‰
            if len(cleaned) > 20:
                # æå–å…³é”®è¯ï¼ˆç®€å•å¤„ç†ï¼‰
                keywords = []
                key_terms = ['å¥¶ç²‰', 'å¥¶ç“¶', 'å¯èµ‹', 'Wyeth', 'A2', 'HMO', 'DHA', 
                           'å¨æˆ¿', 'å®¢å…', 'æ¸©é¦¨', 'ä¸“ä¸š', 'å…³çˆ±', 'å“ç‰Œ']
                for term in key_terms:
                    if term in cleaned:
                        keywords.append(term)
                cleaned = ','.join(keywords[:3]) if keywords else cleaned[:10]
            
            # å»é™¤å¤šä½™ç©ºæ ¼å’Œæ ‡ç‚¹
            cleaned = re.sub(r'\s+', ' ', cleaned).strip()
            cleaned = re.sub(r'[,ï¼Œ]+', ',', cleaned)
            cleaned = cleaned.strip(',')
            
            # è¿‡æ»¤æ— æ„ä¹‰å†…å®¹
            meaningless = ['æ— ', 'ä¸ç¡®å®š', 'ç”»é¢ä¸æ¸…æ™°', 'è§£æå¤±è´¥', 'è¯­éŸ³ä¿¡æ¯ä¸è¶³', 
                          '', 'none', 'n/a', 'ä¸æ˜ç¡®', 'è½¬å½•è¯¯å·®', 'ç›¸å…³']
            if cleaned.lower() in meaningless:
                return ''
            
            # ğŸ”§ æ–°å¢ï¼šè¿‡æ»¤çº¯æ•°å­—å†…å®¹ï¼ˆconfidenceå€¼è¯¯å…¥å…¶ä»–å­—æ®µï¼‰
            if re.match(r'^[0-9.]+$', cleaned):
                return ''
            
            # ğŸ”§ æ–°å¢ï¼šè¿‡æ»¤è¿‡çŸ­çš„æ— æ„ä¹‰å†…å®¹ï¼ˆ1-2å­—ç¬¦ï¼‰
            if len(cleaned) <= 2 and cleaned.lower() in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '.']:
                return ''
            
            return cleaned
        
        try:
            result = {
                'object': '',
                'scene': '', 
                'emotion': '',
                'brand_elements': '',
                'confidence': 0.7
            }
            
            logger.info(f"ğŸ¯ å¼€å§‹è§£æDeepSeekåˆ†ææ–‡æœ¬:")
            logger.info(f"åŸå§‹æ–‡æœ¬: {analysis_text}")
            
            # ğŸ”§ å…¨æ–°çš„è§£æç­–ç•¥ï¼šé€è¡Œå¤„ç†ï¼Œé¿å…è·¨è¡ŒåŒ¹é…é—®é¢˜
            lines = analysis_text.strip().split('\n')
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                    
                logger.info(f"å¤„ç†è¡Œ: '{line}'")
                
                # ğŸ”§ ä¿®å¤ï¼šå¤„ç†ç«–çº¿åˆ†éš”ç¬¦æ ¼å¼å’Œè¡Œå†…æ ¼å¼
                # æ£€æŸ¥æ˜¯å¦æ˜¯ç«–çº¿åˆ†éš”çš„å•è¡Œæ ¼å¼ï¼šobject: ... | scene: ... | emotion: ... | brand: ...
                if '|' in line and any(marker in line.lower() for marker in ['object:', 'scene:', 'emotion:', 'brand']):
                    # å¤„ç†ç«–çº¿åˆ†éš”æ ¼å¼
                    segments = line.split('|')
                    for segment in segments:
                        segment = segment.strip()
                        if segment.lower().startswith('object:'):
                            raw_value = segment[7:].strip()
                            result['object'] = clean_field_value(raw_value)
                            logger.info(f"[ç«–çº¿æ ¼å¼] æå–object: '{raw_value}' -> '{result['object']}'")
                        elif segment.lower().startswith('scene:'):
                            raw_value = segment[6:].strip()
                            result['scene'] = clean_field_value(raw_value)
                            logger.info(f"[ç«–çº¿æ ¼å¼] æå–scene: '{raw_value}' -> '{result['scene']}'")
                        elif segment.lower().startswith('emotion:'):
                            raw_value = segment[8:].strip()
                            result['emotion'] = clean_field_value(raw_value)
                            logger.info(f"[ç«–çº¿æ ¼å¼] æå–emotion: '{raw_value}' -> '{result['emotion']}'")
                        elif segment.lower().startswith('brand:') or segment.lower().startswith('brand_elements:'):
                            if segment.lower().startswith('brand:'):
                                raw_value = segment[6:].strip()
                            else:
                                raw_value = segment[15:].strip()
                            cleaned_brand = clean_field_value(raw_value)
                            if cleaned_brand:
                                brand_parts = [part.strip() for part in cleaned_brand.split(',')]
                                clean_parts = [part for part in brand_parts if part and not re.match(r'^[0-9]+\.?[0-9]*$', part)]
                                result['brand_elements'] = ','.join(clean_parts) if clean_parts else ''
                            else:
                                result['brand_elements'] = ''
                            logger.info(f"[ç«–çº¿æ ¼å¼] æå–brand: '{raw_value}' -> '{result['brand_elements']}'")
                
                # æ ‡å‡†å•è¡Œæ ¼å¼å¤„ç†
                elif line.lower().startswith('object:'):
                    raw_value = line[7:].strip()  # ç§»é™¤ "object:" 
                    # ç§»é™¤å¯èƒ½çš„ç«–çº¿åç¼€
                    if '|' in raw_value:
                        raw_value = raw_value.split('|')[0].strip()
                    result['object'] = clean_field_value(raw_value)
                    logger.info(f"æå–object: '{raw_value}' -> '{result['object']}'")
                    
                elif line.lower().startswith('scene:'):
                    raw_value = line[6:].strip()  # ç§»é™¤ "scene:"
                    if '|' in raw_value:
                        raw_value = raw_value.split('|')[0].strip()
                    result['scene'] = clean_field_value(raw_value)
                    logger.info(f"æå–scene: '{raw_value}' -> '{result['scene']}'")
                    
                elif line.lower().startswith('emotion:'):
                    raw_value = line[8:].strip()  # ç§»é™¤ "emotion:"
                    if '|' in raw_value:
                        raw_value = raw_value.split('|')[0].strip()
                    result['emotion'] = clean_field_value(raw_value)
                    logger.info(f"æå–emotion: '{raw_value}' -> '{result['emotion']}'")
                    
                elif line.lower().startswith('brand_elements:') or line.lower().startswith('brand:'):
                    if line.lower().startswith('brand:'):
                        raw_value = line[6:].strip()
                    else:
                        raw_value = line[15:].strip()  # ç§»é™¤ "brand_elements:"
                    # ç§»é™¤å¯èƒ½çš„ç«–çº¿åç¼€
                    if '|' in raw_value:
                        raw_value = raw_value.split('|')[0].strip()
                    # ğŸ”§ ç‰¹æ®Šå¤„ç†brand_elementsï¼šè¿‡æ»¤æ•°å­—æ±¡æŸ“
                    cleaned_brand = clean_field_value(raw_value)
                    if cleaned_brand:
                        # è¿›ä¸€æ­¥æ¸…ç†ï¼šç§»é™¤çº¯æ•°å­—ç‰‡æ®µ
                        brand_parts = [part.strip() for part in cleaned_brand.split(',')]
                        clean_parts = [part for part in brand_parts if part and not re.match(r'^[0-9]+\.?[0-9]*$', part)]
                        result['brand_elements'] = ','.join(clean_parts) if clean_parts else ''
                    else:
                        result['brand_elements'] = ''
                    logger.info(f"æå–brand_elements: '{raw_value}' -> '{result['brand_elements']}'")
                    
                elif line.lower().startswith('confidence:'):
                    confidence_text = line[11:].strip()  # ç§»é™¤ "confidence:"
                    if '|' in confidence_text:
                        confidence_text = confidence_text.split('|')[0].strip()
                    try:
                        # æå–æ•°å­—éƒ¨åˆ†
                        confidence_match = re.search(r'([0-9.]+)', confidence_text)
                        if confidence_match:
                            result['confidence'] = float(confidence_match.group(1))
                            logger.info(f"æå–confidence: '{confidence_text}' -> {result['confidence']}")
                    except:
                        result['confidence'] = 0.7
            
            # ğŸ”§ åˆ›å»ºall_tags - åªåŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹
            all_tags = []
            for value in [result['object'], result['scene'], result['emotion'], result['brand_elements']]:
                if value:  # åªè¦ä¸ä¸ºç©ºå°±å¤„ç†
                    # åˆ†å‰²é€—å·åˆ†éš”çš„æ ‡ç­¾
                    tags = [tag.strip() for tag in value.split(',') if tag.strip()]
                    for tag in tags:
                        cleaned_tag = clean_field_value(tag)
                        if cleaned_tag:  # æ¸…ç†åä¸ä¸ºç©ºå°±æ·»åŠ 
                            all_tags.append(cleaned_tag)
            
            # å»é‡å¹¶è¿‡æ»¤
            result['all_tags'] = list(set(filter(None, all_tags)))
            
            # ğŸš¨ æœ€åä¸€æ­¥ï¼šä¸¥æ ¼è¿‡æ»¤å“ç‰Œå…ƒç´ ï¼Œåªä¿ç•™é…ç½®ä¸­çš„å“ç‰Œ
            try:
                from utils.keyword_config import get_brands
                allowed_brands = [b.lower() for b in get_brands()]
            except Exception as e:
                logger.error(f"æ— æ³•åŠ è½½å“ç‰Œé…ç½®ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨: {e}")
                allowed_brands = ['illuma', 'å¯èµ‹', 'æƒ æ°', 'è•´æ·³', 'wyeth', 'a2', 'atwo', 'hmo']
            
            if result['brand_elements']:
                detected_brands_raw = result['brand_elements']
                detected_brands_list = [b.strip() for b in detected_brands_raw.split(',') if b.strip()]
                
                final_brands = []
                for brand in detected_brands_list:
                    # å¿…é¡»æ˜¯é…ç½®åˆ—è¡¨ä¸­çš„å“ç‰Œï¼ˆå¿½ç•¥å¤§å°å†™ï¼‰
                    if brand.lower() in allowed_brands:
                        final_brands.append(brand)
                    else:
                        logger.debug(f"ğŸš« [å“ç‰Œè¿‡æ»¤] å·²ç§»é™¤ä¸åœ¨é…ç½®ä¸­çš„å“ç‰Œ: '{brand}'")
                
                # å»é‡å¹¶æ›´æ–°
                if final_brands:
                    result['brand_elements'] = ','.join(list(dict.fromkeys(final_brands)))
                else:
                    result['brand_elements'] = ''
            
            logger.info(f"ğŸ¯ DeepSeekæœ€ç»ˆè§£æç»“æœ:")
            logger.info(f"   ç‰©ä½“: '{result['object']}'")
            logger.info(f"   åœºæ™¯: '{result['scene']}'")
            logger.info(f"   æƒ…ç»ª: '{result['emotion']}'")
            logger.info(f"   å“ç‰Œ: '{result['brand_elements']}'")
            logger.info(f"   ç½®ä¿¡åº¦: {result['confidence']}")
            logger.info(f"   æ ‡ç­¾: {result['all_tags']}")
            
            return result if any(v for v in result.values() if v not in ['', 0.7, []]) else None
            
        except Exception as e:
            logger.error(f"è§£æDeepSeekç»“æœå¤±è´¥: {str(e)}")
            return None
    
    def _simple_text_analysis(self, text: str) -> Dict[str, Any]:
        """ç®€å•æ–‡æœ¬åˆ†æï¼ˆå…³é”®è¯åŒ¹é…ï¼‰- ç»Ÿä¸€ä»matching_rules.jsonæå–è¯æ±‡"""
        try:
            # ğŸ¯ æ ¸å¿ƒæ”¹è¿›ï¼šç›´æ¥ä»matching_rules.jsonæå–æ‰€æœ‰è¯æ±‡
            all_objects = []
            all_scenes = []
            all_emotions = []
            
            # å“ç‰Œå…³é”®è¯ä»é…ç½®è·å–
            try:
                from utils.keyword_config import get_brands
                brands = get_brands()
                brand_keywords = brands if brands else ["å¯èµ‹", "Wyeth", "illuma", "A2", "ATWO", "HMO", "DHA"]
            except Exception as e:
                logger.warning(f"æ— æ³•è·å–å“ç‰Œåˆ—è¡¨: {e}")
                brand_keywords = ["å¯èµ‹", "Wyeth", "illuma", "A2", "ATWO", "HMO", "DHA"]
            
            found_objects = [kw for kw in all_objects if kw in text]
            found_scenes = [kw for kw in all_scenes if kw in text]
            found_emotions = [kw for kw in all_emotions if kw in text]
            found_brands = [kw for kw in brand_keywords if kw in text]
            
            result = {
                'object': ', '.join(found_objects) if found_objects else '',
                'scene': ', '.join(found_scenes) if found_scenes else '',
                'emotion': ', '.join(found_emotions) if found_emotions else '',
                'brand_elements': ', '.join(found_brands) if found_brands else '',
                'confidence': 0.6 if any([found_objects, found_scenes, found_emotions, found_brands]) else 0.3,
                'all_tags': found_objects + found_scenes + found_emotions + found_brands,
                'success': True
            }
            
            return result
            
        except Exception as e:
            logger.error(f"ç®€å•æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
            return {
                'object': '',
                'scene': '',
                'emotion': '',
                'brand_elements': '',
                'confidence': 0.3,
                'all_tags': [],
                'success': False
            }
    
    def _merge_visual_audio_results(self, visual_result: Dict[str, Any], audio_result: Dict[str, Any]) -> Dict[str, Any]:
        """èåˆè§†è§‰å’Œè¯­éŸ³åˆ†æç»“æœ"""
        try:
            logger.info("ğŸ¯ğŸ¤ å¼€å§‹èåˆè§†è§‰å’Œè¯­éŸ³åˆ†æç»“æœ...")
            
            # åŸºäºè´¨é‡åˆ†çš„èåˆç­–ç•¥
            visual_weight = visual_result.get('quality_score', 0.3)
            audio_weight = 0.7  # è¯­éŸ³è½¬å½•é€šå¸¸æ›´å¯é 
            
            # ğŸ”§ ä¿®å¤ï¼šæ ‡å‡†åŒ–å­—æ®µå€¼å¤„ç†å‡½æ•°
            def clean_and_split_value(value):
                """æ¸…ç†å¹¶åˆ†å‰²å­—æ®µå€¼"""
                if not value or value in ['æ— ', 'ä¸ç¡®å®š', 'è§£æå¤±è´¥', '']:
                    return []
                
                # æ¸…ç†å¤šä½™ç¬¦å· 
                cleaned = str(value).strip()
                # ç§»é™¤æ–¹æ‹¬å·å’Œç‰¹æ®Šç¬¦å·
                cleaned = cleaned.replace('[', '').replace(']', '').replace('**', '')
                # åˆ†å‰²å¹¶æ¸…ç†
                parts = []
                for part in cleaned.split(','):
                    part = part.strip()
                    if part and part not in ['æ— ', 'ä¸ç¡®å®š', 'è§£æå¤±è´¥']:
                        parts.append(part)
                return parts
            
            # ğŸ”§ ä¿®å¤ï¼šèåˆå„å­—æ®µ
            merged_result = {}
            
            for field in ['object', 'scene', 'emotion', 'brand_elements']:
                visual_value = visual_result.get(field, '')
                audio_value = audio_result.get(field, '')
                
                # æ¸…ç†å¹¶åˆå¹¶éç©ºå€¼
                visual_parts = clean_and_split_value(visual_value)
                audio_parts = clean_and_split_value(audio_value)
                
                # åˆå¹¶å¹¶å»é‡
                all_parts = visual_parts + audio_parts
                unique_parts = []
                for part in all_parts:
                    if part not in unique_parts:
                        unique_parts.append(part)
                
                # ğŸ”§ æ ¼å¼åŒ–è¾“å‡ºï¼šç¡®ä¿ä¸è§†è§‰åˆ†ææ ¼å¼ä¸€è‡´
                if unique_parts:
                    merged_result[field] = unique_parts[0] if len(unique_parts) == 1 else ', '.join(unique_parts)
                else:
                    merged_result[field] = ''  # ä¿æŒç©ºå€¼è€Œä¸æ˜¯"ä¸ç¡®å®š"
            
            # ğŸ”§ ä¿®å¤ï¼šèåˆè´¨é‡åˆ†å’Œç½®ä¿¡åº¦
            visual_conf = visual_result.get('confidence', 0.3)
            audio_conf = audio_result.get('confidence', 0.7)
            merged_confidence = visual_weight * visual_conf + audio_weight * audio_conf
            
            merged_result['confidence'] = round(merged_confidence, 2)
            merged_result['quality_score'] = round(merged_confidence, 2)
            
            # ğŸ”§ ä¿®å¤ï¼šèåˆall_tags - ç¡®ä¿æ ¼å¼ä¸€è‡´
            visual_tags = visual_result.get('all_tags', [])
            audio_tags = audio_result.get('all_tags', [])
            
            # æ¸…ç†å’Œåˆå¹¶æ ‡ç­¾
            all_tags_raw = visual_tags + audio_tags
            clean_tags = []
            for tag in all_tags_raw:
                if isinstance(tag, str):
                    # æ¸…ç†æ ‡ç­¾
                    clean_tag = tag.strip().replace('[', '').replace(']', '').replace('**', '')
                    if clean_tag and clean_tag not in ['æ— ', 'ä¸ç¡®å®š', 'è§£æå¤±è´¥'] and clean_tag not in clean_tags:
                        clean_tags.append(clean_tag)
            
            merged_result['all_tags'] = clean_tags
            
            # ğŸ”§ å…¶ä»–å¿…éœ€å­—æ®µ
            merged_result['success'] = True
            merged_result['analysis_method'] = 'visual_audio_fusion'
            merged_result['transcription'] = audio_result.get('transcription', '')
            
            logger.info(f"ğŸ¯ğŸ¤ è§†è§‰+è¯­éŸ³èåˆå®Œæˆ")
            logger.info(f"   ç‰©ä½“: {merged_result['object']}")
            logger.info(f"   åœºæ™¯: {merged_result['scene']}")
            logger.info(f"   æƒ…ç»ª: {merged_result['emotion']}")
            logger.info(f"   å“ç‰Œ: {merged_result['brand_elements']}")
            logger.info(f"   è´¨é‡åˆ†: {merged_result['quality_score']}")
            logger.info(f"   æ ‡ç­¾æ•°: {len(merged_result['all_tags'])}")
            
            return merged_result
            
        except Exception as e:
            logger.error(f"ç»“æœèåˆå¤±è´¥: {str(e)}")
            # å¦‚æœèåˆå¤±è´¥ï¼Œè¿”å›éŸ³é¢‘ç»“æœï¼ˆé€šå¸¸æ›´å¯é ï¼‰
            fallback_result = audio_result if audio_result.get('success') else visual_result
            fallback_result['analysis_method'] = 'fallback_audio' if audio_result.get('success') else 'fallback_visual'
            return fallback_result 
    
    def _detect_face_close_up(self, analysis_result: Dict[str, Any], video_path: str) -> bool:
        """
        ğŸ¯ æ£€æµ‹äººè„¸ç‰¹å†™ç‰‡æ®µ
        
        Args:
            analysis_result: è§†è§‰åˆ†æç»“æœ
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦ä¸ºäººè„¸ç‰¹å†™ç‰‡æ®µ
        """
        try:
            # åŠ è½½é…ç½®
            try:
                from config.factory_config import VISUAL_ANALYSIS_CONFIG
                detection_config = VISUAL_ANALYSIS_CONFIG.get("face_close_up_detection", {})
                
                # æ£€æŸ¥æ˜¯å¦å¯ç”¨äººè„¸ç‰¹å†™æ£€æµ‹
                if not detection_config.get("enabled", True):
                    return False
                
                face_close_up_indicators = detection_config.get("keywords", [
                    'äººè„¸', 'é¢éƒ¨', 'å¤´åƒ', 'ç‰¹å†™', 'è‚–åƒ', 'è„¸éƒ¨',
                    'çœ¼ç›', 'å˜´å”‡', 'é¼»å­', 'é¢å­”', 'å¤´éƒ¨ç‰¹å†™'
                ])
                face_area_threshold = detection_config.get("face_area_threshold", 0.3)
                
            except ImportError:
                # é…ç½®ä¸å¯ç”¨æ—¶ä½¿ç”¨é»˜è®¤å€¼
                face_close_up_indicators = [
                    'äººè„¸', 'é¢éƒ¨', 'å¤´åƒ', 'ç‰¹å†™', 'è‚–åƒ', 'è„¸éƒ¨',
                    'çœ¼ç›', 'å˜´å”‡', 'é¼»å­', 'é¢å­”', 'å¤´éƒ¨ç‰¹å†™'
                ]
                face_area_threshold = 0.3
            
            # æ–¹æ³•1: åŸºäºæ ‡ç­¾å†…å®¹æ£€æµ‹
            all_tags = analysis_result.get('all_tags', [])
            object_tags = analysis_result.get('object', '')
            scene_tags = analysis_result.get('scene', '')
            
            # æ£€æŸ¥æ ‡ç­¾æ˜¯å¦ä¸»è¦åŒ…å«äººè„¸ç‰¹å†™ç›¸å…³å†…å®¹
            all_text = f"{' '.join(all_tags)} {object_tags} {scene_tags}".lower()
            
            face_indicators_count = 0
            for indicator in face_close_up_indicators:
                if indicator in all_text:
                    face_indicators_count += 1
            
            # æ£€æŸ¥åœºæ™¯ç¼ºå¤±æƒ…å†µï¼ˆäººè„¸ç‰¹å†™é€šå¸¸ç¼ºä¹åœºæ™¯ä¿¡æ¯ï¼‰
            scene_missing = not scene_tags or scene_tags in ['', 'æ— ', 'ä¸ç¡®å®š']
            
            # æ£€æŸ¥ç‰©ä½“æ ‡ç­¾æ˜¯å¦ä¸»è¦æ˜¯äººè„¸ç›¸å…³
            face_dominant = face_indicators_count >= 2 and scene_missing
            
            if face_dominant:
                logger.info(f"ğŸš« åŸºäºæ ‡ç­¾æ£€æµ‹åˆ°äººè„¸ç‰¹å†™: äººè„¸æŒ‡æ ‡{face_indicators_count}ä¸ªï¼Œåœºæ™¯ç¼ºå¤±: {scene_missing}")
                return True
            
            # æ–¹æ³•2: åŸºäºç”»é¢åˆ†ææ£€æµ‹ï¼ˆå¯å‘å¼è§„åˆ™ï¼‰
            # å¦‚æœç‰©ä½“æ ‡ç­¾å¾ˆå°‘ä¸”ä¸»è¦æ˜¯äººç›¸å…³ï¼Œè€Œåœºæ™¯ä¸ºç©ºï¼Œå¯èƒ½æ˜¯ç‰¹å†™
            objects = object_tags.split(',') if object_tags else []
            person_related = ['äºº', 'å¦ˆå¦ˆ', 'å®å®', 'å©´å„¿', 'æ¯äº²', 'çˆ¶äº²', 'å®¶é•¿']
            
            if len(objects) <= 2 and scene_missing:
                person_objects = [obj for obj in objects if any(pr in obj for pr in person_related)]
                if len(person_objects) >= len(objects) * 0.8:  # 80%ä»¥ä¸Šæ˜¯äººç›¸å…³
                    logger.info(f"ğŸš« åŸºäºç‰©ä½“-åœºæ™¯æ¯”ä¾‹æ£€æµ‹åˆ°äººè„¸ç‰¹å†™: äººç‰©å¯¹è±¡{len(person_objects)}/{len(objects)}")
                    return True
            
            # æ–¹æ³•3: åŸºäºè§†é¢‘å¸§æ£€æµ‹ï¼ˆå¯é€‰ï¼Œéœ€è¦OpenCVï¼‰
            frame_based_detection = self._detect_face_close_up_by_frames(video_path, face_area_threshold)
            if frame_based_detection:
                logger.info(f"ğŸš« åŸºäºè§†é¢‘å¸§æ£€æµ‹åˆ°äººè„¸ç‰¹å†™")
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"äººè„¸ç‰¹å†™æ£€æµ‹å¤±è´¥: {str(e)}")
            return False
    
    def _detect_face_close_up_by_frames(self, video_path: str, face_area_threshold: float = 0.3) -> bool:
        """
        ğŸ¯ åŸºäºè§†é¢‘å¸§çš„äººè„¸ç‰¹å†™æ£€æµ‹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦æ£€æµ‹åˆ°äººè„¸ç‰¹å†™
        """
        try:
            import cv2
            
            # æ‰“å¼€è§†é¢‘
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return False
            
            # è·å–è§†é¢‘åŸºæœ¬ä¿¡æ¯
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = frame_count / fps if fps > 0 else 0
            
            # å¦‚æœè§†é¢‘å¤ªçŸ­æˆ–å¤ªé•¿ï¼Œè·³è¿‡å¸§çº§æ£€æµ‹
            if duration < 1 or duration > 30:
                cap.release()
                return False
            
            # é‡‡æ ·å‡ å¸§è¿›è¡Œæ£€æµ‹
            sample_frames = min(3, frame_count // 10)  # æœ€å¤šé‡‡æ ·3å¸§
            frame_indices = [i * frame_count // (sample_frames + 1) for i in range(1, sample_frames + 1)]
            
            face_frames = 0
            total_frames_checked = 0
            
            for frame_idx in frame_indices:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()
                
                if not ret:
                    continue
                
                total_frames_checked += 1
                
                # ç®€å•çš„äººè„¸æ£€æµ‹ï¼ˆåŸºäºé¢ç§¯å æ¯”ï¼‰
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                height, width = gray.shape
                
                try:
                    # ä½¿ç”¨OpenCVçš„äººè„¸æ£€æµ‹å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
                    faces = face_cascade.detectMultiScale(gray, 1.1, 4)
                    
                    # å¦‚æœæ£€æµ‹åˆ°äººè„¸ä¸”å æ¯”è¾ƒå¤§ï¼Œå¯èƒ½æ˜¯ç‰¹å†™
                    for (x, y, w, h) in faces:
                        face_area = w * h
                        frame_area = width * height
                        face_ratio = face_area / frame_area
                        
                        # å¦‚æœäººè„¸å ç”»é¢è¾¾åˆ°é…ç½®é˜ˆå€¼ä»¥ä¸Šï¼Œè®¤ä¸ºæ˜¯ç‰¹å†™
                        if face_ratio > face_area_threshold:
                            face_frames += 1
                            break
                            
                except Exception:
                    # å¦‚æœäººè„¸æ£€æµ‹å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å¯å‘å¼æ–¹æ³•
                    # æ£€æŸ¥ç”»é¢ä¸­å¤®åŒºåŸŸçš„å˜åŒ–
                    center_region = gray[height//4:3*height//4, width//4:3*width//4]
                    if center_region.std() > 50:  # ä¸­å¤®åŒºåŸŸå˜åŒ–è¾ƒå¤§ï¼Œå¯èƒ½æœ‰äººè„¸
                        face_frames += 1
            
            cap.release()
            
            # å¦‚æœä¸€åŠä»¥ä¸Šçš„å¸§éƒ½æ£€æµ‹åˆ°ç–‘ä¼¼äººè„¸ç‰¹å†™
            if total_frames_checked > 0 and face_frames / total_frames_checked >= 0.5:
                return True
            
            return False
            
        except Exception as e:
            logger.warning(f"åŸºäºå¸§çš„äººè„¸æ£€æµ‹å¤±è´¥: {str(e)}")
            return False
    
    def _optimize_for_short_video(self, video_path: str, original_frame_rate: float) -> Dict[str, Any]:
        """
        ğŸ¯ çŸ­è§†é¢‘æ™ºèƒ½ä¼˜åŒ–ï¼šæ ¹æ®æ–‡ä»¶å¤§å°å’Œæ—¶é•¿åŠ¨æ€è°ƒæ•´åˆ†æå‚æ•°
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            original_frame_rate: åŸå§‹å¸§ç‡
            
        Returns:
            ä¼˜åŒ–åçš„åˆ†æå‚æ•°
        """
        try:
            # è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰
            file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
            
            # ğŸ¯ è¿‡æ»¤è¿‡å°æ–‡ä»¶
            if file_size_mb < self.short_video_config['min_file_size_mb']:
                logger.info(f"ğŸš« æ–‡ä»¶è¿‡å°ï¼Œè·³è¿‡å¤„ç†: {file_size_mb:.2f}MB < {self.short_video_config['min_file_size_mb']}MB")
                return {
                    "frame_rate": 0,
                    "quality_threshold": 0,
                    "should_skip": True,
                    "reason": "æ–‡ä»¶è¿‡å°"
                }
            
            # è·å–è§†é¢‘æ—¶é•¿
            video_info = self._extract_video_info(video_path)
            duration_sec = video_info.get('duration', 0)
            
            # åˆå§‹åŒ–ä¼˜åŒ–å‚æ•°
            optimized_frame_rate = original_frame_rate
            optimized_quality_threshold = self.quality_config['min_quality_threshold']
            
            # åˆ¤æ–­æ˜¯å¦éœ€è¦ä¼˜åŒ–
            is_small_file = file_size_mb < self.short_video_config['file_size_threshold_mb']
            is_short_duration = duration_sec < self.short_video_config['duration_threshold_sec']
            
            if is_small_file or is_short_duration:
                # çŸ­è§†é¢‘ä¼˜åŒ–ç­–ç•¥
                optimized_frame_rate = min(
                    original_frame_rate * self.short_video_config['frame_rate_boost'],
                    self.short_video_config['max_frame_rate']
                )
                optimized_quality_threshold = max(
                    self.quality_config['min_quality_threshold'] - self.short_video_config['quality_threshold_reduction'],
                    0.3
                )
                
                logger.info(f"âš¡ çŸ­è§†é¢‘ä¼˜åŒ–: {file_size_mb:.2f}MB, {duration_sec:.1f}s -> å¸§ç‡{optimized_frame_rate:.1f}, è´¨é‡é˜ˆå€¼{optimized_quality_threshold:.2f}")
            
            return {
                "frame_rate": optimized_frame_rate,
                "quality_threshold": optimized_quality_threshold,
                "should_skip": False,
                "optimization_applied": is_small_file or is_short_duration,
                "file_size_mb": file_size_mb,
                "duration_sec": duration_sec
            }
            
        except Exception as e:
            logger.error(f"çŸ­è§†é¢‘ä¼˜åŒ–å¤±è´¥: {e}")
            return {
                "frame_rate": original_frame_rate,
                "quality_threshold": self.quality_config['min_quality_threshold'],
                "should_skip": False,
                "optimization_applied": False
            }
    
    def _apply_negative_keywords_filter(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ğŸ›¡ï¸ å‡çº§ç‰ˆåå¹»è§‰æœºåˆ¶ï¼šå“ç‰Œæ„ŸçŸ¥çš„æ™ºèƒ½è¿‡æ»¤
        
        æ ¸å¿ƒç­–ç•¥ï¼š
        1. æœ‰å“ç‰Œæ ‡è¯† + å¥¶ç²‰ç›¸å…³ = çœŸå®äº§å“ï¼Œä¿ç•™ä½†é™ä½ç½®ä¿¡åº¦
        2. æ— å“ç‰Œæ ‡è¯† + å¥¶ç²‰ç›¸å…³ + è´Ÿé¢åœºæ™¯ = å¯èƒ½è¯¯è¯†åˆ«ï¼Œç§»é™¤
        3. ç©å…·/æ¸¸ä¹åœºæ™¯ + æ— å“ç‰Œ = å®Œå…¨ç§»é™¤å¥¶ç²‰æ ‡ç­¾
        
        Args:
            result: è§†è§‰åˆ†æç»“æœ
            
        Returns:
            æ™ºèƒ½è¿‡æ»¤åçš„ç»“æœ
        """
        try:
            # è·å–è´Ÿé¢å…³é”®è¯é…ç½®
            config_manager = get_config_manager()
            keywords_config = config_manager.get_keywords_config()
            
            # æå–æ ¸å¿ƒä¿¡æ¯
            brand_elements = str(result.get('brand_elements', '')).strip()
            object_content = str(result.get('object', '')).strip()
            scene_content = str(result.get('scene', '')).strip()
            
            # ğŸ” åˆ¤æ–­æ˜¯å¦æœ‰æ˜ç¡®å“ç‰Œæ ‡è¯†
            has_brand = bool(brand_elements)
            known_brands = ['å¯èµ‹', 'illuma', 'A2', 'Wyeth', 'æƒ æ°', 'HMO', 'DHA']
            has_known_brand = any(brand in brand_elements for brand in known_brands) if has_brand else False
            
            # ğŸ” æ”¶é›†æ‰€æœ‰åˆ†ææ–‡æœ¬ç”¨äºè´Ÿé¢å…³é”®è¯æ£€æµ‹
            all_analysis_text = f"{object_content} {scene_content}".lower()
            
            # ğŸ” æ£€æµ‹è´Ÿé¢åœºæ™¯å…³é”®è¯
            features_negatives = keywords_config.get('features_formula', {}).get('negative_keywords', [])
            detected_negatives = []
            for negative_word in features_negatives:
                if negative_word in all_analysis_text:
                    detected_negatives.append(negative_word)
            
            # ğŸ” è¯†åˆ«å¥¶ç²‰ç›¸å…³æ ‡ç­¾
            milk_related_keywords = ['å¥¶ç²‰', 'å¥¶ç“¶', 'å¥¶ç²‰ç½', 'é…æ–¹å¥¶', 'é…æ–¹', 'å¥¶ç²‰å‹º']
            has_milk_objects = any(milk_keyword in object_content for milk_keyword in milk_related_keywords)
            
            # ğŸ” è¯†åˆ«é«˜é£é™©è´Ÿé¢åœºæ™¯ï¼ˆç»å¯¹ä¸åº”è¯¥æœ‰å¥¶ç²‰çš„åœºæ™¯ï¼‰
            high_risk_negatives = ['ç©å…·', 'æ»‘æ¢¯', 'æ¸¸ä¹åœº', 'å•†åœº', 'å¨±ä¹', 'å…¬å›­', 'æˆ·å¤–']
            has_high_risk_scene = any(neg in detected_negatives for neg in high_risk_negatives)
            
            # ğŸ” è¯†åˆ«ä¸­ç­‰é£é™©è´Ÿé¢åœºæ™¯ï¼ˆå¯èƒ½æœ‰å¥¶ç²‰ä½†éœ€è¦è°¨æ…çš„åœºæ™¯ï¼‰
            medium_risk_negatives = ['è´­ç‰©', 'è¿åŠ¨', 'è·‘æ­¥', 'æ•£æ­¥', 'çˆ¬è¡Œ', 'è·³è·ƒ']
            has_medium_risk_scene = any(neg in detected_negatives for neg in medium_risk_negatives)
            
            # ğŸ§  æ™ºèƒ½å†³ç­–é€»è¾‘
            if detected_negatives and has_milk_objects:
                filter_action = self._decide_filter_action(
                    has_brand=has_brand,
                    has_known_brand=has_known_brand,
                    has_high_risk_scene=has_high_risk_scene,
                    has_medium_risk_scene=has_medium_risk_scene,
                    detected_negatives=detected_negatives
                )
                
                logger.info(f"ğŸ§  æ™ºèƒ½è¿‡æ»¤å†³ç­–: {filter_action['action']} (åŸå› : {filter_action['reason']})")
                
                # æ‰§è¡Œè¿‡æ»¤åŠ¨ä½œ
                result = self._execute_filter_action(result, filter_action, detected_negatives)
            
            return result
            
        except Exception as e:
            logger.error(f"åº”ç”¨æ™ºèƒ½åå¹»è§‰è¿‡æ»¤å¤±è´¥: {e}")
            return result
    
    def _decide_filter_action(self, has_brand: bool, has_known_brand: bool, 
                            has_high_risk_scene: bool, has_medium_risk_scene: bool,
                            detected_negatives: List[str]) -> Dict[str, str]:
        """
        ğŸ§  æ™ºèƒ½å†³ç­–ï¼šæ ¹æ®å“ç‰Œå’Œåœºæ™¯ä¿¡æ¯å†³å®šè¿‡æ»¤ç­–ç•¥
        
        Returns:
            Dict with 'action' and 'reason' keys
        """
        
        # ğŸš¨ é«˜é£é™©åœºæ™¯ï¼šç©å…·ã€æ¸¸ä¹åœºç­‰ï¼Œæ— è®ºæ˜¯å¦æœ‰å“ç‰Œéƒ½è¦è¿‡æ»¤
        if has_high_risk_scene:
            if has_known_brand:
                return {
                    'action': 'reduce_confidence',
                    'reason': f'é«˜é£é™©åœºæ™¯ä½†æœ‰çŸ¥åå“ç‰Œ({detected_negatives})'
                }
            else:
                return {
                    'action': 'remove_objects',
                    'reason': f'é«˜é£é™©åœºæ™¯ä¸”æ— å“ç‰Œæ ‡è¯†({detected_negatives})'
                }
        
        # âš ï¸ ä¸­ç­‰é£é™©åœºæ™¯ï¼šæ ¹æ®å“ç‰Œä¿¡æ¯å†³ç­–
        elif has_medium_risk_scene:
            if has_known_brand:
                return {
                    'action': 'keep_with_note',
                    'reason': f'ä¸­ç­‰é£é™©åœºæ™¯ä½†æœ‰çŸ¥åå“ç‰Œ({detected_negatives})'
                }
            else:
                return {
                    'action': 'reduce_confidence',
                    'reason': f'ä¸­ç­‰é£é™©åœºæ™¯ä¸”æ— æ˜ç¡®å“ç‰Œ({detected_negatives})'
                }
        
        # ğŸ” ä½é£é™©åœºæ™¯ï¼šæœ‰è´Ÿé¢å…³é”®è¯ä½†é£é™©è¾ƒä½
        else:
            if has_brand:
                return {
                    'action': 'keep_with_note',
                    'reason': f'ä½é£é™©åœºæ™¯ä¸”æœ‰å“ç‰Œæ ‡è¯†({detected_negatives})'
                }
            else:
                return {
                    'action': 'reduce_confidence',
                    'reason': f'ä½é£é™©åœºæ™¯ä½†æ— å“ç‰Œç¡®è®¤({detected_negatives})'
                }
    
    def _execute_filter_action(self, result: Dict[str, Any], filter_action: Dict[str, str], 
                             detected_negatives: List[str]) -> Dict[str, Any]:
        """
        ğŸ¯ æ‰§è¡Œè¿‡æ»¤åŠ¨ä½œ
        """
        action = filter_action['action']
        reason = filter_action['reason']
        
        if action == 'remove_objects':
            # å®Œå…¨ç§»é™¤å¥¶ç²‰ç›¸å…³æ ‡ç­¾
            result = self._remove_milk_related_objects(result)
            result['anti_hallucination'] = {
                'action': 'objects_removed',
                'reason': reason,
                'detected_negatives': detected_negatives
            }
            logger.info(f"ğŸš« å·²ç§»é™¤å¥¶ç²‰ç›¸å…³æ ‡ç­¾: {reason}")
            
        elif action == 'reduce_confidence':
            # é™ä½ç½®ä¿¡åº¦ä½†ä¿ç•™æ ‡ç­¾
            original_confidence = result.get('confidence', 0.8)
            result['confidence'] = max(0.4, original_confidence - 0.3)
            result['anti_hallucination'] = {
                'action': 'confidence_reduced',
                'reason': reason,
                'detected_negatives': detected_negatives,
                'original_confidence': original_confidence
            }
            logger.info(f"âš ï¸ å·²é™ä½ç½®ä¿¡åº¦: {original_confidence:.2f} â†’ {result['confidence']:.2f}")
            
        elif action == 'keep_with_note':
            # ä¿ç•™ä½†æ·»åŠ å¤‡æ³¨
            result['anti_hallucination'] = {
                'action': 'kept_with_note',
                'reason': reason,
                'detected_negatives': detected_negatives,
                'note': 'æœ‰å“ç‰Œæ ‡è¯†æ”¯æŒï¼Œä¿ç•™ä½†éœ€äººå·¥ç¡®è®¤'
            }
            logger.info(f"âœ… ä¿ç•™æ ‡ç­¾ä½†æ·»åŠ å¤‡æ³¨: {reason}")
        
        return result
    
    def _remove_milk_related_objects(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä»objectå­—æ®µä¸­ç§»é™¤å¥¶åˆ¶å“ç›¸å…³çš„å…³é”®è¯
        """
        try:
            object_value = result.get('object', '')
            if not object_value:
                return result
            
            # å¥¶åˆ¶å“ç›¸å…³å…³é”®è¯
            milk_keywords = ['å¥¶ç²‰ç½', 'å¥¶ç“¶', 'å¥¶ç²‰', 'å¥¶åˆ¶å“', 'é…æ–¹å¥¶', 'æ¯ä¹³', 'ç‰›å¥¶', 'å¥¶ç²‰åŒ…è£…']
            
            # åˆ†å‰²å¹¶è¿‡æ»¤
            object_list = [obj.strip() for obj in str(object_value).split(',') if obj.strip()]
            filtered_objects = [obj for obj in object_list if not any(keyword in obj for keyword in milk_keywords)]
            
            result['object'] = ','.join(filtered_objects) if filtered_objects else ''
            
            if filtered_objects != object_list:
                logger.info(f"å·²ç§»é™¤å¥¶åˆ¶å“ç›¸å…³ç‰©ä½“: {[obj for obj in object_list if obj not in filtered_objects]}")
            
            return result
            
        except Exception as e:
            logger.error(f"ç§»é™¤å¥¶åˆ¶å“ç›¸å…³ç‰©ä½“æ—¶å‡ºé”™: {e}")
            return result

    # ===============================
    # åŒæ¨¡å‹åˆ†å·¥æœºåˆ¶ - æ–°å¢æ–¹æ³•
    # ===============================

    def _build_general_detection_prompt(self, tag_language: str) -> str:
        """
        æ„å»ºAI-Bé€šç”¨æ£€æµ‹promptï¼Œä¸“æ³¨"è¡Œä¸º/äº¤äº’"è¯†åˆ«
        """
        try:
            from utils.keyword_config import get_visual_objects, get_scenes, get_emotions
            
            objects = get_visual_objects()[:15]  # å–å‰15ä¸ªå¸¸è§ç‰©ä½“
            scenes = get_scenes()[:10]   # å–å‰10ä¸ªå¸¸è§åœºæ™¯
            emotions = get_emotions()[:6]  # å–å‰6ä¸ªæƒ…ç»ª
            
            # ç¡®ä¿æœ‰é»˜è®¤å€¼
            if not objects: objects = ["å®å®", "ç©å…·", "é¤å…·", "è¡£æœ"]
            if not scenes: scenes = ["å®¤å†…", "å®¶ä¸­å§å®¤", "å®¢å…"]
            if not emotions: emotions = ["å¼€å¿ƒ", "æ¸©é¦¨", "å¹³é™"]
            
            return f"""ğŸ¯ ä½ æ˜¯ä¸“ä¸šçš„è§†é¢‘å†…å®¹åˆ†æå¸ˆï¼Œè¯·å°†ç”»é¢å†…å®¹æè¿°ä¸º"è¡Œä¸º/äº¤äº’"çŸ­å¥ã€‚

**é‡è¦ï¼šæœ¬æ¬¡åˆ†æä¸æ¶‰åŠä»»ä½•å“ç‰Œè¯†åˆ«ï¼Œè¯·ä¸“æ³¨äºä»¥ä¸‹ä¸‰ä¸ªç»´åº¦ï¼š**

1. **interactionï¼ˆè¡Œä¸º/äº¤äº’ï¼‰**: **æ ¸å¿ƒä»»åŠ¡**ï¼Œç”¨"ä¸»è¯­+åŠ¨è¯+å®¾è¯­"çš„æ ¼å¼æè¿°ç”»é¢ä¸­çš„æ ¸å¿ƒäº‹ä»¶ã€‚
   - **ä¼˜ç§€ç¤ºä¾‹**: "å®å®å¼€å¿ƒå–å¥¶", "å¦ˆå¦ˆå†²æ³¡å¥¶ç²‰", "å®å®æ‹’ç»å¥¶ç“¶", "åŒ»ç”Ÿæ¨èäº§å“", "å®å®çš®è‚¤æ³›çº¢"
   - **é¿å…**: "å®å®, å¥¶ç“¶" (è¿‡äºå­¤ç«‹)

2. **sceneï¼ˆåœºæ™¯è¯†åˆ«ï¼‰**: å®¢è§‚æè¿°ç”»é¢å‘ç”Ÿçš„åœºæ™¯ç¯å¢ƒ
   - å‚è€ƒè¯æ±‡ï¼š{', '.join(scenes)}

3. **emotionï¼ˆæƒ…ç»ªè¯†åˆ«ï¼‰**: åˆ†æå¹¶æç‚¼å‡ºç”»é¢ä¸­æœ€æ ¸å¿ƒã€æœ€å…³é”®çš„ä¸€ä¸ªæƒ…ç»ªè¯ã€‚
   - å‚è€ƒè¯æ±‡ï¼š{', '.join(emotions)}

**è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼éµå¾ªï¼‰ï¼š**
interaction: è¡Œä¸º/äº¤äº’çŸ­å¥
scene: åœºæ™¯æè¿°(å¯å«é€—å·)
emotion: å•ä¸ªå…³é”®è¯"""

        except Exception as e:
            logger.warning(f"æ„å»ºé€šç”¨æ£€æµ‹promptå¤±è´¥ï¼Œä½¿ç”¨å…œåº•ç‰ˆæœ¬: {e}")
            return """è¯·å°†ç”»é¢å†…å®¹æè¿°ä¸º"è¡Œä¸º/äº¤äº’"çŸ­å¥ã€‚
è¾“å‡ºæ ¼å¼ï¼š
interaction: è¡Œä¸º/äº¤äº’çŸ­å¥
scene: åœºæ™¯1,åœºæ™¯2
emotion: æƒ…ç»ª1,æƒ…ç»ª2"""

    def _should_trigger_brand_detection(self, general_analysis: Dict[str, Any]) -> bool:
        """
        åˆ¤æ–­æ˜¯å¦éœ€è¦è§¦å‘å“ç‰Œæ£€æµ‹ï¼ˆAI-Aï¼‰ï¼ŒåŸºäºinteractionå­—æ®µ
        """
        # ğŸ”§ ä»é…ç½®æ–‡ä»¶è¯»å–è§¦å‘å…³é”®è¯
        try:
            config_manager = get_config_manager()
            keywords_config = config_manager.get_keywords_config()
            product_keywords = keywords_config.get('ai_brand_detection', {}).get('trigger_keywords', [])
            
            # å¦‚æœé…ç½®ä¸ºç©ºï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯ä½œä¸ºå…œåº•
            if not product_keywords:
                logger.warning("æœªæ‰¾åˆ°ai_brand_detection.trigger_keywordsé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯")
                product_keywords = [
                    # è¡Œä¸º/äº’åŠ¨ç›¸å…³
                    'ç½', 'äº§å“', 'å–‚å…»', 'å–', 'å†²æ³¡', 'æ…æ‹Œ',
                    # ä¼ ç»Ÿç‰©ä½“ç›¸å…³
                    'å¥¶ç²‰ç½', 'å¥¶ç“¶', 'å¥¶ç²‰', 'é…æ–¹å¥¶', 'å©´å„¿å¥¶ç²‰',
                    'å¥¶ç²‰åŒ…è£…', 'å¥¶ç²‰ç½ç‰¹å†™', 'æˆåˆ†è¡¨', 'é…æ–™è¡¨',
                    'è¥å…»æˆåˆ†', 'äº§å“åŒ…è£…', 'åŒ…è£…ç›’'
                ]
            else:
                logger.info(f"ä»é…ç½®æ–‡ä»¶åŠ è½½å“ç‰Œæ£€æµ‹è§¦å‘å…³é”®è¯: {product_keywords}")
                
        except Exception as e:
            logger.error(f"è¯»å–å“ç‰Œæ£€æµ‹é…ç½®å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å…³é”®è¯")
            product_keywords = [
                'ç½', 'äº§å“', 'å–‚å…»', 'å–', 'å†²æ³¡', 'æ…æ‹Œ',
                'å¥¶ç²‰ç½', 'å¥¶ç“¶', 'å¥¶ç²‰', 'é…æ–¹å¥¶', 'å©´å„¿å¥¶ç²‰',
                'å¥¶ç²‰åŒ…è£…', 'å¥¶ç²‰ç½ç‰¹å†™', 'æˆåˆ†è¡¨', 'é…æ–™è¡¨',
                'è¥å…»æˆåˆ†', 'äº§å“åŒ…è£…', 'åŒ…è£…ç›’'
            ]

        # æ£€æŸ¥interactionå’Œsceneå­—æ®µ
        interaction_text = str(general_analysis.get('interaction', '')).lower()
        object_text = str(general_analysis.get('object', '')).lower() # å…¼å®¹æ—§ç‰ˆobjectå­—æ®µ
        scene_text = str(general_analysis.get('scene', '')).lower()

        # ç»„åˆæ‰€æœ‰å¯èƒ½çš„æ–‡æœ¬æ¥æº
        combined_text = f"{interaction_text} {object_text} {scene_text}"

        for keyword in product_keywords:
            if keyword in combined_text:
                logger.info(f"è§¦å‘å“ç‰Œæ£€æµ‹ï¼šæ£€æµ‹åˆ°å…³é”®è¯ '{keyword}' (æ¥æº: é…ç½®æ–‡ä»¶)")
                return True

        return False

    def _detect_core_brands(self, video_path: str, frame_rate: float) -> str:
        """
        AI-Aä¸“ç”¨æ ¸å¿ƒå“ç‰Œæ£€æµ‹ï¼ˆæ–°å¢éŸ³é¢‘å…œåº•æœºåˆ¶ï¼‰
        """
        # 1. ä¼˜å…ˆå°è¯•è§†è§‰æ£€æµ‹
        try:
            brand_prompt = self._build_brand_detection_prompt()
            logger.info("ğŸ•µï¸â€â™‚ï¸ [ä¾¦æŸ¥æ—¥å¿—] ====== å“ç‰Œæ£€æµ‹é˜¶æ®µ (AI-A) - è§†è§‰ ======")
            logger.info(f"   - ä½¿ç”¨çš„Prompt: {brand_prompt}")
            
            result = self._analyze_video_file(video_path, frame_rate, brand_prompt)

            if result and 'analysis' in result:
                analysis_text = result['analysis']
                logger.info(f"   - å“ç‰Œæ£€æµ‹AIåŸå§‹è¿”å›: '{analysis_text}'")

                # å¦‚æœAIæ˜ç¡®è¿”å›"æ— "ï¼Œåˆ™è®¤ä¸ºè§†è§‰æ£€æµ‹å·²ç¡®è®¤æ— å“ç‰Œï¼Œæ— éœ€éŸ³é¢‘å…œåº•
                if any(neg in analysis_text for neg in ["æ— ", "æœªæ£€æµ‹åˆ°", "ä¸åŒ…å«", "æ²¡æœ‰"]):
                    logger.info("   - [ç»“è®º] è§†è§‰å“ç‰Œæ£€æµ‹æ¨¡å‹æ˜ç¡®è¿”å›æœªæ£€æµ‹åˆ°å“ç‰Œã€‚")
                    logger.info("ğŸ•µï¸â€â™‚ï¸ =======================================")
                    return ""

                config_manager = get_config_manager()
                keywords_config = config_manager.get_keywords_config()
                core_brands = keywords_config.get('ai_brand_detection', {}).get('core_brands', [])
                if not core_brands: core_brands = ['å¯èµ‹', 'illuma', 'æƒ æ°', 'Wyeth', 'è•´æ·³', 'A2', 'ATWO', 'HMO']
                logger.info(f"   - æ ¸å¿ƒå“ç‰Œåˆ—è¡¨: {core_brands}")
                
                found_brands = []
                for brand in core_brands:
                    if re.search(r'\b' + re.escape(brand) + r'\b', analysis_text, re.IGNORECASE):
                        found_brands.append(brand)
                
                if found_brands:
                    detected_brands_str = ','.join(list(dict.fromkeys(found_brands)))
                    logger.info(f"   - [ç»“è®º] âœ… è§†è§‰æ ¸å¿ƒå“ç‰Œæ£€æµ‹æˆåŠŸ: {detected_brands_str}")
                    logger.info("ğŸ•µï¸â€â™‚ï¸ =======================================")
                    return detected_brands_str
                else:
                    logger.info("   - [ç»“è®º] è§†è§‰å“ç‰Œæ£€æµ‹æœªè¿”å›æ ¸å¿ƒå“ç‰Œï¼Œå‡†å¤‡å°è¯•éŸ³é¢‘å…œåº•ã€‚")

        except Exception as e:
            logger.warning(f"è§†è§‰å“ç‰Œæ£€æµ‹å¤±è´¥: {e}, å°è¯•éŸ³é¢‘å…œåº•")

        # 2. å¦‚æœè§†è§‰æ£€æµ‹å¤±è´¥æˆ–æœªæ‰¾åˆ°ï¼Œå°è¯•éŸ³é¢‘å…œåº•
        logger.info("ğŸ¤ [ä¾¦æŸ¥æ—¥å¿—] ====== å“ç‰Œæ£€æµ‹é˜¶æ®µ (AI-A) - éŸ³é¢‘å…œåº• ======")
        try:
            transcription = self._extract_and_transcribe_audio(video_path)
            if not transcription:
                logger.info("   - éŸ³é¢‘è½¬å½•ç»“æœä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œå“ç‰Œæ£€æµ‹ã€‚")
                logger.info("ğŸ¤ =======================================")
                return ""

            logger.info(f"   - éŸ³é¢‘è½¬å½•å†…å®¹(ç‰‡æ®µ): '{transcription[:100]}...'")

            config_manager = get_config_manager()
            keywords_config = config_manager.get_keywords_config()
            core_brands = keywords_config.get('ai_brand_detection', {}).get('core_brands', [])
            if not core_brands: core_brands = ['å¯èµ‹', 'illuma', 'æƒ æ°', 'Wyeth', 'è•´æ·³', 'A2', 'ATWO', 'HMO']
            
            found_brands = []
            for brand in core_brands:
                if re.search(r'\b' + re.escape(brand) + r'\b', transcription, re.IGNORECASE):
                    found_brands.append(brand)
            
            if found_brands:
                detected_brands_str = ','.join(list(dict.fromkeys(found_brands)))
                logger.info(f"   - [ç»“è®º] âœ… éŸ³é¢‘å…œåº•æ ¸å¿ƒå“ç‰Œæ£€æµ‹æˆåŠŸ: {detected_brands_str}")
                logger.info("ğŸ¤ =======================================")
                return detected_brands_str
            else:
                logger.info("   - [ç»“è®º] ğŸ” éŸ³é¢‘è½¬å½•ä¸­æœªå‘ç°æ ¸å¿ƒå“ç‰Œã€‚")
                logger.info("ğŸ¤ =======================================")
                return ""

        except Exception as e:
            logger.error(f"å“ç‰Œæ£€æµ‹çš„éŸ³é¢‘å…œåº•å¤±è´¥: {e}")
            logger.info("ğŸ¤ =======================================")
            return ""

    def _build_brand_detection_prompt(self) -> str:
        """
        æ„å»ºAI-Aä¸“ç”¨çš„æ ¸å¿ƒå“ç‰Œæ£€æµ‹prompt
        """
        try:
            config_manager = get_config_manager()
            keywords_config = config_manager.get_keywords_config()
            core_brands = keywords_config.get('ai_brand_detection', {}).get('core_brands', [])

            if not core_brands:
                logger.error("æ ¸å¿ƒå“ç‰Œåˆ—è¡¨(core_brands)æœªé…ç½®ï¼Œä½¿ç”¨é»˜è®¤åˆ—è¡¨è¿›è¡Œå“ç‰Œæ£€æµ‹ã€‚")
                core_brands = ['å¯èµ‹', 'illuma', 'æƒ æ°', 'Wyeth', 'è•´æ·³', 'A2', 'ATWO', 'HMO']

            brand_list_str = ", ".join(core_brands)
            return f"""ğŸ” ä½ æ˜¯å“ç‰Œè¯†åˆ«ä¸“å®¶ï¼Œè¯·ä¸¥æ ¼æŒ‰ç…§æä¾›çš„å“ç‰Œåˆ—è¡¨æ£€æŸ¥ç”»é¢ã€‚

# **æ ¸å¿ƒä»»åŠ¡**
ä½ çš„å”¯ä¸€ä»»åŠ¡æ˜¯è¯†åˆ«ç”»é¢ä¸­æ˜¯å¦æ¸…æ™°å‡ºç°äº†ä»¥ä¸‹ **æ ¸å¿ƒå“ç‰Œåˆ—è¡¨** ä¸­çš„ä»»ä½•ä¸€ä¸ªå“ç‰Œæ ‡è¯†ã€‚

# **æ ¸å¿ƒå“ç‰Œåˆ—è¡¨**
`{brand_list_str}`

# **æ£€æŸ¥é‡ç‚¹**
1. å¥¶ç²‰ç½åŒ…è£…ä¸Šçš„å“ç‰ŒLogoæˆ–æ–‡å­—ã€‚
2. äº§å“åŒ…è£…æ­£é¢çš„å“ç‰Œåç§°ã€‚
3. ä»»ä½•ä¸æ ¸å¿ƒå“ç‰Œåˆ—è¡¨ç›¸å…³çš„æ¸…æ™°å¯è§çš„æ ‡è¯†ã€‚

# **ä¸¥æ ¼è¦æ±‚**
- **åªè¯†åˆ«åˆ—è¡¨ä¸­çš„å“ç‰Œ**ã€‚å¦‚æœç”»é¢ä¸­å‡ºç°äº†å…¶ä»–å“ç‰Œï¼Œå¿½ç•¥å®ƒä»¬ã€‚
- å¦‚æœç”»é¢æ¨¡ç³Šã€è§’åº¦ä¸ä½³æˆ–æ— æ³•100%ç¡®è®¤ï¼Œè¯·ä¸è¦è¾“å‡ºä»»ä½•å“ç‰Œã€‚
- å¦‚æœæ²¡æœ‰åœ¨ç”»é¢ä¸­æ‰¾åˆ°ä»»ä½•æ ¸å¿ƒå“ç‰Œï¼Œè¯·ç›´æ¥è¾“å‡º "æ— "ã€‚

# **è¾“å‡ºæ ¼å¼**
- å¦‚æœæ£€æµ‹åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªå“ç‰Œï¼Œè¯·ç”¨é€—å·åˆ†éš”è¿”å›ï¼Œä¾‹å¦‚: "å¯èµ‹, illuma"
- å¦‚æœæœªæ£€æµ‹åˆ°ä»»ä½•æ ¸å¿ƒå“ç‰Œï¼Œè¯·è¾“å‡º: "æ— "
"""
        except Exception as e:
            logger.error(f"æ„å»ºå“ç‰Œæ£€æµ‹promptå¤±è´¥: {e}")
            # Return a non-functional prompt
            return "è¯·è¯†åˆ«è§†é¢‘ä¸­çš„å“ç‰Œ"