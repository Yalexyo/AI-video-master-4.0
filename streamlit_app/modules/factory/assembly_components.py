"""
ç»„è£…å·¥å‚UIç»„ä»¶æ¨¡å—
æå–å’Œå°è£…ç»„è£…å·¥å‚çš„ç”¨æˆ·ç•Œé¢ç»„ä»¶
"""

import streamlit as st
import os
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path

# å¯¼å…¥é…ç½®
from streamlit_app.config.factory_config import FactoryConfig


def render_video_upload_section() -> Optional[Any]:
    """æ¸²æŸ“è§†é¢‘ä¸Šä¼ åŒºåŸŸ
    
    Returns:
        ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶å¯¹è±¡æˆ–None
    """
    st.markdown("### ğŸ“¤ è§†é¢‘ä¸Šä¼ ")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2 = st.columns(2)
    
    with col1:
        uploaded_video = st.file_uploader(
            "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            type=config["supported_video_formats"],
            help="ä¸Šä¼ è§†é¢‘æ–‡ä»¶è¿›è¡Œæ™ºèƒ½åˆ†æå’Œåˆ‡åˆ†"
        )
    
    with col2:
        use_sample_video = st.checkbox(
            "ä½¿ç”¨ç¤ºä¾‹è§†é¢‘",
            help="ä½¿ç”¨Google Cloudæä¾›çš„ç¤ºä¾‹è§†é¢‘ï¼ˆcat.mp4ï¼‰",
            key="assembly_use_sample_video"
        )
    
    return uploaded_video, use_sample_video


def render_analysis_features() -> Dict[str, bool]:
    """æ¸²æŸ“åˆ†æåŠŸèƒ½é€‰æ‹©
    
    Returns:
        Dict: åŒ…å«å„åŠŸèƒ½å¯ç”¨çŠ¶æ€çš„å­—å…¸
    """
    st.markdown("### ğŸ”§ åˆ†æåŠŸèƒ½é€‰æ‹©")
    
    # åŸºç¡€åŠŸèƒ½
    col1, col2 = st.columns(2)
    
    with col1:
        shot_detection = st.checkbox(
            "ğŸ¬ é•œå¤´æ£€æµ‹",
            value=True,
            help="æ£€æµ‹è§†é¢‘ä¸­çš„é•œå¤´åˆ‡æ¢",
            key="assembly_shot_detection"
        )
        
        label_detection = st.checkbox(
            "ğŸ·ï¸ æ ‡ç­¾æ£€æµ‹", 
            value=True,
            help="è¯†åˆ«è§†é¢‘ä¸­çš„ç‰©ä½“å’Œåœºæ™¯",
            key="assembly_label_detection"
        )
    
    with col2:
        object_tracking = st.checkbox(
            "ğŸ“ å¯¹è±¡è·Ÿè¸ª",
            value=False,
            help="è·Ÿè¸ªè§†é¢‘ä¸­çš„ç‰¹å®šå¯¹è±¡",
            key="assembly_object_tracking"
        )
        
        auto_cleanup = st.checkbox(
            "ğŸ§¹ è‡ªåŠ¨æ¸…ç†",
            value=True,
            help="åˆ†æå®Œæˆåè‡ªåŠ¨æ¸…ç†äº‘ç«¯æ–‡ä»¶",
            key="assembly_auto_cleanup"
        )
    
    return {
        "shot_detection": shot_detection,
        "label_detection": label_detection,
        "object_tracking": object_tracking,
        "auto_cleanup": auto_cleanup
    }


def render_batch_analysis_settings() -> Dict[str, Any]:
    """æ¸²æŸ“æ‰¹é‡åˆ†æè®¾ç½®
    
    Returns:
        Dict: æ‰¹é‡åˆ†æè®¾ç½®å‚æ•°
    """
    st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        batch_size = st.number_input(
            "æ‰¹å¤„ç†å¤§å°",
            min_value=1,
            max_value=10,
            value=config["default_batch_size"],
            help="åŒæ—¶å¤„ç†çš„è§†é¢‘ç‰‡æ®µæ•°é‡"
        )
    
    with col2:
        min_empty_tags = st.number_input(
            "ç©ºæ ‡ç­¾é˜ˆå€¼",
            min_value=1,
            max_value=5,
            value=config["min_empty_tags"],
            help="è§¦å‘DeepSeekå…œåº•åˆ†æçš„ç©ºæ ‡ç­¾æ•°é‡"
        )
    
    with col3:
        # ğŸš€ æ–°å¢ï¼šå¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°é…ç½®
        max_workers = st.number_input(
            "å¹¶è¡Œçº¿ç¨‹æ•°",
            min_value=1,
            max_value=8,
            value=3,
            help="å¹¶è¡Œåˆ†æçš„æœ€å¤§çº¿ç¨‹æ•°ï¼Œå½±å“åˆ†æé€Ÿåº¦"
        )
    
    with col4:
        auto_merge_results = st.checkbox(
            "è‡ªåŠ¨åˆå¹¶åˆ†æç»“æœ",
            value=config["auto_merge_results"],
            help="å°†å¤šä¸ªæ¨¡å‹çš„åˆ†æç»“æœè‡ªåŠ¨åˆå¹¶",
            key="assembly_auto_merge_results"
        )
    
    return {
        "batch_size": batch_size,
        "min_empty_tags": min_empty_tags,
        "max_workers": max_workers,
        "auto_merge_results": auto_merge_results
    }


def render_clustering_settings() -> Dict[str, float]:
    """æ¸²æŸ“èšç±»è®¾ç½®
    
    Returns:
        Dict: èšç±»è®¾ç½®å‚æ•°
    """
    st.markdown("### ğŸ§  åœºæ™¯èšç±»è®¾ç½®")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        similarity_threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.5,
            max_value=1.0,
            value=config["default_similarity_threshold"],
            step=0.05,
            help="åœºæ™¯ç›¸ä¼¼åº¦åˆ¤æ–­é˜ˆå€¼ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼"
        )
    
    with col2:
        min_scene_duration = st.number_input(
            "æœ€å°åœºæ™¯æ—¶é•¿ (ç§’)",
            min_value=1.0,
            max_value=10.0,
            value=config["default_min_scene_duration"],
            step=0.5,
            help="åˆå¹¶ååœºæ™¯çš„æœ€å°æ—¶é•¿è¦æ±‚"
        )
    
    with col3:
        max_scenes = st.number_input(
            "æœ€å¤§åœºæ™¯æ•°",
            min_value=5,
            max_value=50,
            value=config["default_max_scenes"],
            help="èšç±»åä¿ç•™çš„æœ€å¤§åœºæ™¯æ•°é‡"
        )
    
    return {
        "similarity_threshold": similarity_threshold,
        "min_scene_duration": min_scene_duration,
        "max_scenes": max_scenes
    }


def render_video_selector(context: str = "default") -> Tuple[Optional[str], List[Any]]:
    """æ¸²æŸ“è§†é¢‘é€‰æ‹©å™¨
    
    Args:
        context: ä¸Šä¸‹æ–‡æ ‡è¯†ç¬¦ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€çš„key
    
    Returns:
        Tuple: (é€‰ä¸­çš„è§†é¢‘ID, ç‰‡æ®µæ–‡ä»¶åˆ—è¡¨)
    """
    st.markdown("### ğŸ“ è§†é¢‘ç‰‡æ®µé€‰æ‹©")
    
    # æ‰«æå¯ç”¨çš„è§†é¢‘ç›®å½•
    config = FactoryConfig.get_assembly_config()
    video_pool_path = Path(config["default_video_pool_path"])
    
    if not video_pool_path.exists():
        st.warning(f"âš ï¸ è§†é¢‘æ± ç›®å½•ä¸å­˜åœ¨: {video_pool_path}")
        return None, []
    
    # è·å–æ‰€æœ‰è§†é¢‘ç›®å½•
    video_dirs = [d for d in video_pool_path.iterdir() if d.is_dir()]
    
    if not video_dirs:
        st.info("ğŸ“‚ è§†é¢‘æ± ä¸ºç©ºï¼Œè¯·å…ˆä½¿ç”¨é›¶ä»¶å·¥å‚å¤„ç†ä¸€äº›è§†é¢‘")
        return None, []
    
    # è§†é¢‘é€‰æ‹© - ä½¿ç”¨å”¯ä¸€çš„key
    video_ids = [d.name for d in video_dirs]
    selected_video_id = st.selectbox(
        "é€‰æ‹©è¦åˆ†æçš„è§†é¢‘",
        options=video_ids,
        help="é€‰æ‹©å·²åˆ‡åˆ†çš„è§†é¢‘è¿›è¡Œæ ‡ç­¾åˆ†æ",
        key=f"assembly_factory_video_selector_{context}"
    )
    
    if selected_video_id:
        video_dir = video_pool_path / selected_video_id
        segment_files = list(video_dir.glob("*.mp4"))
        
        if segment_files:
            st.info(f"ğŸ“Š æ‰¾åˆ° {len(segment_files)} ä¸ªè§†é¢‘ç‰‡æ®µ")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶åä½œä¸ºé¢„è§ˆ
            preview_files = segment_files[:3]
            preview_names = [f.name for f in preview_files]
            
            if len(segment_files) > 3:
                preview_names.append(f"... è¿˜æœ‰ {len(segment_files) - 3} ä¸ªæ–‡ä»¶")
            
            st.code("\n".join(preview_names))
            
            return selected_video_id, segment_files
        else:
            st.warning("âš ï¸ è¯¥è§†é¢‘ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°MP4ç‰‡æ®µæ–‡ä»¶")
            return selected_video_id, []
    
    return None, []


def render_analysis_results_display(results: Dict[str, Any], analysis_type: str = "default") -> None:
    """æ¸²æŸ“åˆ†æç»“æœæ˜¾ç¤º
    
    Args:
        results: åˆ†æç»“æœå­—å…¸
        analysis_type: åˆ†æç±»å‹æ ‡è¯†ç¬¦
    """
    if not results:
        st.info("æš‚æ— åˆ†æç»“æœ")
        return
    
    # ç»“æœæ¦‚è§ˆ
    if isinstance(results, list):
        st.metric("åˆ†æç‰‡æ®µæ•°", len(results))
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        import pandas as pd
        
        display_data = []
        for result in results:
            display_data.append({
                "æ–‡ä»¶å": result.get("file_name", "N/A"),
                "å¤§å°(MB)": f"{result.get('file_size', 0):.1f}",
                "æ¨¡å‹": result.get("model", "Unknown"),
                "ç‰©ä½“": result.get("object", "æ— "),
                "åœºæ™¯": result.get("sence", "æ— "),
                "æƒ…æ„Ÿ": result.get("emotion", "æ— "),
                "ç½®ä¿¡åº¦": f"{result.get('confidence', 0):.2f}"
            })
        
        if display_data:
            df = pd.DataFrame(display_data)
            st.dataframe(df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        _render_analysis_statistics(results)
    
    elif isinstance(results, dict):
        # å•ä¸ªç»“æœæ˜¾ç¤º
        st.json(results)


def _render_analysis_statistics(results: List[Dict[str, Any]]) -> None:
    """æ¸²æŸ“åˆ†æç»Ÿè®¡ä¿¡æ¯
    
    Args:
        results: åˆ†æç»“æœåˆ—è¡¨
    """
    if not results:
        return
    
    st.markdown("#### ğŸ“Š åˆ†æç»Ÿè®¡")
    
    # åŸºæœ¬ç»Ÿè®¡
    total_count = len(results)
    success_count = len([r for r in results if r.get("success", False)])
    avg_confidence = sum(r.get("confidence", 0) for r in results) / total_count if total_count > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»ç‰‡æ®µ", total_count)
    with col2:
        st.metric("æˆåŠŸåˆ†æ", success_count)
    with col3:
        st.metric("æˆåŠŸç‡", f"{success_count/total_count*100:.1f}%" if total_count > 0 else "0%")
    with col4:
        st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
    
    # æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
    model_counts = {}
    for result in results:
        model = result.get("model", "Unknown")
        model_counts[model] = model_counts.get(model, 0) + 1
    
    if model_counts:
        st.markdown("**æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ:**")
        for model, count in model_counts.items():
            percentage = count / total_count * 100
            st.text(f"â€¢ {model}: {count} ä¸ªç‰‡æ®µ ({percentage:.1f}%)")


def render_progress_tracking(phase: str, current: int, total: int, status: str = "") -> None:
    """æ¸²æŸ“è¿›åº¦è·Ÿè¸ª
    
    Args:
        phase: å½“å‰é˜¶æ®µ
        current: å½“å‰è¿›åº¦
        total: æ€»æ•°
        status: çŠ¶æ€æ–‡æœ¬
    """
    progress_value = current / total if total > 0 else 0
    
    st.progress(progress_value)
    
    progress_text = f"**{phase}**: {current}/{total}"
    if status:
        progress_text += f" - {status}"
    
    st.text(progress_text)


def render_credentials_check() -> bool:
    """æ¸²æŸ“å‡­æ®æ£€æŸ¥
    
    Returns:
        bool: å‡­æ®æ˜¯å¦æœ‰æ•ˆ
    """
    st.markdown("### ğŸ” APIå‡­æ®æ£€æŸ¥")
    
    config = FactoryConfig.get_assembly_config()
    
    # Google Cloudå‡­æ®æ£€æŸ¥
    if st.button("ğŸ” æ£€æŸ¥Google Cloudå‡­æ®", key="assembly_check_credentials"):
        try:
            from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
            analyzer = GoogleVideoAnalyzer()
            has_credentials, cred_path = analyzer.check_credentials()
            
            if has_credentials:
                st.success(f"âœ… Google Cloudå‡­æ®æœ‰æ•ˆ: {cred_path}")
                return True
            else:
                st.error("âŒ Google Cloudå‡­æ®æ— æ•ˆæˆ–æœªè®¾ç½®")
                st.info("è¯·åœ¨è®¾ç½®é¡µé¢é…ç½®Google Cloudå‡­æ®æ–‡ä»¶")
                return False
        except Exception as e:
            st.error(f"âŒ æ£€æŸ¥Google Cloudå‡­æ®æ—¶å‡ºé”™: {e}")
            return False
    
    # DeepSeek APIæ£€æŸ¥
    if config["deepseek_enabled"]:
        if config["deepseek_api_key"]:
            st.success("âœ… DeepSeek APIå¯†é’¥å·²é…ç½®")
        else:
            st.warning("âš ï¸ DeepSeek APIå¯†é’¥æœªé…ç½®")
            st.info("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
    
    return True


def render_action_buttons(analysis_type: str = "default") -> Dict[str, bool]:
    """æ¸²æŸ“æ“ä½œæŒ‰é’®
    
    Args:
        analysis_type: åˆ†æç±»å‹
        
    Returns:
        Dict: æŒ‰é’®ç‚¹å‡»çŠ¶æ€
    """
    col1, col2, col3 = st.columns(3)
    
    buttons = {}
    
    with col1:
        buttons["start_analysis"] = st.button(
            "ğŸš€ å¼€å§‹åˆ†æ",
            type="primary",
            help="å¼€å§‹æ‰§è¡Œé€‰å®šçš„åˆ†æä»»åŠ¡",
            key=f"assembly_start_analysis_{analysis_type}"
        )
    
    with col2:
        buttons["save_results"] = st.button(
            "ğŸ’¾ ä¿å­˜ç»“æœ",
            help="å°†åˆ†æç»“æœä¿å­˜åˆ°æ–‡ä»¶",
            key=f"assembly_save_results_{analysis_type}"
        )
    
    with col3:
        buttons["export_csv"] = st.button(
            "ğŸ“Š å¯¼å‡ºCSV",
            help="å°†ç»“æœå¯¼å‡ºä¸ºCSVæ ¼å¼",
            key=f"assembly_export_csv_{analysis_type}"
        )
    
    return buttons


def render_error_display(error: Exception, context: str = "") -> None:
    """æ¸²æŸ“é”™è¯¯ä¿¡æ¯æ˜¾ç¤º
    
    Args:
        error: å¼‚å¸¸å¯¹è±¡
        context: é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    if context:
        st.error(f"âŒ {context}: {str(error)}")
    else:
        st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(error)}")
    
    # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
    with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…", expanded=False):
        import traceback
        st.code(traceback.format_exc(), language="python")


def render_model_selection() -> Dict[str, bool]:
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©ç•Œé¢
    
    Returns:
        Dict: æ¨¡å‹å¯ç”¨çŠ¶æ€
    """
    st.markdown("### ğŸ¤– AIæ¨¡å‹é€‰æ‹©")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3 = st.columns(3)
    
    models = {}
    
    with col1:
        models["google_cloud"] = st.checkbox(
            "ğŸŒ©ï¸ Google Cloud Video Intelligence",
            value=config["google_cloud_enabled"],
            help="ä½¿ç”¨Google Cloudè¿›è¡Œè§†é¢‘åˆ†æ",
            key="assembly_model_google_cloud"
        )
    
    with col2:
        models["qwen"] = st.checkbox(
            "ğŸ¤– Qwenæ¨¡å‹",
            value=config["qwen_enabled"],
            help="ä½¿ç”¨Qwenè¿›è¡Œè§†è§‰ç†è§£åˆ†æ",
            key="assembly_model_qwen"
        )
    
    with col3:
        models["deepseek"] = st.checkbox(
            "ğŸ§  DeepSeekæ¨¡å‹",
            value=config["deepseek_enabled"],
            help="ä½¿ç”¨DeepSeekè¿›è¡Œæ™ºèƒ½åˆ†æå…œåº•",
            key="assembly_model_deepseek"
        )
    
    return models 


def render_prompt_configuration() -> None:
    """æ¸²æŸ“ä¼˜åŒ–çš„AIæ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘é…ç½®ç•Œé¢"""
    st.markdown("### ğŸ¯ æ™ºèƒ½é…ç½®ä¸­å¿ƒ")
    
    st.info("""
    ğŸ” **é…ç½®é€»è¾‘è¯´æ˜**ï¼š
    1. **AIè¯†åˆ«è¯åº“** â†’ å®šä¹‰AIèƒ½"çœ‹åˆ°"å’Œ"å¬åˆ°"ä»€ä¹ˆ
    2. **ä¸šåŠ¡åˆ†ç±»è§„åˆ™** â†’ å®šä¹‰è¯†åˆ«ç»“æœå¦‚ä½•æ˜ å°„åˆ°ä¸šåŠ¡æ¨¡å—
    3. **Prompté¢„è§ˆ** â†’ æŸ¥çœ‹æœ€ç»ˆç”Ÿæˆçš„AIæŒ‡ä»¤
    """)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs([
        "ğŸ¤– AIè¯†åˆ«è¯åº“", 
        "ğŸ” Prompté¢„è§ˆ"
    ])
    
    with tab1:
        _render_ai_recognition_config()
        
    with tab2:
        _render_prompt_previews()
    
    # ğŸ’¡ æç¤ºï¼šä¸šåŠ¡åˆ†ç±»è§„åˆ™é…ç½®å·²ç§»è‡³è°ƒè¯•å·¥å‚
    st.info("""
    ğŸ”§ **ä¸šåŠ¡åˆ†ç±»è§„åˆ™é…ç½®åŠŸèƒ½å·²è¿ç§»è‡³è°ƒè¯•å·¥å‚ï¼**
    
    ğŸ“ **æ–°åŠŸèƒ½ä½ç½®**: ğŸ› è°ƒè¯•å·¥å‚ â†’ ğŸ“‹ æ˜ å°„è§„åˆ™è¯¦ç»†æ£€æŸ¥
    
    ğŸ¯ **å‡çº§ä¼˜åŠ¿**:
    - âœ… å®æ—¶è§„åˆ™é¢„è§ˆå’Œç¼–è¾‘
    - âœ… ç«‹å³æµ‹è¯•ä¿®æ”¹æ•ˆæœ  
    - âœ… å¯è§†åŒ–è°ƒè¯•è¿‡ç¨‹
    - âœ… æ’é™¤å…³é”®è¯éªŒè¯
    
    ğŸ‘‰ ç‚¹å‡»å·¦ä¾§å¯¼èˆªä¸­çš„ ğŸ›è°ƒè¯•å·¥å‚ è¿›è¡Œè§„åˆ™é…ç½®
    """)


def _render_ai_recognition_config() -> None:
    """æ¸²æŸ“AIè¯†åˆ«é…ç½®ç•Œé¢"""
    import time
    
    st.markdown("#### ğŸ¤– AIè¯†åˆ«è¯åº“é…ç½®")
    st.write("é…ç½®AIæ¨¡å‹è¯†åˆ«è§†é¢‘å†…å®¹æ—¶ä½¿ç”¨çš„åŸºç¡€è¯æ±‡è¡¨")
    
    try:
        from streamlit_app.utils.optimized_keyword_manager import keyword_manager
        current_config = keyword_manager.get_ai_recognition_config()
    except ImportError:
        st.error("æ— æ³•å¯¼å…¥ä¼˜åŒ–çš„å…³é”®è¯ç®¡ç†å™¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return
    
    # è§†è§‰AIé…ç½®
    with st.expander("ğŸ‘ï¸ **è§†è§‰AI (Qwen) è¯†åˆ«è¯åº“**", expanded=True):
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“¦ è¯†åˆ«å¯¹è±¡")
            
            # åŸºç¡€å¯¹è±¡
            basic_objects_str = ", ".join(current_config["visual"]["objects_basic"])
            new_basic_objects_str = st.text_area(
                "åŸºç¡€å¯¹è±¡",
                value=basic_objects_str,
                placeholder="å¥¶ç²‰ç½, å¥¶ç“¶, å®å®, å¦ˆå¦ˆ",
                help="AIè¯†åˆ«çš„åŸºç¡€è§†è§‰å¯¹è±¡",
                key="qwen_basic_objects",
                height=80
            )
            
            # å“ç‰Œç›¸å…³å¯¹è±¡
            brand_objects_str = ", ".join(current_config["visual"]["objects_brand"])
            new_brand_objects_str = st.text_area(
                "å“ç‰Œç›¸å…³å¯¹è±¡",
                value=brand_objects_str,
                placeholder="å“ç‰Œlogo, åŒ…è£…, å•†æ ‡",
                help="ä¸å“ç‰Œè¯†åˆ«ç›¸å…³çš„è§†è§‰å…ƒç´ ",
                key="qwen_brand_objects",
                height=80
            )
            
            # æˆåˆ†ç›¸å…³å¯¹è±¡
            comp_objects_str = ", ".join(current_config["visual"]["objects_composition"])
            new_comp_objects_str = st.text_area(
                "æˆåˆ†ç›¸å…³å¯¹è±¡",
                value=comp_objects_str,
                placeholder="æˆåˆ†è¡¨, è¥å…»è¡¨, é…æ–™è¡¨",
                help="è¥å…»æˆåˆ†å’Œé…æ–™è¡¨ç›¸å…³å¯¹è±¡",
                key="qwen_comp_objects",
                height=80
            )
        
        with col2:
            st.subheader("ğŸï¸ åœºæ™¯é…ç½®")
            
            # åœºæ™¯
            scenes_str = ", ".join(current_config["visual"]["scenes"])
            new_scenes_str = st.text_area(
                "è¯†åˆ«åœºæ™¯",
                value=scenes_str,
                placeholder="å¨æˆ¿, å®¢å…, åŒ»é™¢, æˆ·å¤–",
                help="AIè¯†åˆ«çš„åœºæ™¯ç¯å¢ƒ",
                key="qwen_scenes",
                height=80
            )
            
        # å“ç‰Œé…ç½®åŒºåŸŸ
        st.subheader("ğŸ·ï¸ å“ç‰Œè¯†åˆ«é…ç½®")
        st.info("ğŸ’¡ ä¸“æ³¨æ ¸å¿ƒå“ç‰Œï¼šæƒ æ°ã€å¯èµ‹ã€è•´æ·³ï¼Œé¿å…é…ç½®è¿‡å¤šå“ç‰Œåˆ†æ•£AIæ³¨æ„åŠ›")
        
        # ğŸ¯ ç®€åŒ–å“ç‰Œé…ç½® - åªæ˜¾ç¤ºä¸€ä¸ªå“ç‰Œåˆ—è¡¨
        brands_str = ", ".join(current_config["visual"]["brands"])
        new_brands_str = st.text_area(
            "ğŸ¯ æ ¸å¿ƒå“ç‰Œï¼ˆå»ºè®®3-5ä¸ªï¼‰",
            value=brands_str,
            placeholder="æƒ æ°, å¯èµ‹, è•´æ·³",
            help="AIä¼šé‡ç‚¹è¯†åˆ«è¿™äº›å“ç‰Œï¼Œå»ºè®®ä¸“æ³¨æ ¸å¿ƒå“ç‰Œ",
            key="qwen_brands",
            height=80
        )
        
        # ä¿å­˜è§†è§‰é…ç½®æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜è§†è§‰AIé…ç½®", type="primary", key="save_visual_config"):
            new_config = {
                "visual": {
                    "objects_basic": [kw.strip() for kw in new_basic_objects_str.split(",") if kw.strip()],
                    "objects_brand": [kw.strip() for kw in new_brand_objects_str.split(",") if kw.strip()],
                    "objects_composition": [kw.strip() for kw in new_comp_objects_str.split(",") if kw.strip()],
                    "scenes": [kw.strip() for kw in new_scenes_str.split(",") if kw.strip()],
                    "brands": [kw.strip() for kw in new_brands_str.split(",") if kw.strip()],
                    "pain_signals": [kw.strip() for kw in new_pain_signals_str.split(",") if kw.strip()],
                    "vitality_signals": [kw.strip() for kw in new_vitality_signals_str.split(",") if kw.strip()]
                },
                "audio": current_config["audio"],
                "shared": current_config["shared"]
            }
            
            # éªŒè¯é…ç½®
            issues = keyword_manager.validate_config("ai_recognition", new_config)
            if issues:
                st.error("é…ç½®éªŒè¯å¤±è´¥ï¼š")
                for issue in issues:
                    st.text(f"â€¢ {issue}")
            else:
                success = keyword_manager.save_ai_recognition_config(new_config)
                if success:
                    # è®¾ç½®æˆåŠŸæ¶ˆæ¯å’Œæ—¶é—´æˆ³
                    import time
                    st.session_state["save_message_visual"] = {
                        "type": "success",
                        "message": "âœ… è§†è§‰AIé…ç½®ä¿å­˜æˆåŠŸï¼",
                        "timestamp": time.time()
                    }
                    # æ¸…é™¤ç¼“å­˜å¹¶é‡æ–°åŠ è½½é…ç½®
                    try:
                        from streamlit_app.utils.keyword_config import reload_config
                        reload_config()
                    except ImportError:
                        pass
                    st.rerun()
                else:
                    import time
                    st.session_state["save_message_visual"] = {
                        "type": "error",
                        "message": "âŒ ä¿å­˜å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æƒé™",
                        "timestamp": time.time()
                    }
    
    # éŸ³é¢‘AIé…ç½®
    with st.expander("ğŸ¤ **éŸ³é¢‘AI (DeepSeek) è¯†åˆ«è¯åº“**", expanded=False):
        col1, col2 = st.columns(2)
        
        with col1:
            audio_objects_str = ", ".join(current_config["audio"]["objects"])
            new_audio_objects_str = st.text_area(
                "éŸ³é¢‘è¯†åˆ«å¯¹è±¡",
                value=audio_objects_str,
                placeholder="å¥¶ç²‰, å®å®, å¦ˆå¦ˆ",
                help="AIä»éŸ³é¢‘ä¸­è¯†åˆ«çš„å¯¹è±¡",
                key="deepseek_objects",
                height=80
            )
        
        with col2:
            audio_scenes_str = ", ".join(current_config["audio"]["scenes"])
            new_audio_scenes_str = st.text_area(
                "éŸ³é¢‘è¯†åˆ«åœºæ™¯",
                value=audio_scenes_str,
                placeholder="å†²å¥¶, æŒ‡å¯¼, æŠ¤ç†",
                help="AIä»éŸ³é¢‘ä¸­è¯†åˆ«çš„åœºæ™¯",
                key="deepseek_scenes",
                height=80
            )
        
        # ä¿å­˜éŸ³é¢‘é…ç½®æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜éŸ³é¢‘AIé…ç½®", type="primary", key="save_audio_config"):
            new_config = current_config.copy()
            new_config["audio"] = {
                "objects": [kw.strip() for kw in new_audio_objects_str.split(",") if kw.strip()],
                "scenes": [kw.strip() for kw in new_audio_scenes_str.split(",") if kw.strip()]
            }
            
            success = keyword_manager.save_ai_recognition_config(new_config)
            if success:
                # è®¾ç½®æˆåŠŸæ¶ˆæ¯å’Œæ—¶é—´æˆ³
                import time
                st.session_state["save_message_audio"] = {
                    "type": "success",
                    "message": "âœ… éŸ³é¢‘AIé…ç½®ä¿å­˜æˆåŠŸï¼",
                    "timestamp": time.time()
                }
                try:
                    from streamlit_app.utils.keyword_config import reload_config
                    reload_config()
                except ImportError:
                    pass
                st.rerun()
            else:
                import time
                st.session_state["save_message_audio"] = {
                    "type": "error",
                    "message": "âŒ ä¿å­˜å¤±è´¥",
                    "timestamp": time.time()
                }
    
    # é€šç”¨é…ç½®
    with st.expander("ğŸŒ **é€šç”¨AIé…ç½®**", expanded=False):
        emotions_str = " / ".join(current_config["shared"]["emotions"])
        new_emotions_str = st.text_input(
            "å¯è¯†åˆ«æƒ…ç»ªï¼ˆå¿…é¡»5ä¸ªï¼Œç”¨ / åˆ†éš”ï¼‰",
            value=emotions_str,
            help="AIæ¨¡å‹åªèƒ½ä»è¿™5ç§æƒ…ç»ªä¸­é€‰æ‹©",
            key="shared_emotions"
        )
        
        # ä¿å­˜é€šç”¨é…ç½®æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜é€šç”¨é…ç½®", type="primary", key="save_shared_config"):
            emotions = [emo.strip() for emo in new_emotions_str.split("/") if emo.strip()]
            
            if len(emotions) != 5:
                st.error(f"æƒ…ç»ªå¿…é¡»æ˜¯5ä¸ªï¼Œå½“å‰ä¸º{len(emotions)}ä¸ª")
            else:
                new_config = current_config.copy()
                new_config["shared"]["emotions"] = emotions
                
                success = keyword_manager.save_ai_recognition_config(new_config)
                if success:
                    # è®¾ç½®æˆåŠŸæ¶ˆæ¯å’Œæ—¶é—´æˆ³
                    import time
                    st.session_state["save_message_shared"] = {
                        "type": "success",
                        "message": "âœ… é€šç”¨é…ç½®ä¿å­˜æˆåŠŸï¼",
                        "timestamp": time.time()
                    }
                    try:
                        from streamlit_app.utils.keyword_config import reload_config
                        reload_config()
                    except ImportError:
                        pass
                    st.rerun()
                else:
                    import time
                    st.session_state["save_message_shared"] = {
                        "type": "error",
                        "message": "âŒ ä¿å­˜å¤±è´¥",
                        "timestamp": time.time()
                    }

    # æ˜¾ç¤ºæ‰€æœ‰AIè¯†åˆ«é…ç½®çš„ä¸´æ—¶æ¶ˆæ¯ï¼ˆå¦‚æœå­˜åœ¨ä¸”æœªè¿‡æœŸï¼‰
    import time
    for message_key in ["save_message_visual", "save_message_audio", "save_message_shared"]:
        if message_key in st.session_state:
            message_data = st.session_state[message_key]
            elapsed_time = time.time() - message_data["timestamp"]
            
            # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦è¶…è¿‡3ç§’
            if elapsed_time < 3:
                if message_data["type"] == "success":
                    st.success(message_data["message"])
                else:
                    st.error(message_data["message"])
            else:
                # æ¶ˆæ¯è¿‡æœŸï¼Œåˆ é™¤
                del st.session_state[message_key]




def _render_prompt_previews() -> None:
    """æ¸²æŸ“AIæ¨¡å‹Prompté¢„è§ˆç•Œé¢"""
    st.markdown("#### ğŸ“ AIæ¨¡å‹Prompté¢„è§ˆ")
    st.write("æ ¹æ®å½“å‰é…ç½®ç”Ÿæˆçš„AIæ¨¡å‹æŒ‡ä»¤é¢„è§ˆï¼ˆåªè¯»ï¼‰")
    
    try:
        from streamlit_app.utils.keyword_config import sync_prompt_templates
        templates = sync_prompt_templates()
        
        if templates:
            with st.expander("ğŸ‘ï¸ Qwenè§†è§‰åˆ†æPrompt", expanded=True):
                if "qwen_visual" in templates:
                    st.code(templates["qwen_visual"], language="text")
                    st.caption(f"Prompté•¿åº¦: {len(templates['qwen_visual'])} å­—ç¬¦")
                else:
                    st.error("Qwen Promptç”Ÿæˆå¤±è´¥")
            
            with st.expander("ğŸ§  DeepSeekéŸ³é¢‘åˆ†æPrompt", expanded=False):
                if "deepseek_audio" in templates:
                    st.code(templates["deepseek_audio"], language="text")
                    st.caption(f"Prompté•¿åº¦: {len(templates['deepseek_audio'])} å­—ç¬¦")
                else:
                    st.error("DeepSeek Promptç”Ÿæˆå¤±è´¥")
                    
            if "qwen_retry" in templates:
                with st.expander("ğŸ”„ Qwené‡è¯•Prompt", expanded=False):
                    st.code(templates["qwen_retry"], language="text")
                    
            # æ·»åŠ é…ç½®æ•ˆæœé¢„è§ˆ
            st.subheader("ğŸ”§ é…ç½®æ•ˆæœåˆ†æ")
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**å“ç‰Œè¯†åˆ«å¼ºåŒ–æ•ˆæœ**")
                qwen_prompt = templates.get("qwen_visual", "")
                brand_mentions = qwen_prompt.count("é‡ç‚¹å“ç‰Œ") + qwen_prompt.count("å“ç‰Œç›¸å…³") + qwen_prompt.count("æˆåˆ†ç›¸å…³")
                st.metric("å“ç‰Œå¼ºåŒ–æ¬¡æ•°", brand_mentions)
                
                if brand_mentions >= 3:
                    st.success("âœ… å“ç‰Œè¯†åˆ«å¼ºåŒ–å……åˆ†")
                else:
                    st.warning("âš ï¸ å»ºè®®å¢å¼ºå“ç‰Œè¯†åˆ«é…ç½®")
            
            with col2:
                st.markdown("**Promptå¤æ‚åº¦**")
                total_keywords = len(templates.get("qwen_visual", "").split("ã€"))
                st.metric("æ€»å…³é”®è¯ä¼°ç®—", total_keywords)
                
                if total_keywords > 50:
                    st.success("âœ… å…³é”®è¯é…ç½®ä¸°å¯Œ")
                else:
                    st.info("ğŸ’¡ å¯è€ƒè™‘æ·»åŠ æ›´å¤šå…³é”®è¯")
        else:
            st.error("æ— æ³•ç”ŸæˆPromptæ¨¡æ¿ï¼Œè¯·æ£€æŸ¥é…ç½®")
            
    except Exception as e:
        st.error(f"Prompté¢„è§ˆå¤±è´¥: {e}")
        st.info("è¯·ç¡®ä¿é…ç½®æ­£ç¡®å¹¶å·²ä¿å­˜") 