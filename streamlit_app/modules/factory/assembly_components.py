"""
ç»„è£…å·¥å‚UIç»„ä»¶æ¨¡å—
æå–å’Œå°è£…ç»„è£…å·¥å‚çš„ç”¨æˆ·ç•Œé¢ç»„ä»¶
"""

import streamlit as st
import os
from typing import Dict, Any, List, Optional, Tuple
from pathlib import Path

# å¯¼å…¥é…ç½®
from config.factory_config import FactoryConfig


def render_video_upload_section() -> Optional[Any]:
    """æ¸²æŸ“è§†é¢‘ä¸Šä¼ åŒºåŸŸ
    
    Returns:
        ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶å¯¹è±¡æˆ–None
    """
    st.markdown("### ğŸ“¤ è§†é¢‘ä¸Šä¼ ")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2 = st.columns(2)
    
    with col1:
        uploaded_video = st.file_uploader(
            "é€‰æ‹©è§†é¢‘æ–‡ä»¶",
            type=config["supported_video_formats"],
            help="ä¸Šä¼ è§†é¢‘æ–‡ä»¶è¿›è¡Œæ™ºèƒ½åˆ†æå’Œåˆ‡åˆ†"
        )
    
    with col2:
        use_sample_video = st.checkbox(
            "ä½¿ç”¨ç¤ºä¾‹è§†é¢‘",
            help="ä½¿ç”¨Google Cloudæä¾›çš„ç¤ºä¾‹è§†é¢‘ï¼ˆcat.mp4ï¼‰",
            key="assembly_use_sample_video"
        )
    
    return uploaded_video, use_sample_video


def render_analysis_features() -> Dict[str, bool]:
    """æ¸²æŸ“åˆ†æåŠŸèƒ½é€‰æ‹©
    
    Returns:
        Dict: åŒ…å«å„åŠŸèƒ½å¯ç”¨çŠ¶æ€çš„å­—å…¸
    """
    st.markdown("### ğŸ”§ åˆ†æåŠŸèƒ½é€‰æ‹©")
    
    # åŸºç¡€åŠŸèƒ½
    col1, col2 = st.columns(2)
    
    with col1:
        shot_detection = st.checkbox(
            "ğŸ¬ é•œå¤´æ£€æµ‹",
            value=True,
            help="æ£€æµ‹è§†é¢‘ä¸­çš„é•œå¤´åˆ‡æ¢",
            key="assembly_shot_detection"
        )
        
        label_detection = st.checkbox(
            "ğŸ·ï¸ æ ‡ç­¾æ£€æµ‹", 
            value=True,
            help="è¯†åˆ«è§†é¢‘ä¸­çš„ç‰©ä½“å’Œåœºæ™¯",
            key="assembly_label_detection"
        )
    
    with col2:
        object_tracking = st.checkbox(
            "ğŸ“ å¯¹è±¡è·Ÿè¸ª",
            value=False,
            help="è·Ÿè¸ªè§†é¢‘ä¸­çš„ç‰¹å®šå¯¹è±¡",
            key="assembly_object_tracking"
        )
        
        auto_cleanup = st.checkbox(
            "ğŸ§¹ è‡ªåŠ¨æ¸…ç†",
            value=True,
            help="åˆ†æå®Œæˆåè‡ªåŠ¨æ¸…ç†äº‘ç«¯æ–‡ä»¶",
            key="assembly_auto_cleanup"
        )
    
    return {
        "shot_detection": shot_detection,
        "label_detection": label_detection,
        "object_tracking": object_tracking,
        "auto_cleanup": auto_cleanup
    }


def render_batch_analysis_settings() -> Dict[str, Any]:
    """æ¸²æŸ“æ‰¹é‡åˆ†æè®¾ç½®
    
    Returns:
        Dict: æ‰¹é‡åˆ†æè®¾ç½®å‚æ•°
    """
    st.markdown("### âš™ï¸ åˆ†æè®¾ç½®")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        batch_size = st.number_input(
            "æ‰¹å¤„ç†å¤§å°",
            min_value=1,
            max_value=10,
            value=config["default_batch_size"],
            help="åŒæ—¶å¤„ç†çš„è§†é¢‘ç‰‡æ®µæ•°é‡"
        )
    
    with col2:
        min_empty_tags = st.number_input(
            "ç©ºæ ‡ç­¾é˜ˆå€¼",
            min_value=1,
            max_value=5,
            value=config["min_empty_tags"],
            help="è§¦å‘DeepSeekå…œåº•åˆ†æçš„ç©ºæ ‡ç­¾æ•°é‡"
        )
    
    with col3:
        # ğŸš€ æ–°å¢ï¼šå¹¶è¡Œå·¥ä½œçº¿ç¨‹æ•°é…ç½®
        max_workers = st.number_input(
            "å¹¶è¡Œçº¿ç¨‹æ•°",
            min_value=1,
            max_value=8,
            value=3,
            help="å¹¶è¡Œåˆ†æçš„æœ€å¤§çº¿ç¨‹æ•°ï¼Œå½±å“åˆ†æé€Ÿåº¦"
        )
    
    with col4:
        auto_merge_results = st.checkbox(
            "è‡ªåŠ¨åˆå¹¶åˆ†æç»“æœ",
            value=config["auto_merge_results"],
            help="å°†å¤šä¸ªæ¨¡å‹çš„åˆ†æç»“æœè‡ªåŠ¨åˆå¹¶",
            key="assembly_auto_merge_results"
        )
    
    return {
        "batch_size": batch_size,
        "min_empty_tags": min_empty_tags,
        "max_workers": max_workers,
        "auto_merge_results": auto_merge_results
    }


def render_clustering_settings() -> Dict[str, float]:
    """æ¸²æŸ“èšç±»è®¾ç½®
    
    Returns:
        Dict: èšç±»è®¾ç½®å‚æ•°
    """
    st.markdown("### ğŸ§  åœºæ™¯èšç±»è®¾ç½®")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        similarity_threshold = st.slider(
            "ç›¸ä¼¼åº¦é˜ˆå€¼",
            min_value=0.5,
            max_value=1.0,
            value=config["default_similarity_threshold"],
            step=0.05,
            help="åœºæ™¯ç›¸ä¼¼åº¦åˆ¤æ–­é˜ˆå€¼ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼"
        )
    
    with col2:
        min_scene_duration = st.number_input(
            "æœ€å°åœºæ™¯æ—¶é•¿ (ç§’)",
            min_value=1.0,
            max_value=10.0,
            value=config["default_min_scene_duration"],
            step=0.5,
            help="åˆå¹¶ååœºæ™¯çš„æœ€å°æ—¶é•¿è¦æ±‚"
        )
    
    with col3:
        max_scenes = st.number_input(
            "æœ€å¤§åœºæ™¯æ•°",
            min_value=5,
            max_value=50,
            value=config["default_max_scenes"],
            help="èšç±»åä¿ç•™çš„æœ€å¤§åœºæ™¯æ•°é‡"
        )
    
    return {
        "similarity_threshold": similarity_threshold,
        "min_scene_duration": min_scene_duration,
        "max_scenes": max_scenes
    }


def render_video_selector(context: str = "default") -> Tuple[Optional[str], List[Any]]:
    """æ¸²æŸ“è§†é¢‘é€‰æ‹©å™¨
    
    Args:
        context: ä¸Šä¸‹æ–‡æ ‡è¯†ç¬¦ï¼Œç”¨äºç”Ÿæˆå”¯ä¸€çš„key
    
    Returns:
        Tuple: (é€‰ä¸­çš„è§†é¢‘ID, ç‰‡æ®µæ–‡ä»¶åˆ—è¡¨)
    """
    st.markdown("### ğŸ“ è§†é¢‘ç‰‡æ®µé€‰æ‹©")
    
    # æ‰«æå¯ç”¨çš„è§†é¢‘ç›®å½•
    config = FactoryConfig.get_assembly_config()
    video_pool_path = Path(config["default_video_pool_path"])
    
    if not video_pool_path.exists():
        st.warning(f"âš ï¸ è§†é¢‘æ± ç›®å½•ä¸å­˜åœ¨: {video_pool_path}")
        return None, []
    
    # è·å–æ‰€æœ‰è§†é¢‘ç›®å½•
    video_dirs = [d for d in video_pool_path.iterdir() if d.is_dir()]
    
    if not video_dirs:
        st.info("ğŸ“‚ è§†é¢‘æ± ä¸ºç©ºï¼Œè¯·å…ˆä½¿ç”¨é›¶ä»¶å·¥å‚å¤„ç†ä¸€äº›è§†é¢‘")
        return None, []
    
    # è§†é¢‘é€‰æ‹© - ä½¿ç”¨å”¯ä¸€çš„key
    video_ids = [d.name for d in video_dirs]
    selected_video_id = st.selectbox(
        "é€‰æ‹©è¦åˆ†æçš„è§†é¢‘",
        options=video_ids,
        help="é€‰æ‹©å·²åˆ‡åˆ†çš„è§†é¢‘è¿›è¡Œæ ‡ç­¾åˆ†æ",
        key=f"assembly_factory_video_selector_{context}"
    )
    
    if selected_video_id:
        video_dir = video_pool_path / selected_video_id
        segment_files = list(video_dir.glob("*.mp4"))
        
        if segment_files:
            st.info(f"ğŸ“Š æ‰¾åˆ° {len(segment_files)} ä¸ªè§†é¢‘ç‰‡æ®µ")
            
            # æ˜¾ç¤ºå‰å‡ ä¸ªæ–‡ä»¶åä½œä¸ºé¢„è§ˆ
            preview_files = segment_files[:3]
            preview_names = [f.name for f in preview_files]
            
            if len(segment_files) > 3:
                preview_names.append(f"... è¿˜æœ‰ {len(segment_files) - 3} ä¸ªæ–‡ä»¶")
            
            st.code("\n".join(preview_names))
            
            return selected_video_id, segment_files
        else:
            st.warning("âš ï¸ è¯¥è§†é¢‘ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°MP4ç‰‡æ®µæ–‡ä»¶")
            return selected_video_id, []
    
    return None, []


def render_analysis_results_display(results: Dict[str, Any], analysis_type: str = "default") -> None:
    """æ¸²æŸ“åˆ†æç»“æœæ˜¾ç¤º
    
    Args:
        results: åˆ†æç»“æœå­—å…¸
        analysis_type: åˆ†æç±»å‹æ ‡è¯†ç¬¦
    """
    if not results:
        st.info("æš‚æ— åˆ†æç»“æœ")
        return
    
    # ç»“æœæ¦‚è§ˆ
    if isinstance(results, list):
        st.metric("åˆ†æç‰‡æ®µæ•°", len(results))
        
        # åˆ›å»ºç»“æœè¡¨æ ¼
        import pandas as pd
        
        display_data = []
        for result in results:
            display_data.append({
                "æ–‡ä»¶å": result.get("file_name", "N/A"),
                "å¤§å°(MB)": f"{result.get('file_size', 0):.1f}",
                "æ¨¡å‹": result.get("model", "Unknown"),
                "ç‰©ä½“": result.get("object", "æ— "),
                "åœºæ™¯": result.get("scene", "æ— "),
                "æƒ…æ„Ÿ": result.get("emotion", "æ— "),
                "ç½®ä¿¡åº¦": f"{result.get('confidence', 0):.2f}"
            })
        
        if display_data:
            df = pd.DataFrame(display_data)
            st.dataframe(df, use_container_width=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        _render_analysis_statistics(results)
    
    elif isinstance(results, dict):
        # å•ä¸ªç»“æœæ˜¾ç¤º
        st.json(results)


def _render_analysis_statistics(results: List[Dict[str, Any]]) -> None:
    """æ¸²æŸ“åˆ†æç»Ÿè®¡ä¿¡æ¯
    
    Args:
        results: åˆ†æç»“æœåˆ—è¡¨
    """
    if not results:
        return
    
    st.markdown("#### ğŸ“Š åˆ†æç»Ÿè®¡")
    
    # åŸºæœ¬ç»Ÿè®¡
    total_count = len(results)
    success_count = len([r for r in results if r.get("success", False)])
    avg_confidence = sum(r.get("confidence", 0) for r in results) / total_count if total_count > 0 else 0
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("æ€»ç‰‡æ®µ", total_count)
    with col2:
        st.metric("æˆåŠŸåˆ†æ", success_count)
    with col3:
        st.metric("æˆåŠŸç‡", f"{success_count/total_count*100:.1f}%" if total_count > 0 else "0%")
    with col4:
        st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
    
    # æ¨¡å‹ä½¿ç”¨ç»Ÿè®¡
    model_counts = {}
    for result in results:
        model = result.get("model", "Unknown")
        model_counts[model] = model_counts.get(model, 0) + 1
    
    if model_counts:
        st.markdown("**æ¨¡å‹ä½¿ç”¨åˆ†å¸ƒ:**")
        for model, count in model_counts.items():
            percentage = count / total_count * 100
            st.text(f"â€¢ {model}: {count} ä¸ªç‰‡æ®µ ({percentage:.1f}%)")


def render_progress_tracking(phase: str, current: int, total: int, status: str = "") -> None:
    """æ¸²æŸ“è¿›åº¦è·Ÿè¸ª
    
    Args:
        phase: å½“å‰é˜¶æ®µ
        current: å½“å‰è¿›åº¦
        total: æ€»æ•°
        status: çŠ¶æ€æ–‡æœ¬
    """
    progress_value = current / total if total > 0 else 0
    
    st.progress(progress_value)
    
    progress_text = f"**{phase}**: {current}/{total}"
    if status:
        progress_text += f" - {status}"
    
    st.text(progress_text)


def render_credentials_check() -> bool:
    """æ¸²æŸ“å‡­æ®æ£€æŸ¥
    
    Returns:
        bool: å‡­æ®æ˜¯å¦æœ‰æ•ˆ
    """
    st.markdown("### ğŸ” APIå‡­æ®æ£€æŸ¥")
    
    config = FactoryConfig.get_assembly_config()
    
    # Google Cloudå‡­æ®æ£€æŸ¥
    if st.button("ğŸ” æ£€æŸ¥Google Cloudå‡­æ®", key="assembly_check_credentials"):
        try:
            from modules.ai_analyzers import GoogleVideoAnalyzer
            analyzer = GoogleVideoAnalyzer()
            has_credentials, cred_path = analyzer.check_credentials()
            
            if has_credentials:
                st.success(f"âœ… Google Cloudå‡­æ®æœ‰æ•ˆ: {cred_path}")
                return True
            else:
                st.error("âŒ Google Cloudå‡­æ®æ— æ•ˆæˆ–æœªè®¾ç½®")
                st.info("è¯·åœ¨è®¾ç½®é¡µé¢é…ç½®Google Cloudå‡­æ®æ–‡ä»¶")
                return False
        except Exception as e:
            st.error(f"âŒ æ£€æŸ¥Google Cloudå‡­æ®æ—¶å‡ºé”™: {e}")
            return False
    
    # DeepSeek APIæ£€æŸ¥
    if config["deepseek_enabled"]:
        if config["deepseek_api_key"]:
            st.success("âœ… DeepSeek APIå¯†é’¥å·²é…ç½®")
        else:
            st.warning("âš ï¸ DeepSeek APIå¯†é’¥æœªé…ç½®")
            st.info("è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
    
    return True


def render_action_buttons(analysis_type: str = "default") -> Dict[str, bool]:
    """æ¸²æŸ“æ“ä½œæŒ‰é’®
    
    Args:
        analysis_type: åˆ†æç±»å‹
        
    Returns:
        Dict: æŒ‰é’®ç‚¹å‡»çŠ¶æ€
    """
    col1, col2, col3 = st.columns(3)
    
    buttons = {}
    
    with col1:
        buttons["start_analysis"] = st.button(
            "ğŸš€ å¼€å§‹åˆ†æ",
            type="primary",
            help="å¼€å§‹æ‰§è¡Œé€‰å®šçš„åˆ†æä»»åŠ¡",
            key=f"assembly_start_analysis_{analysis_type}"
        )
    
    with col2:
        buttons["save_results"] = st.button(
            "ğŸ’¾ ä¿å­˜ç»“æœ",
            help="å°†åˆ†æç»“æœä¿å­˜åˆ°æ–‡ä»¶",
            key=f"assembly_save_results_{analysis_type}"
        )
    
    with col3:
        buttons["export_csv"] = st.button(
            "ğŸ“Š å¯¼å‡ºCSV",
            help="å°†ç»“æœå¯¼å‡ºä¸ºCSVæ ¼å¼",
            key=f"assembly_export_csv_{analysis_type}"
        )
    
    return buttons


def render_error_display(error: Exception, context: str = "") -> None:
    """æ¸²æŸ“é”™è¯¯ä¿¡æ¯æ˜¾ç¤º
    
    Args:
        error: å¼‚å¸¸å¯¹è±¡
        context: é”™è¯¯ä¸Šä¸‹æ–‡ä¿¡æ¯
    """
    if context:
        st.error(f"âŒ {context}: {str(error)}")
    else:
        st.error(f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(error)}")
    
    # æ˜¾ç¤ºé”™è¯¯è¯¦æƒ…
    with st.expander("ğŸ” é”™è¯¯è¯¦æƒ…", expanded=False):
        import traceback
        st.code(traceback.format_exc(), language="python")


def render_model_selection() -> Dict[str, bool]:
    """æ¸²æŸ“æ¨¡å‹é€‰æ‹©ç•Œé¢
    
    Returns:
        Dict: æ¨¡å‹å¯ç”¨çŠ¶æ€
    """
    st.markdown("### ğŸ¤– AIæ¨¡å‹é€‰æ‹©")
    
    config = FactoryConfig.get_assembly_config()
    
    col1, col2, col3 = st.columns(3)
    
    models = {}
    
    with col1:
        models["google_cloud"] = st.checkbox(
            "ğŸŒ©ï¸ Google Cloud Video Intelligence",
            value=config["google_cloud_enabled"],
            help="ä½¿ç”¨Google Cloudè¿›è¡Œè§†é¢‘åˆ†æ",
            key="assembly_model_google_cloud"
        )
    
    with col2:
        models["qwen"] = st.checkbox(
            "ğŸ¤– Qwenæ¨¡å‹",
            value=config["qwen_enabled"],
            help="ä½¿ç”¨Qwenè¿›è¡Œè§†è§‰ç†è§£åˆ†æ",
            key="assembly_model_qwen"
        )
    
    with col3:
        models["deepseek"] = st.checkbox(
            "ğŸ§  DeepSeekæ¨¡å‹",
            value=config["deepseek_enabled"],
            help="ä½¿ç”¨DeepSeekè¿›è¡Œæ™ºèƒ½åˆ†æå…œåº•",
            key="assembly_model_deepseek"
        )
    
    return models 


def render_prompt_configuration() -> None:
    """æ¸²æŸ“ä¼˜åŒ–çš„AIæ¨¡å‹ä¸ä¸šåŠ¡é€»è¾‘é…ç½®ç•Œé¢"""
    st.markdown("### ğŸ¯ æ™ºèƒ½é…ç½®ä¸­å¿ƒ")
    
    st.info("""
    ğŸ” **é…ç½®é€»è¾‘è¯´æ˜**ï¼š
    1. **AIè¯†åˆ«è¯åº“** â†’ å®šä¹‰AIèƒ½"çœ‹åˆ°"å’Œ"å¬åˆ°"ä»€ä¹ˆ
    2. **ä¸šåŠ¡åˆ†ç±»è§„åˆ™** â†’ å®šä¹‰è¯†åˆ«ç»“æœå¦‚ä½•æ˜ å°„åˆ°ä¸šåŠ¡æ¨¡å—
    3. **Prompté¢„è§ˆ** â†’ æŸ¥çœ‹æœ€ç»ˆç”Ÿæˆçš„AIæŒ‡ä»¤
    """)
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs([
        "ğŸ¤– AIè¯†åˆ«è¯åº“", 
        "ğŸ” Prompté¢„è§ˆ"
    ])
    
    with tab1:
        _render_ai_recognition_config()
        
    with tab2:
        _render_prompt_previews()


def _render_ai_recognition_config() -> None:
    """æ¸²æŸ“AIè¯†åˆ«é…ç½®ç•Œé¢ - é€šç”¨é…ç½®ç½®é¡¶è®¾è®¡"""
    import time
    
    st.markdown("#### ğŸ¤– AIè¯†åˆ«è¯åº“é…ç½®")
    st.write("é…ç½®AIæ¨¡å‹è¯†åˆ«è§†é¢‘å†…å®¹æ—¶ä½¿ç”¨çš„åŸºç¡€è¯æ±‡è¡¨")
    
    st.info("""
    ğŸ“ **ç¼–è¾‘è¯´æ˜**: æ¯ä¸ªå­—æ®µéƒ½å¯ä»¥ç‹¬ç«‹ç¼–è¾‘å’Œä¿å­˜ï¼Œä¿®æ”¹åç‚¹å‡»å¯¹åº”çš„ä¿å­˜æŒ‰é’®å³å¯ç”Ÿæ•ˆ
    """)
    
    try:
        from utils.optimized_keyword_manager import keyword_manager
        current_config = keyword_manager.get_ai_recognition_config()
    except ImportError:
        st.error("æ— æ³•å¯¼å…¥ä¼˜åŒ–çš„å…³é”®è¯ç®¡ç†å™¨ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return

    # =============================================================================
    # ğŸŒ é€šç”¨AIé…ç½® (ç½®é¡¶æ˜¾ç¤º)
    # =============================================================================
    st.markdown("---")
    st.markdown("### ğŸŒ é€šç”¨AIé…ç½®")
    st.info("**è§†è§‰å’ŒéŸ³é¢‘AIå…±äº«çš„é…ç½®**ï¼Œä¿®æ”¹ååŒæ—¶å½±å“ä¸¤ä¸ªAIæ¨¡å‹çš„è¯†åˆ«èƒ½åŠ›")
    
    # ğŸ¯ æ ¸å¿ƒå“ç‰Œé…ç½®
    st.write("**ğŸ¯ æ ¸å¿ƒå“ç‰Œé…ç½® (è§†è§‰+éŸ³é¢‘AIå…±ç”¨):**")
    current_brands = current_config.get("shared", {}).get("brands", [])
    brands_str = ", ".join(current_brands)
    
    # æ˜¾ç¤ºå½“å‰å·²ä¿å­˜çš„æ ‡ç­¾
    if current_brands:
        st.markdown("**ğŸ“‹ å½“å‰å·²ä¿å­˜çš„æ ¸å¿ƒå“ç‰Œ:**")
        # å°†æ ‡ç­¾æŒ‰è¡Œæ˜¾ç¤ºï¼Œæ¯è¡Œæœ€å¤š5ä¸ª
        brand_chunks = [current_brands[i:i+5] for i in range(0, len(current_brands), 5)]
        for chunk in brand_chunks:
            cols = st.columns(len(chunk))
            for i, brand in enumerate(chunk):
                with cols[i]:
                    st.code(brand, language=None)
    else:
        st.info("ğŸ’¡ å°šæœªé…ç½®æ ¸å¿ƒå“ç‰Œï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥æ¡†ä¸­æ·»åŠ ")
    
    new_brands_str = st.text_area(
        "ğŸ¯ æ ¸å¿ƒå“ç‰Œç†å¿µ (æƒé‡ 2.0):",
        value=brands_str,
        placeholder="illuma, å¯èµ‹, æƒ æ°, è•´æ·³, A2",
        help="è§†è§‰AIè¯†åˆ«logoæ ‡è¯†ï¼ŒéŸ³é¢‘AIè¯†åˆ«å“ç‰Œåç§°æåŠ",
        key="shared_brands",
        height=80
    )
    
    # ä¿å­˜å“ç‰ŒæŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜æ ¸å¿ƒå“ç‰Œ", key="save_brands", type="primary"):
        new_brands_list = [kw.strip() for kw in new_brands_str.split(",") if kw.strip()]
        try:
            updated_config = current_config.copy()
            if "shared" not in updated_config:
                updated_config["shared"] = {}
            updated_config["shared"]["brands"] = new_brands_list
            keyword_manager.save_ai_recognition_config(updated_config)
            st.success("âœ… æ ¸å¿ƒå“ç‰Œå·²ä¿å­˜! (åº”ç”¨äºè§†è§‰+éŸ³é¢‘AI)")
            st.info("ğŸ”„ æ ‡ç­¾å·²æ›´æ–°ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ˜¾ç¤ºçš„å½“å‰æ ‡ç­¾")
            st.rerun()
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥: {e}")

    # ğŸ­ æƒ…ç»ªè¯åº“é…ç½® (åˆ†æ­£é¢è´Ÿé¢)
    st.write("**ğŸ­ æƒ…ç»ªè¯åº“é…ç½® (è§†è§‰+éŸ³é¢‘AIå…±ç”¨):**")
    
    # ä¿®æ”¹ä¸ºä»ai_batch.emotionè·å–
    shared_config = current_config.get("shared", {})
    ai_batch = shared_config.get("ai_batch", {})
    emotion_items = ai_batch.get("emotion", [])
    
    # æå–wordå­—æ®µ
    current_emotions = []
    for item in emotion_items:
        if isinstance(item, dict):
            word = item.get("word", "")
            if word:
                current_emotions.append(word)
        else:
            current_emotions.append(str(item))
    
    # å¦‚æœæ²¡æœ‰ai_batchæ ¼å¼ï¼Œå°è¯•ä¼ ç»Ÿemotionså­—æ®µä½œä¸ºå…œåº•
    if not current_emotions:
        current_emotions = shared_config.get("emotions", [])
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ˜Š æ­£é¢æƒ…ç»ª:**")
        
        # æ˜¾ç¤ºå½“å‰å·²ä¿å­˜çš„æ­£é¢æƒ…ç»ªæ ‡ç­¾
        if current_emotions:
            st.markdown("**ğŸ“‹ å½“å‰æ­£é¢æƒ…ç»ªæ ‡ç­¾:**")
            emotion_chunks = [current_emotions[i:i+3] for i in range(0, len(current_emotions), 3)]
            for chunk in emotion_chunks:
                emotion_cols = st.columns(len(chunk))
                for i, emotion in enumerate(chunk):
                    with emotion_cols[i]:
                        st.code(emotion, language=None)
        else:
            st.info("ğŸ’¡ å°šæœªé…ç½®æ­£é¢æƒ…ç»ªï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥")
        
        positive_str = ", ".join(current_emotions)
        new_positive_str = st.text_area(
            "ğŸ§  æƒ…ç»ªä¸ç—›ç‚¹ (æƒé‡ 1.0):",
            value=positive_str,
            height=120,
            help="ç§¯æã€æ­£å‘çš„æƒ…ç»ªè¯æ±‡ï¼Œå¦‚ï¼šå¿«ä¹ã€å¼€å¿ƒã€æ´»åŠ›æ»¡æ»¡",
            key="positive_emotions"
        )
    
    with col2:
        st.write("**ğŸ˜Ÿ è´Ÿé¢æƒ…ç»ª:**")
        
        # æ˜¾ç¤ºå½“å‰å·²ä¿å­˜çš„è´Ÿé¢æƒ…ç»ªæ ‡ç­¾
        if current_emotions:
            st.markdown("**ğŸ“‹ å½“å‰è´Ÿé¢æƒ…ç»ªæ ‡ç­¾:**")
            neg_emotion_chunks = [emotion for emotion in current_emotions if emotion not in positive_emotions]
            neg_emotion_chunks = neg_emotion_chunks[:3]
            for chunk in neg_emotion_chunks:
                neg_emotion_cols = st.columns(1)
                with neg_emotion_cols[0]:
                    st.code(chunk, language=None)
        else:
            st.info("ğŸ’¡ å°šæœªé…ç½®è´Ÿé¢æƒ…ç»ªï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥")
        
        negative_str = ", ".join(neg_emotion_chunks)
        new_negative_str = st.text_area(
            "ğŸ” åœºæ™¯ä¸ç—›ç‚¹ (æƒé‡ 1.0):",
            value=negative_str,
            height=120,
            help="æ¶ˆæã€è´Ÿå‘çš„æƒ…ç»ªè¯æ±‡ï¼Œå¦‚ï¼šç„¦è™‘ã€ç—›è‹¦ã€å“­é—¹",
            key="negative_emotions"
        )
    
    # ä¿å­˜æƒ…ç»ªè¯åº“æŒ‰é’®
    if st.button("ğŸ’¾ ä¿å­˜æƒ…ç»ªè¯åº“", key="save_shared_emotions", type="primary"):
        positive_list = [emo.strip() for emo in new_positive_str.split(",") if emo.strip()]
        negative_list = [emo.strip() for emo in new_negative_str.split(",") if emo.strip()]
        combined_emotions = positive_list + negative_list
        
        if len(combined_emotions) < 10:
            st.warning(f"æƒ…ç»ªè¯åº“è¾ƒå°‘ï¼Œå»ºè®®è‡³å°‘10ä¸ªï¼Œå½“å‰ä¸º{len(combined_emotions)}ä¸ª")
        
        try:
            updated_config = current_config.copy()
            if "shared" not in updated_config:
                updated_config["shared"] = {}
            if "ai_batch" not in updated_config["shared"]:
                updated_config["shared"]["ai_batch"] = {}
            
            # ä¿å­˜ä¸ºai_batchæ ¼å¼
            emotion_batch = [{"word": word, "weight": 2} for word in combined_emotions]
            updated_config["shared"]["ai_batch"]["emotion"] = emotion_batch
            
            # ä¸ºäº†å…¼å®¹æ€§ï¼Œä¹Ÿä¿ç•™traditionalæ ¼å¼
            updated_config["shared"]["emotions"] = combined_emotions
            
            keyword_manager.save_ai_recognition_config(updated_config)
            st.success(f"âœ… æƒ…ç»ªè¯åº“å·²ä¿å­˜! å…±{len(combined_emotions)}ä¸ªæƒ…ç»ªè¯æ±‡ (æ­£é¢:{len(positive_list)}, è´Ÿé¢:{len(negative_list)})")
            st.info("ğŸ”„ æ ‡ç­¾å·²æ›´æ–°ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ˜¾ç¤ºçš„å½“å‰æ ‡ç­¾")
            st.rerun()
        except Exception as e:
            st.error(f"ä¿å­˜å¤±è´¥: {e}")

    # é€šç”¨é…ç½®ç»Ÿè®¡
    st.markdown("**ğŸ“Š é€šç”¨é…ç½®ç»Ÿè®¡:**")
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    with col_stat1:
        brands_count = len(current_config.get("shared", {}).get("brands", []))
        st.metric("æ ¸å¿ƒå“ç‰Œ", brands_count)
    with col_stat2:
        # ä¼˜å…ˆä»ai_batchè·å–ï¼Œå…œåº•ç”¨ä¼ ç»Ÿemotions
        shared_config = current_config.get("shared", {})
        ai_batch = shared_config.get("ai_batch", {})
        emotion_items = ai_batch.get("emotion", [])
        emotions_count = len(emotion_items) if emotion_items else len(shared_config.get("emotions", []))
        st.metric("æƒ…ç»ªè¯æ±‡", emotions_count)
    with col_stat3:
        positive_count = len(positive_emotions)
        negative_count = len(negative_emotions)
        st.metric("æ­£é¢/è´Ÿé¢", f"{positive_count}/{negative_count}")

    # =============================================================================
    # ğŸ” è§†è§‰AIé…ç½®
    # =============================================================================
    
    # ä¸»é…ç½®åŒºåŸŸ - é‡‡ç”¨å·¦å³åˆ†æ è®¾è®¡
    st.markdown("### ğŸ‘ï¸ è§†è§‰AI (Qwen) è¯†åˆ«è¯åº“")
    
    # å·¦å³åˆ†æ 
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ… æ­£é¢è§„åˆ™")
        
        # åŸºç¡€å¯¹è±¡é…ç½®
        st.write("**ğŸ“¦ åŸºç¡€è¯†åˆ«å¯¹è±¡ (æƒé‡ 2.0):**")
        
        # æ˜¾ç¤ºå½“å‰å·²ä¿å­˜çš„åŸºç¡€å¯¹è±¡æ ‡ç­¾
        current_basic_objects = current_config["visual"]["objects_basic"]
        if current_basic_objects:
            st.markdown("**ğŸ“‹ å½“å‰åŸºç¡€è¯†åˆ«å¯¹è±¡:**")
            basic_chunks = [current_basic_objects[i:i+3] for i in range(0, len(current_basic_objects), 3)]
            for chunk in basic_chunks:
                basic_cols = st.columns(len(chunk))
                for i, obj in enumerate(chunk):
                    with basic_cols[i]:
                        st.code(obj, language=None)
        else:
            st.info("ğŸ’¡ å°šæœªé…ç½®åŸºç¡€è¯†åˆ«å¯¹è±¡ï¼Œè¯·åœ¨ä¸‹æ–¹è¾“å…¥")
        
        basic_objects_str = ", ".join(current_basic_objects)
        new_basic_objects_str = st.text_area(
            "åŸºç¡€è¯†åˆ«è¯åº“ (ç”¨é€—å·åˆ†éš”)",
            value=basic_objects_str,
            key="qwen_basic_objects",
            height=80,
            help="AIè¯†åˆ«çš„åŸºç¡€è§†è§‰å¯¹è±¡ï¼Œå¦‚ï¼šå¥¶ç²‰ç½, å¥¶ç“¶, å®å®, å¦ˆå¦ˆ"
        )
        
        # ä¿å­˜åŸºç¡€å¯¹è±¡æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜åŸºç¡€å¯¹è±¡", key="save_basic_objects"):
            new_basic_list = [kw.strip() for kw in new_basic_objects_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["objects_basic"] = new_basic_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… åŸºç¡€å¯¹è±¡å·²ä¿å­˜!")
                st.info("ğŸ”„ æ ‡ç­¾å·²æ›´æ–°ï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ˜¾ç¤ºçš„å½“å‰æ ‡ç­¾")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # å“ç‰Œç›¸å…³å¯¹è±¡é…ç½®
        st.write("**ğŸ·ï¸ å“ç‰Œè¯†åˆ«å¯¹è±¡ (æƒé‡ 1.5):**")
        brand_objects_str = ", ".join(current_config["visual"]["objects_brand"])
        new_brand_objects_str = st.text_area(
            "ç¼–è¾‘å“ç‰Œè¯†åˆ«å¯¹è±¡",
            value=brand_objects_str,
            key="qwen_brand_objects",
            height=80,
            help="ä¸å“ç‰Œè¯†åˆ«ç›¸å…³çš„è§†è§‰å…ƒç´ ï¼Œå¦‚ï¼šå“ç‰Œlogo, åŒ…è£…, å•†æ ‡"
        )
        
        # ä¿å­˜å“ç‰Œå¯¹è±¡æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜å“ç‰Œå¯¹è±¡", key="save_brand_objects"):
            new_brand_list = [kw.strip() for kw in new_brand_objects_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["objects_brand"] = new_brand_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… å“ç‰Œå¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # æˆåˆ†ç›¸å…³å¯¹è±¡é…ç½®
        st.write("**ğŸ§ª æˆåˆ†è¯†åˆ«å¯¹è±¡ (æƒé‡ 1.5):**")
        comp_objects_str = ", ".join(current_config["visual"]["objects_composition"])
        new_comp_objects_str = st.text_area(
            "ç¼–è¾‘æˆåˆ†è¯†åˆ«å¯¹è±¡",
            value=comp_objects_str,
            key="qwen_comp_objects",
            height=80,
            help="è¥å…»æˆåˆ†å’Œé…æ–™è¡¨ç›¸å…³å¯¹è±¡ï¼Œå¦‚ï¼šæˆåˆ†è¡¨, è¥å…»è¡¨, é…æ–™è¡¨"
        )
        
        # ä¿å­˜æˆåˆ†å¯¹è±¡æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜æˆåˆ†å¯¹è±¡", key="save_comp_objects"):
            new_comp_list = [kw.strip() for kw in new_comp_objects_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["objects_composition"] = new_comp_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… æˆåˆ†å¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # åŒ»ç–—å¯¹è±¡é…ç½®
        st.write("**ğŸ¥ åŒ»ç–—ç›¸å…³å¯¹è±¡ (æƒé‡ 1.0):**")
        medical_objects_str = ", ".join(current_config["visual"].get("objects_medical", []))
        new_medical_objects_str = st.text_area(
            "ç¼–è¾‘åŒ»ç–—ç›¸å…³å¯¹è±¡",
            value=medical_objects_str,
            key="qwen_medical_objects",
            height=80,
            help="åŒ»ç–—åœºæ™¯ç›¸å…³å¯¹è±¡ï¼Œå¦‚ï¼šè¾“æ¶²ç®¡, ç—…åºŠ, åŒ»ç–—è®¾å¤‡, è¯å“"
        )
        
        # ä¿å­˜åŒ»ç–—å¯¹è±¡æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜åŒ»ç–—å¯¹è±¡", key="save_medical_objects"):
            new_medical_list = [kw.strip() for kw in new_medical_objects_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["objects_medical"] = new_medical_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… åŒ»ç–—å¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    
    with col2:
        st.subheader("ğŸï¸ åœºæ™¯ä¸ä¿¡å·")
        
        # åœºæ™¯é…ç½®
        st.write("**ğŸï¸ è¯†åˆ«åœºæ™¯ (æƒé‡ 1.0):**")
        scenes_str = ", ".join(current_config["visual"]["scenes"])
        new_scenes_str = st.text_area(
            "ç¼–è¾‘è¯†åˆ«åœºæ™¯",
            value=scenes_str,
            key="qwen_scenes",
            height=80,
            help="AIè¯†åˆ«çš„åœºæ™¯ç¯å¢ƒï¼Œå¦‚ï¼šå¨æˆ¿, å®¢å…, åŒ»é™¢, æˆ·å¤–"
        )
        
        # ä¿å­˜åœºæ™¯æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜è¯†åˆ«åœºæ™¯", key="save_scenes"):
            new_scenes_list = [kw.strip() for kw in new_scenes_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["scenes"] = new_scenes_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… è¯†åˆ«åœºæ™¯å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # æƒ…æ„Ÿé…ç½®æç¤º - ä½¿ç”¨å…±ç”¨æƒ…ç»ª
        st.write("**ğŸ­ æƒ…æ„Ÿè¯†åˆ«é…ç½®:**")
        st.info("ğŸ’¡ è§†è§‰AIä½¿ç”¨ä¸Šæ–¹å…±ç”¨æƒ…ç»ªé…ç½®ï¼Œæ— éœ€å•ç‹¬è®¾ç½®")
        
        # åœºæ™¯ç»†åˆ†é…ç½®
        st.markdown("---")
        st.write("**ğŸ  åœºæ™¯ç»†åˆ†é…ç½®:**")
        
        # å®¤å†…åœºæ™¯
        indoor_scenes_str = ", ".join(current_config["visual"].get("scenes_indoor", []))
        new_indoor_scenes_str = st.text_area(
            "ğŸ  å®¤å†…åœºæ™¯",
            value=indoor_scenes_str,
            key="qwen_indoor_scenes",
            height=70,
            help="å®¤å†…ç¯å¢ƒåœºæ™¯ï¼Œå¦‚ï¼šå¨æˆ¿, å®¢å…, å§å®¤, å©´å„¿æˆ¿"
        )
        
        # æˆ·å¤–åœºæ™¯
        outdoor_scenes_str = ", ".join(current_config["visual"].get("scenes_outdoor", []))
        new_outdoor_scenes_str = st.text_area(
            "ğŸŒ³ æˆ·å¤–åœºæ™¯",
            value=outdoor_scenes_str,
            key="qwen_outdoor_scenes",
            height=70,
            help="æˆ·å¤–ç¯å¢ƒåœºæ™¯ï¼Œå¦‚ï¼šå…¬å›­, æ¸¸ä¹åœº, æ»‘æ¢¯, è¹¦åºŠ"
        )
        
        # åŒ»ç–—åœºæ™¯
        medical_scenes_str = ", ".join(current_config["visual"].get("scenes_medical", []))
        new_medical_scenes_str = st.text_area(
            "ğŸ¥ åŒ»ç–—åœºæ™¯",
            value=medical_scenes_str,
            key="qwen_medical_scenes",
            height=70,
            help="åŒ»ç–—ç¯å¢ƒåœºæ™¯ï¼Œå¦‚ï¼šåŒ»é™¢, ç—…æˆ¿, è¯Šæ‰€"
        )
        
        # æ¼”ç¤ºåœºæ™¯
        demo_scenes_str = ", ".join(current_config["visual"].get("scenes_demonstration", []))
        new_demo_scenes_str = st.text_area(
            "ğŸ“¹ æ¼”ç¤ºåœºæ™¯",
            value=demo_scenes_str,
            key="qwen_demo_scenes",
            height=70,
            help="äº§å“æ¼”ç¤ºåœºæ™¯ï¼Œå¦‚ï¼šå°é¢æ“ä½œ, äº§å“æ¼”ç¤º, å†²å¥¶æ¼”ç¤º"
        )
        
        # ä¿å­˜åœºæ™¯ç»†åˆ†æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜åœºæ™¯ç»†åˆ†", key="save_scene_details"):
            try:
                updated_config = current_config.copy()
                updated_config["visual"]["scenes_indoor"] = [s.strip() for s in new_indoor_scenes_str.split(",") if s.strip()]
                updated_config["visual"]["scenes_outdoor"] = [s.strip() for s in new_outdoor_scenes_str.split(",") if s.strip()]
                updated_config["visual"]["scenes_medical"] = [s.strip() for s in new_medical_scenes_str.split(",") if s.strip()]
                updated_config["visual"]["scenes_demonstration"] = [s.strip() for s in new_demo_scenes_str.split(",") if s.strip()]
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… åœºæ™¯ç»†åˆ†å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    


    # è§†è§‰é…ç½®ç»Ÿè®¡
    st.markdown("---")
    st.subheader("ğŸ“Š è§†è§‰AIé…ç½®ç»Ÿè®¡")
    
    col_stat1, col_stat2, col_stat3, col_stat4, col_stat5, col_stat6 = st.columns(6)
    
    with col_stat1:
        basic_count = len(current_config["visual"]["objects_basic"])
        st.metric("åŸºç¡€è¯†åˆ«å¯¹è±¡", basic_count)
    
    with col_stat2:
        brand_obj_count = len(current_config["visual"]["objects_brand"])
        st.metric("å“ç‰Œè¯†åˆ«å¯¹è±¡", brand_obj_count)
    
    with col_stat3:
        comp_obj_count = len(current_config["visual"]["objects_composition"])
        st.metric("æˆåˆ†è¯†åˆ«å¯¹è±¡", comp_obj_count)
    
    with col_stat4:
        medical_obj_count = len(current_config["visual"].get("objects_medical", []))
        st.metric("åŒ»ç–—ç›¸å…³å¯¹è±¡", medical_obj_count)
    
    with col_stat5:
        scenes_count = len(current_config["visual"]["scenes"])
        st.metric("è¯†åˆ«åœºæ™¯", scenes_count)
    
    with col_stat6:
        brands_count = len(current_config["visual"]["brands"])
        st.metric("æ ¸å¿ƒå“ç‰Œ", brands_count)
    

    
    # éŸ³é¢‘AIé…ç½®
    st.markdown("---")
    st.markdown("### ğŸ¤ éŸ³é¢‘AI (DeepSeek) è¯†åˆ«è¯åº“")
    
    # å·¦å³åˆ†æ  - ä¸è§†è§‰AIä¿æŒä¸€è‡´çš„ç»“æ„
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("âœ… æ­£é¢è§„åˆ™")
        
        # éŸ³é¢‘å¯¹è±¡é…ç½®
        st.write("**ğŸ“¦ åŸºç¡€è¯†åˆ«å¯¹è±¡ (æƒé‡ 2.0):**")
        audio_objects_str = ", ".join(current_config["audio"]["objects"])
        new_audio_objects_str = st.text_area(
            "ç¼–è¾‘åŸºç¡€è¯†åˆ«å¯¹è±¡",
            value=audio_objects_str,
            key="deepseek_objects",
            height=80,
            help="AIä»éŸ³é¢‘ä¸­è¯†åˆ«çš„å¯¹è±¡ï¼Œå¦‚ï¼šå¥¶ç²‰, å®å®, å¦ˆå¦ˆ"
        )
        
        # ä¿å­˜éŸ³é¢‘å¯¹è±¡æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜åŸºç¡€å¯¹è±¡", key="save_audio_objects"):
            new_audio_objects_list = [kw.strip() for kw in new_audio_objects_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["audio"]["objects"] = new_audio_objects_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… åŸºç¡€å¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # å“ç‰ŒæåŠé…ç½®
        st.write("**ğŸ·ï¸ å“ç‰Œè¯†åˆ«å¯¹è±¡ (æƒé‡ 1.5):**")
        brand_mentions_str = ", ".join(current_config["audio"].get("brand_mentions", []))
        new_brand_mentions_str = st.text_area(
            "ç¼–è¾‘å“ç‰Œè¯†åˆ«å¯¹è±¡",
            value=brand_mentions_str,
            key="deepseek_brand_mentions",
            height=80,
            help="éŸ³é¢‘ä¸­æåŠçš„å“ç‰Œåç§°ï¼Œå¦‚ï¼šå¯èµ‹, æƒ æ°, è•´æ·³"
        )
        
        # ä¿å­˜å“ç‰ŒæåŠæŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜å“ç‰Œå¯¹è±¡", key="save_brand_mentions"):
            new_brand_mentions_list = [kw.strip() for kw in new_brand_mentions_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                if "brand_mentions" not in updated_config["audio"]:
                    updated_config["audio"]["brand_mentions"] = []
                updated_config["audio"]["brand_mentions"] = new_brand_mentions_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… å“ç‰Œå¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # äº§å“ç‰¹æ€§é…ç½®
        st.write("**ğŸ§ª æˆåˆ†è¯†åˆ«å¯¹è±¡ (æƒé‡ 1.5):**")
        product_features_str = ", ".join(current_config["audio"].get("product_features", []))
        new_product_features_str = st.text_area(
            "ç¼–è¾‘æˆåˆ†è¯†åˆ«å¯¹è±¡",
            value=product_features_str,
            key="deepseek_product_features",
            height=80,
            help="äº§å“ç‰¹æ€§å’Œæˆåˆ†æè¿°ï¼Œå¦‚ï¼šA2è›‹ç™½, DHA, è¥å…»æˆåˆ†"
        )
        
        # ä¿å­˜äº§å“ç‰¹æ€§æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜æˆåˆ†å¯¹è±¡", key="save_product_features"):
            new_product_features_list = [kw.strip() for kw in new_product_features_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                if "product_features" not in updated_config["audio"]:
                    updated_config["audio"]["product_features"] = []
                updated_config["audio"]["product_features"] = new_product_features_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… æˆåˆ†å¯¹è±¡å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    
    with col2:
        st.subheader("ğŸï¸ åœºæ™¯ä¸ä¿¡å·")
        
        # éŸ³é¢‘åœºæ™¯é…ç½®
        st.write("**ğŸ¤ éŸ³é¢‘è¯†åˆ«åœºæ™¯ (æƒé‡ 1.0):**")
        audio_scenes_str = ", ".join(current_config["audio"]["scenes"])
        new_audio_scenes_str = st.text_area(
            "ç¼–è¾‘éŸ³é¢‘è¯†åˆ«åœºæ™¯",
            value=audio_scenes_str,
            key="deepseek_scenes",
            height=80,
            help="AIä»éŸ³é¢‘ä¸­è¯†åˆ«çš„åœºæ™¯ï¼Œå¦‚ï¼šå†²å¥¶æ¼”ç¤º, ç»éªŒåˆ†äº«, äº§å“æµ‹è¯„"
        )
        
        # ä¿å­˜éŸ³é¢‘åœºæ™¯æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜éŸ³é¢‘åœºæ™¯", key="save_audio_scenes"):
            new_audio_scenes_list = [kw.strip() for kw in new_audio_scenes_str.split(",") if kw.strip()]
            try:
                updated_config = current_config.copy()
                updated_config["audio"]["scenes"] = new_audio_scenes_list
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… éŸ³é¢‘åœºæ™¯å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
        
        # æƒ…æ„Ÿé…ç½®æç¤º - ä½¿ç”¨å…±ç”¨æƒ…ç»ª
        st.write("**ğŸ­ æƒ…æ„Ÿè¯†åˆ«é…ç½®:**")
        st.info("ğŸ’¡ éŸ³é¢‘AIä½¿ç”¨ä¸Šæ–¹å…±ç”¨æƒ…ç»ªé…ç½®ï¼Œæ— éœ€å•ç‹¬è®¾ç½®")
        
        # éŸ³é¢‘åœºæ™¯ç»†åˆ†é…ç½®
        st.markdown("---")
        st.write("**ğŸ¤ éŸ³é¢‘åœºæ™¯ç»†åˆ†é…ç½®:**")
        
        # å–‚å…»åœºæ™¯
        feeding_scenes_str = ", ".join(current_config["audio"].get("scenes_feeding", []))
        new_feeding_scenes_str = st.text_area(
            "ğŸ¼ å–‚å…»åœºæ™¯",
            value=feeding_scenes_str,
            key="deepseek_feeding_scenes",
            height=70,
            help="å–‚å…»ç›¸å…³åœºæ™¯ï¼Œå¦‚ï¼šå†²å¥¶æ¼”ç¤º, å–‚å¥¶æ—¶åˆ», è¾…é£Ÿåˆ¶ä½œ, å†²è°ƒ"
        )
        
        # äº’åŠ¨åœºæ™¯
        interaction_scenes_str = ", ".join(current_config["audio"].get("scenes_interaction", []))
        new_interaction_scenes_str = st.text_area(
            "ğŸ¤ äº’åŠ¨åœºæ™¯",
            value=interaction_scenes_str,
            key="deepseek_interaction_scenes",
            height=70,
            help="äº²å­äº’åŠ¨åœºæ™¯ï¼Œå¦‚ï¼šäº²å­æ¸¸æˆ, ç¡å‰å‡†å¤‡, æˆ·å¤–æ´»åŠ¨"
        )
        
        # åˆ†äº«åœºæ™¯
        sharing_scenes_str = ", ".join(current_config["audio"].get("scenes_sharing", []))
        new_sharing_scenes_str = st.text_area(
            "ğŸ“¢ åˆ†äº«åœºæ™¯",
            value=sharing_scenes_str,
            key="deepseek_sharing_scenes",
            height=70,
            help="ç»éªŒåˆ†äº«åœºæ™¯ï¼Œå¦‚ï¼šç»éªŒåˆ†äº«, å¥½ç‰©æ¨è, äº§å“æµ‹è¯„, ç­”ç–‘è§£æƒ‘"
        )
        
        # ç”Ÿæ´»åœºæ™¯
        lifestyle_scenes_str = ", ".join(current_config["audio"].get("scenes_lifestyle", []))
        new_lifestyle_scenes_str = st.text_area(
            "ğŸ  ç”Ÿæ´»åœºæ™¯",
            value=lifestyle_scenes_str,
            key="deepseek_lifestyle_scenes",
            height=70,
            help="æ—¥å¸¸ç”Ÿæ´»åœºæ™¯ï¼Œå¦‚ï¼šæ—¥å¸¸vlog, å±…å®¶ç”Ÿæ´», æˆé•¿è®°å½•, è¸©é›·é¿å‘"
        )
        
        # ä¿å­˜éŸ³é¢‘åœºæ™¯ç»†åˆ†æŒ‰é’®
        if st.button("ğŸ’¾ ä¿å­˜éŸ³é¢‘åœºæ™¯ç»†åˆ†", key="save_audio_scene_details"):
            try:
                updated_config = current_config.copy()
                updated_config["audio"]["scenes_feeding"] = [s.strip() for s in new_feeding_scenes_str.split(",") if s.strip()]
                updated_config["audio"]["scenes_interaction"] = [s.strip() for s in new_interaction_scenes_str.split(",") if s.strip()]
                updated_config["audio"]["scenes_sharing"] = [s.strip() for s in new_sharing_scenes_str.split(",") if s.strip()]
                updated_config["audio"]["scenes_lifestyle"] = [s.strip() for s in new_lifestyle_scenes_str.split(",") if s.strip()]
                keyword_manager.save_ai_recognition_config(updated_config)
                st.success("âœ… éŸ³é¢‘åœºæ™¯ç»†åˆ†å·²ä¿å­˜!")
                st.rerun()
            except Exception as e:
                st.error(f"ä¿å­˜å¤±è´¥: {e}")
    
    # éŸ³é¢‘é…ç½®ç»Ÿè®¡
    st.markdown("---")
    st.subheader("ğŸ“Š éŸ³é¢‘AIé…ç½®ç»Ÿè®¡")
    
    col_stat1, col_stat2, col_stat3, col_stat4, col_stat5 = st.columns(5)
    
    with col_stat1:
        audio_obj_count = len(current_config["audio"]["objects"])
        st.metric("åŸºç¡€è¯†åˆ«å¯¹è±¡", audio_obj_count)
    
    with col_stat2:
        audio_scenes_count = len(current_config["audio"]["scenes"])
        st.metric("è¯†åˆ«åœºæ™¯", audio_scenes_count)
    
    with col_stat3:
        brand_mentions_count = len(current_config["audio"].get("brand_mentions", []))
        st.metric("å“ç‰Œè¯†åˆ«å¯¹è±¡", brand_mentions_count)
    
    with col_stat4:
        product_features_count = len(current_config["audio"].get("product_features", []))
        st.metric("æˆåˆ†è¯†åˆ«å¯¹è±¡", product_features_count)
    
    with col_stat5:
        # æƒ…æ„Ÿè¯æ±‡å·²ç»Ÿä¸€åˆ°å…±ç”¨é…ç½®ï¼Œæ­¤å¤„æ˜¾ç¤ºå…±ç”¨æƒ…ç»ªæ•°é‡
        shared_config = current_config.get("shared", {})
        ai_batch = shared_config.get("ai_batch", {})
        emotion_items = ai_batch.get("emotion", [])
        shared_emotions_count = len(emotion_items) if emotion_items else len(shared_config.get("emotions", []))
        st.metric("å…±ç”¨æƒ…æ„Ÿè¯æ±‡", shared_emotions_count)


def _render_prompt_previews() -> None:
    """æ¸²æŸ“AIæ¨¡å‹Prompté¢„è§ˆç•Œé¢"""
    st.markdown("#### ğŸ“ AIæ¨¡å‹Prompté¢„è§ˆ")
    st.write("æ ¹æ®å½“å‰é…ç½®ç”Ÿæˆçš„AIæ¨¡å‹æŒ‡ä»¤é¢„è§ˆï¼ˆåªè¯»ï¼‰")
    try:
        from utils.keyword_config import get_qwen_visual_prompt, get_deepseek_audio_prompt
        qwen_prompt = get_qwen_visual_prompt()
        deepseek_prompt = get_deepseek_audio_prompt()

        with st.expander("ğŸ‘ï¸ Qwenè§†è§‰åˆ†æPrompt", expanded=True):
            st.code(qwen_prompt, language="text")
            st.caption(f"Prompté•¿åº¦: {len(qwen_prompt)} å­—ç¬¦")
        with st.expander("ğŸ§  DeepSeekéŸ³é¢‘åˆ†æPrompt", expanded=False):
            st.code(deepseek_prompt, language="text")
            st.caption(f"Prompté•¿åº¦: {len(deepseek_prompt)} å­—ç¬¦")

        # é…ç½®æ•ˆæœåˆ†æç­‰å¯ä¿ç•™åŸæœ‰é€»è¾‘
    except Exception as e:
        st.error(f"Prompté¢„è§ˆå¤±è´¥: {e}")
        st.info("è¯·ç¡®ä¿é…ç½®æ­£ç¡®å¹¶å·²ä¿å­˜") 