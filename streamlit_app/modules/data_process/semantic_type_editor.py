"""
è¯­ä¹‰ç±»å‹å®šä¹‰ç¼–è¾‘å™¨æ¨¡å—
ç”¨äºé…ç½®å’Œç®¡ç†å„ä¸ªè¯­ä¹‰ç±»å‹çš„è¯¦ç»†å®šä¹‰
"""

import streamlit as st
import json
import copy
from typing import Dict, List, Any

from config.config import (
    get_semantic_type_definitions, 
    DEFAULT_SEMANTIC_TYPE_DEFINITIONS,
    DEFAULT_SEMANTIC_SEGMENT_TYPES,
    USER_CONFIG_FILE
)

@st.cache_data(ttl=60)
def load_semantic_definitions() -> Dict[str, Any]:
    """åŠ è½½è¯­ä¹‰ç±»å‹å®šä¹‰ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
    return get_semantic_type_definitions()

def save_semantic_definitions(definitions: Dict[str, Any]) -> bool:
    """ä¿å­˜è¯­ä¹‰ç±»å‹å®šä¹‰åˆ°ç”¨æˆ·é…ç½®æ–‡ä»¶
    
    Args:
        definitions: è¯­ä¹‰ç±»å‹å®šä¹‰å­—å…¸
        
    Returns:
        bool: ä¿å­˜æ˜¯å¦æˆåŠŸ
    """
    try:
        # è¯»å–ç°æœ‰é…ç½®
        try:
            with open(USER_CONFIG_FILE, "r", encoding="utf-8") as f:
                user_config = json.load(f)
        except (FileNotFoundError, json.JSONDecodeError):
            user_config = {}
        
        # æ›´æ–°è¯­ä¹‰ç±»å‹å®šä¹‰
        user_config["SEMANTIC_TYPE_DEFINITIONS"] = definitions
        
        # ä¿å­˜é…ç½®
        with open(USER_CONFIG_FILE, "w", encoding="utf-8") as f:
            json.dump(user_config, f, ensure_ascii=False, indent=2)
        
        # æ¸…é™¤ç¼“å­˜ä»¥ä¾¿é‡æ–°åŠ è½½
        load_semantic_definitions.clear()
        
        return True
    except Exception as e:
        st.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")
        return False

def render_semantic_type_editor():
    """æ¸²æŸ“è¯­ä¹‰ç±»å‹ç¼–è¾‘å™¨ç•Œé¢"""
    
    st.markdown("### ğŸ“ è¯­ä¹‰ç±»å‹è®¾ç½®")
    st.markdown("é…ç½®è§†é¢‘ç‰‡æ®µçš„è¯­ä¹‰åˆ†ç±»å‹ï¼Œç”¨äºè‡ªåŠ¨åˆ†æç»„ç»‡è§†é¢‘å†…å®¹ã€‚")
    
    # åŠ è½½å½“å‰å®šä¹‰
    current_definitions = load_semantic_definitions()
    
    # åˆ›å»ºç¼–è¾‘çŠ¶æ€
    if "semantic_definitions_editing" not in st.session_state:
        st.session_state.semantic_definitions_editing = copy.deepcopy(current_definitions)
    
    # é‡ç½®æŒ‰é’®
    col1, col2, col3 = st.columns([1, 1, 2])
    
    with col1:
        if st.button("ğŸ”„ é‡ç½®ä¸ºé»˜è®¤", help="æ¢å¤åˆ°ç³»ç»Ÿé»˜è®¤çš„è¯­ä¹‰ç±»å‹å®šä¹‰"):
            st.session_state.semantic_definitions_editing = copy.deepcopy(DEFAULT_SEMANTIC_TYPE_DEFINITIONS)
            st.rerun()
    
    with col2:
        if st.button("ğŸ’¾ ä¿å­˜é…ç½®", help="ä¿å­˜å½“å‰çš„è¯­ä¹‰ç±»å‹å®šä¹‰"):
            if save_semantic_definitions(st.session_state.semantic_definitions_editing):
                st.success("âœ… è¯­ä¹‰ç±»å‹å®šä¹‰å·²ä¿å­˜ï¼")
                st.balloons()
            else:
                st.error("âŒ ä¿å­˜å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
    
    st.markdown("---")
    
    # è¯­ä¹‰ç±»å‹åˆ—è¡¨
    st.markdown("#### ğŸ“‹ å½“å‰è¯­ä¹‰ç±»å‹")
    
    # æ˜¾ç¤ºæ•ˆæœé¢„è§ˆ
    with st.expander("ğŸ“Š é¢„è§ˆæ•ˆæœ", expanded=False):
        st.markdown("è§†é¢‘ç‰‡æ®µå°†æŒ‰ä»¥ä¸‹ç±»å‹è¿›è¡Œåˆ†æï¼š")
        for type_name in DEFAULT_SEMANTIC_SEGMENT_TYPES:
            definition = st.session_state.semantic_definitions_editing.get(type_name, {})
            st.markdown(f"- **{type_name}**: {definition.get('description', 'æœªå®šä¹‰')[:50]}...")
    
    # ç¼–è¾‘ç•Œé¢
    st.markdown("#### âœï¸ ç¼–è¾‘è¯­ä¹‰ç±»å‹å®šä¹‰")
    
    # ç±»å‹é€‰æ‹©
    selected_type = st.selectbox(
        "é€‰æ‹©è¦ç¼–è¾‘çš„è¯­ä¹‰ç±»å‹ï¼š",
        options=DEFAULT_SEMANTIC_SEGMENT_TYPES,
        help="é€‰æ‹©è¦ä¿®æ”¹å®šä¹‰çš„è¯­ä¹‰ç±»å‹"
    )
    
    if selected_type:
        # è·å–å½“å‰å®šä¹‰
        current_def = st.session_state.semantic_definitions_editing.get(selected_type, {
            "name": selected_type,
            "description": "",
            "keywords": [],
            "examples": []
        })
        
        # ç¼–è¾‘è¡¨å•
        with st.form(f"edit_semantic_type_{selected_type}"):
            st.markdown(f"##### ğŸ¯ ç¼–è¾‘ã€Œ{selected_type}ã€")
            
            # ç±»å‹åç§°ï¼ˆåªè¯»æ˜¾ç¤ºï¼‰
            st.text_input("ç±»å‹åç§°", value=current_def.get("name", selected_type), disabled=True)
            
            # æè¿°
            description = st.text_area(
                "è¯¦ç»†æè¿°",
                value=current_def.get("description", ""),
                height=120,
                help="è¯¦ç»†æè¿°è¯¥è¯­ä¹‰ç±»å‹çš„ç‰¹å¾ã€ç”¨é€”å’Œè¯†åˆ«è¦ç‚¹",
                placeholder="ä¾‹å¦‚ï¼šè§†é¢‘çš„èµ·å§‹éƒ¨åˆ†ï¼Œç”¨äºå¸å¼•è§‚ä¼—ã€å¼•å…¥å“ç‰Œæˆ–å¥ å®šè§†é¢‘åŸºè°ƒ..."
            )
            
            # å…³é”®è¯
            keywords_text = st.text_area(
                "å…³é”®è¯åˆ—è¡¨ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰",
                value="\n".join(current_def.get("keywords", [])),
                height=80,
                help="è¾“å…¥ç”¨äºè¯†åˆ«è¯¥ç±»å‹çš„å…³é”®è¯ï¼Œæ¯è¡Œä¸€ä¸ª",
                placeholder="å¼€åœºç™½\nå“ç‰Œä»‹ç»\nslogan"
            )
            
            # ç¤ºä¾‹
            examples_text = st.text_area(
                "ç¤ºä¾‹æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€ä¸ªå…¸å‹è¡¨è¾¾æ¨¡å¼ï¼‰",
                value="\n".join(current_def.get("examples", [])),
                height=100,
                help="è¾“å…¥å…¸å‹çš„è¡¨è¾¾æ¨¡å¼ï¼Œæ¯è¡Œä¸€ä¸ªç‹¬ç«‹çš„è¡¨è¾¾æ–¹å¼ï¼Œä¸è¦è¾“å…¥è¿è´¯çš„æ®µè½",
                placeholder="å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯xxx\nä»Šå¤©è¦ç»™å¤§å®¶ä»‹ç»\nå¯èµ‹å¥¶ç²‰å¸¦æ¥\næ¬¢è¿å¤§å®¶å…³æ³¨\næ„Ÿè°¢è§‚çœ‹"
            )
            
            # ğŸ†• æ·»åŠ ç¤ºä¾‹è¯´æ˜
            st.info("""
            ğŸ’¡ **ç¤ºä¾‹æ–‡æœ¬æœ€ä½³å®è·µ**ï¼š
            
            âœ… **æ¨èåšæ³•**ï¼ˆæ¯è¡Œä¸€ç§è¡¨è¾¾æ¨¡å¼ï¼‰ï¼š
            ```
            å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯xxx
            ä»Šå¤©è¦ç»™å¤§å®¶ä»‹ç»  
            å¯èµ‹å¥¶ç²‰å¸¦æ¥
            æ¬¢è¿è§‚çœ‹ä»Šå¤©çš„è§†é¢‘
            æ„Ÿè°¢å¤§å®¶çš„å…³æ³¨
            ```
            
            âŒ **ä¸æ¨è**ï¼ˆè¿è´¯æ®µè½ï¼‰ï¼š
            ```
            å¤§å®¶å¥½ï¼Œæˆ‘æ˜¯xxxã€‚ä»Šå¤©è¦ç»™å¤§å®¶ä»‹ç»å¯èµ‹å¥¶ç²‰å¸¦æ¥çš„è¥å…»ä»·å€¼ï¼Œæ¬¢è¿è§‚çœ‹ä»Šå¤©çš„è§†é¢‘ï¼Œæ„Ÿè°¢å¤§å®¶çš„å…³æ³¨ã€‚
            ```
            
            **åŸå› **ï¼šæ¯è¡Œä»£è¡¨ä¸€ç§å…¸å‹è¡¨è¾¾æ¨¡å¼ï¼Œè®©LLMèƒ½å­¦ä¹ åˆ°å¤šç§ä¸åŒçš„è¡¨è¾¾æ–¹å¼ï¼Œæé«˜è¯†åˆ«å‡†ç¡®æ€§ã€‚
            """)
            
            # ä¿å­˜æŒ‰é’®
            col1, col2 = st.columns([1, 3])
            with col1:
                submitted = st.form_submit_button("ğŸ’¾ ä¿å­˜ä¿®æ”¹", use_container_width=True)
            
            if submitted:
                # å¤„ç†å…³é”®è¯å’Œç¤ºä¾‹
                keywords = [kw.strip() for kw in keywords_text.split("\n") if kw.strip()]
                examples = [ex.strip() for ex in examples_text.split("\n") if ex.strip()]
                
                # æ›´æ–°å®šä¹‰
                st.session_state.semantic_definitions_editing[selected_type] = {
                    "name": selected_type,
                    "description": description.strip(),
                    "keywords": keywords,
                    "examples": examples
                }
                
                st.success(f"âœ… ã€Œ{selected_type}ã€å®šä¹‰å·²æ›´æ–°ï¼è®°å¾—ç‚¹å‡»ä¸Šæ–¹çš„ã€ŒğŸ’¾ ä¿å­˜é…ç½®ã€æŒ‰é’®æŒä¹…åŒ–ä¿å­˜ã€‚")
                st.rerun()
        
        # æ˜¾ç¤ºå½“å‰å®šä¹‰é¢„è§ˆ
        with st.expander(f"ğŸ“– ã€Œ{selected_type}ã€å½“å‰å®šä¹‰é¢„è§ˆ", expanded=True):
            def_preview = st.session_state.semantic_definitions_editing.get(selected_type, {})
            
            st.markdown(f"**æè¿°**: {def_preview.get('description', 'æœªå®šä¹‰')}")
            
            if def_preview.get('keywords'):
                st.markdown(f"**å…³é”®è¯**: {', '.join(def_preview['keywords'])}")
            
            if def_preview.get('examples'):
                st.markdown("**ç¤ºä¾‹**:")
                for example in def_preview['examples']:
                    st.markdown(f"- {example}")

def render_semantic_type_quick_actions():
    """æ¸²æŸ“å¿«é€Ÿæ“ä½œé¢æ¿"""
    st.markdown("#### âš¡ å¿«é€Ÿæ“ä½œ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“¥ å¯¼å…¥é…ç½®", help="ä»JSONæ–‡ä»¶å¯¼å…¥è¯­ä¹‰ç±»å‹å®šä¹‰"):
            uploaded_file = st.file_uploader(
                "é€‰æ‹©é…ç½®æ–‡ä»¶",
                type=["json"],
                key="semantic_import"
            )
            if uploaded_file:
                try:
                    imported_config = json.load(uploaded_file)
                    if "SEMANTIC_TYPE_DEFINITIONS" in imported_config:
                        st.session_state.semantic_definitions_editing = imported_config["SEMANTIC_TYPE_DEFINITIONS"]
                        st.success("âœ… é…ç½®å¯¼å…¥æˆåŠŸï¼")
                    else:
                        st.error("âŒ æ–‡ä»¶æ ¼å¼ä¸æ­£ç¡®")
                except Exception as e:
                    st.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    
    with col2:
        if st.button("ğŸ“¤ å¯¼å‡ºé…ç½®", help="å¯¼å‡ºå½“å‰è¯­ä¹‰ç±»å‹å®šä¹‰"):
            export_data = {
                "SEMANTIC_TYPE_DEFINITIONS": st.session_state.get("semantic_definitions_editing", current_definitions)
            }
            st.download_button(
                label="ä¸‹è½½é…ç½®æ–‡ä»¶",
                data=json.dumps(export_data, ensure_ascii=False, indent=2),
                file_name="semantic_type_definitions.json",
                mime="application/json"
            )
    
    with col3:
        if st.button("ğŸ” éªŒè¯é…ç½®", help="æ£€æŸ¥å½“å‰é…ç½®çš„å®Œæ•´æ€§"):
            editing_defs = st.session_state.get("semantic_definitions_editing", {})
            missing_types = []
            
            for type_name in DEFAULT_SEMANTIC_SEGMENT_TYPES:
                if type_name not in editing_defs or not editing_defs[type_name].get("description"):
                    missing_types.append(type_name)
            
            if missing_types:
                st.warning(f"âš ï¸ ä»¥ä¸‹ç±»å‹ç¼ºå°‘è¯¦ç»†å®šä¹‰: {', '.join(missing_types)}")
            else:
                st.success("âœ… æ‰€æœ‰è¯­ä¹‰ç±»å‹éƒ½å·²é…ç½®å®Œæ•´ï¼") 