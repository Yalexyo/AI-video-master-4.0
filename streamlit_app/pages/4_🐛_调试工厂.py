import streamlit as st
import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
import pandas as pd

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="ğŸ› è°ƒè¯•å·¥å‚ - AIè§†é¢‘æ··å‰ªç³»ç»Ÿ",
    page_icon="ğŸ›",
    layout="wide"
)

def main():
    """è°ƒè¯•å·¥å‚ä¸»ç•Œé¢"""
    
    st.title("ğŸ› è°ƒè¯•å·¥å‚")
    st.markdown("**å®æ—¶æŸ¥çœ‹æ˜ å°„æœºåˆ¶ã€è¿‡æ»¤è§„åˆ™å’Œé€‰ç‰‡è¿‡ç¨‹çš„è¯¦ç»†ä¿¡æ¯**")
    
    # ä¾§è¾¹æ  - è°ƒè¯•é€‰é¡¹
    with st.sidebar:
        st.header("ğŸ”§ è°ƒè¯•é€‰é¡¹")
        
        debug_mode = st.selectbox(
            "é€‰æ‹©è°ƒè¯•æ¨¡å¼",
            ["æ˜ å°„è§„åˆ™æ£€æŸ¥", "è¿‡æ»¤æœºåˆ¶æµ‹è¯•", "é€‰ç‰‡å†³ç­–æ—¥å¿—"]
        )
        
        st.markdown("---")
    
    # ä¸»è¦å†…å®¹åŒºåŸŸ
    if debug_mode == "æ˜ å°„è§„åˆ™æ£€æŸ¥":
        render_mapping_rules_debug()
    elif debug_mode == "è¿‡æ»¤æœºåˆ¶æµ‹è¯•":
        render_filter_mechanism_debug()
    elif debug_mode == "é€‰ç‰‡å†³ç­–æ—¥å¿—":
        render_selection_decision_log()

def render_mapping_rules_debug():
    """æ¸²æŸ“æ˜ å°„è§„åˆ™è°ƒè¯•ç•Œé¢"""
    st.header("ğŸ“‹ æ˜ å°„è§„åˆ™è¯¦ç»†æ£€æŸ¥")
    
    # æ˜¾ç¤ºå½“å‰å·¥ä½œç›®å½•å’Œé…ç½®æ–‡ä»¶è·¯å¾„ä¿¡æ¯
    current_dir = os.getcwd()
    st.info(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: {current_dir}")
    
    # å°è¯•ä¸¤ä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶è·¯å¾„
    config_paths = [
        "../config/matching_rules.json",  # é¡¹ç›®æ ¹ç›®å½•
        "config/matching_rules.json"      # streamlit_appç›®å½•
    ]
    
    config_file = None
    for path in config_paths:
        abs_path = os.path.abspath(path)
        st.info(f"ğŸ“ æ£€æŸ¥é…ç½®æ–‡ä»¶: {path} -> {abs_path} (å­˜åœ¨: {os.path.exists(path)})")
        if os.path.exists(path):
            config_file = path
            break
    
    if not config_file:
        st.error("âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ config/matching_rules.json")
        return
    
    # åŠ è½½é…ç½®æ–‡ä»¶
    try:        
        with open(config_file, 'r', encoding='utf-8') as f:
            matching_rules = json.load(f)
    except Exception as e:
        st.error(f"åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        st.info("ä½¿ç”¨é»˜è®¤é…ç½®ç»§ç»­è¿è¡Œ...")
        # æ˜¾ç¤ºé»˜è®¤é…ç½®ç¤ºä¾‹
        st.code("""
{
  "ç—›ç‚¹": {
    "object_keywords": ["å¦ˆå¦ˆ", "å®å®"],
    "negative_keywords": ["é«˜é€Ÿå…¬è·¯", "çº¢ç»¿ç¯", "é©¾é©¶"]
  }
}
        """, language="json")
        return
    
    # é…ç½®åŠ è½½æˆåŠŸï¼Œç»§ç»­å¤„ç†
    try:
            
        st.success(f"âœ… ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_file}")
        
        # æ˜¾ç¤ºæ–‡ä»¶çŠ¶æ€ä¿¡æ¯
        try:
            file_stat = os.stat(config_file)
            mod_time = datetime.fromtimestamp(file_stat.st_mtime)
            st.info(f"ğŸ“… é…ç½®æ–‡ä»¶æœ€åä¿®æ”¹: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
            st.info(f"ğŸ“¦ æ–‡ä»¶å¤§å°: {file_stat.st_size} bytes")
        except Exception as e:
            st.warning(f"æ— æ³•è·å–æ–‡ä»¶ä¿¡æ¯: {e}")
            
        # æ·»åŠ å®æ—¶éªŒè¯æŒ‰é’®
        if st.button("ğŸ”„ åˆ·æ–°é…ç½®æ–‡ä»¶çŠ¶æ€", key="refresh_config_status"):
            st.rerun()
            
        # æ˜¾ç¤ºå„æ¨¡å—çš„è§„åˆ™
        modules = ["ç—›ç‚¹", "è§£å†³æ–¹æ¡ˆå¯¼å…¥", "å–ç‚¹Â·æˆåˆ†&é…æ–¹", "ä¿ƒé”€æœºåˆ¶"]
        
        for module in modules:
            if module in matching_rules:
                with st.expander(f"ğŸ“‹ **{module}** å®Œæ•´è§„åˆ™", expanded=True):
                    rules = matching_rules[module]
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("âœ… æ­£é¢è§„åˆ™")
                        
                        # ğŸ”§ å¯ç¼–è¾‘çš„å…³é”®è¯é…ç½®
                        keyword_types = [
                            ("object_keywords", "å¯¹è±¡å…³é”®è¯"),
                            ("sence_keywords", "åœºæ™¯å…³é”®è¯"), 
                            ("emotion_keywords", "æƒ…æ„Ÿå…³é”®è¯"),
                            ("required_keywords", "å¿…éœ€å…³é”®è¯")
                        ]
                        
                        for kw_type, kw_name in keyword_types:
                            st.write(f"**{kw_name}:**")
                            current_keywords = rules.get(kw_type, [])
                            
                            keywords_str = ", ".join(current_keywords)
                            new_keywords_str = st.text_area(
                                f"ç¼–è¾‘ {module} {kw_name}",
                                value=keywords_str,
                                key=f"edit_{kw_type}_{module}",
                                height=80
                            )
                            
                            if st.button(f"ğŸ’¾ ä¿å­˜ {kw_name}", key=f"save_{kw_type}_{module}"):
                                new_keywords_list = [kw.strip() for kw in new_keywords_str.split(",") if kw.strip()]
                                
                                # æ›´æ–°é…ç½®
                                matching_rules[module][kw_type] = new_keywords_list
                                
                                # ä¿å­˜åˆ°æ–‡ä»¶
                                try:
                                    # è®°å½•ä¿å­˜å‰çš„æ–‡ä»¶æ—¶é—´
                                    old_time = os.path.getmtime(config_file) if os.path.exists(config_file) else 0
                                    
                                    with open(config_file, 'w', encoding='utf-8') as f:
                                        json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                                    
                                    # éªŒè¯ä¿å­˜æ˜¯å¦æˆåŠŸ
                                    if os.path.exists(config_file):
                                        new_time = os.path.getmtime(config_file)
                                        time_str = datetime.fromtimestamp(new_time).strftime("%H:%M:%S")
                                        
                                        if new_time > old_time:
                                            st.balloons()  # æ·»åŠ æ°”çƒåŠ¨ç”»
                                            st.success(f"ğŸ‰ {module} {kw_name} ä¿å­˜æˆåŠŸ!")
                                            st.success(f"â° æ–‡ä»¶æ›´æ–°æ—¶é—´: {time_str}")
                                            st.success(f"ğŸ“Š æ–°å…³é”®è¯æ•°é‡: {len(new_keywords_list)}")
                                        else:
                                            st.warning("âš ï¸ æ–‡ä»¶æ—¶é—´æœªæ›´æ–°ï¼Œå¯èƒ½ä¿å­˜å¤±è´¥")
                                    else:
                                        st.error(f"âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
                                    
                                    # çŸ­æš‚å»¶è¿Ÿååˆ·æ–°
                                    import time
                                    time.sleep(0.5)
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ğŸ’¥ ä¿å­˜å¤±è´¥: {e}")
                                    st.error(f"ğŸ“ é…ç½®æ–‡ä»¶è·¯å¾„: {config_file}")
                                    st.error(f"ğŸ” æ–‡ä»¶æ˜¯å¦å­˜åœ¨: {os.path.exists(config_file)}")
                                    st.error(f"âœï¸ å°è¯•å†™å…¥çš„å†…å®¹é•¿åº¦: {len(str(matching_rules))}")
                    
                    with col2:
                        st.subheader("âŒ è´Ÿé¢è§„åˆ™")
                        
                        if rules.get("negative_keywords"):
                            st.write("**æ’é™¤å…³é”®è¯:**")
                            negative_list = rules["negative_keywords"]
                            
                            # ğŸ”§ æ·»åŠ ç¼–è¾‘åŠŸèƒ½
                            negative_str = ", ".join(negative_list)
                            new_negative_str = st.text_area(
                                f"ç¼–è¾‘ {module} æ’é™¤å…³é”®è¯",
                                value=negative_str,
                                key=f"edit_negative_{module}",
                                height=80,
                                help="ä¿®æ”¹åç‚¹å‡»ä¿å­˜æŒ‰é’®"
                            )
                            
                            # ä¿å­˜æŒ‰é’®
                            if st.button(f"ğŸ’¾ ä¿å­˜ {module} æ’é™¤å…³é”®è¯", key=f"save_negative_{module}"):
                                new_negative_list = [kw.strip() for kw in new_negative_str.split(",") if kw.strip()]
                                
                                # æ›´æ–°é…ç½®
                                matching_rules[module]["negative_keywords"] = new_negative_list
                                
                                # ä¿å­˜åˆ°æ–‡ä»¶
                                try:
                                    with open(config_file, 'w', encoding='utf-8') as f:
                                        json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                                    st.success(f"âœ… {module} æ’é™¤å…³é”®è¯å·²ä¿å­˜!")
                                    st.rerun()
                                except Exception as e:
                                    st.error(f"ä¿å­˜å¤±è´¥: {e}")
                            
                            # ğŸ”¥ é‡ç‚¹çªå‡ºæ’é™¤å…³é”®è¯
                            if "é«˜é€Ÿå…¬è·¯" in negative_list or "çº¢ç»¿ç¯" in negative_list:
                                st.error("âš ï¸ **å‘ç°é«˜é€Ÿå…¬è·¯/çº¢ç»¿ç¯æ’é™¤è§„åˆ™!**")
                                st.write("è¿™äº›å…³é”®è¯åº”è¯¥è¢«è¿‡æ»¤ï¼Œå¦‚æœä»ç„¶å‡ºç°è¯·æ£€æŸ¥è¿‡æ»¤é€»è¾‘!")
                        else:
                            st.info("è¯¥æ¨¡å—æ²¡æœ‰é…ç½®æ’é™¤å…³é”®è¯")
                            
                            # ä¸ºæ²¡æœ‰æ’é™¤å…³é”®è¯çš„æ¨¡å—æ·»åŠ æ–°å¢åŠŸèƒ½
                            new_negative_str = st.text_area(
                                f"æ·»åŠ  {module} æ’é™¤å…³é”®è¯",
                                value="",
                                key=f"add_negative_{module}",
                                height=80,
                                placeholder="è¾“å…¥è¦æ’é™¤çš„å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”"
                            )
                            
                            if st.button(f"â• æ·»åŠ  {module} æ’é™¤å…³é”®è¯", key=f"add_save_negative_{module}"):
                                if new_negative_str.strip():
                                    new_negative_list = [kw.strip() for kw in new_negative_str.split(",") if kw.strip()]
                                    
                                    # æ›´æ–°é…ç½®
                                    matching_rules[module]["negative_keywords"] = new_negative_list
                                    
                                    # ä¿å­˜åˆ°æ–‡ä»¶
                                    try:
                                        with open(config_file, 'w', encoding='utf-8') as f:
                                            json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                                        st.success(f"âœ… {module} æ’é™¤å…³é”®è¯å·²æ·»åŠ !")
                                        st.rerun()
                                    except Exception as e:
                                        st.error(f"ä¿å­˜å¤±è´¥: {e}")
                                else:
                                    st.warning("è¯·è¾“å…¥è¦æ·»åŠ çš„å…³é”®è¯")
                        
                        # æ˜¾ç¤ºæƒé‡å’Œé˜ˆå€¼
                        st.write("**æƒé‡é…ç½®:**")
                        if rules.get("weights"):
                            for weight_type, value in rules["weights"].items():
                                st.write(f"- {weight_type}: {value}")
                        
                        st.write("**è´¨é‡é˜ˆå€¼:**")
                        st.write(f"- æœ€å°è´¨é‡: {rules.get('min_quality', 'æœªè®¾ç½®')}")
                        st.write(f"- æœ€å°åˆ†æ•°: {rules.get('min_score_threshold', 'æœªè®¾ç½®')}")
        
        # å…¨å±€è¿‡æ»¤è§„åˆ™
        if "GLOBAL_SETTINGS" in matching_rules:
            st.header("ğŸŒ å…¨å±€è¿‡æ»¤è§„åˆ™")
            
            global_settings = matching_rules["GLOBAL_SETTINGS"]
            
            # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºå…¨å±€æ’é™¤å…³é”®è¯
            if "global_exclusion_keywords" in global_settings:
                st.subheader("ğŸš« å…¨å±€æ’é™¤å…³é”®è¯")
                current_global_keywords = global_settings["global_exclusion_keywords"]
                st.code(", ".join(current_global_keywords))
                st.warning("âš ï¸ è¿™äº›å…³é”®è¯ä¼šå¯¼è‡´ç‰‡æ®µè¢«å…¨å±€è¿‡æ»¤ï¼Œä¸åˆ†æ¨¡å—")
                
                # ç¼–è¾‘å…¨å±€æ’é™¤å…³é”®è¯
                global_exclusion_str = ", ".join(current_global_keywords)
                new_global_exclusion_str = st.text_area(
                    "ç¼–è¾‘å…¨å±€æ’é™¤å…³é”®è¯",
                    value=global_exclusion_str,
                    key="edit_global_exclusion",
                    help="åŒ…å«è¿™äº›å…³é”®è¯çš„ç‰‡æ®µå°†è¢«å®Œå…¨è¿‡æ»¤"
                )
                
                if st.button("ğŸ’¾ ä¿å­˜å…¨å±€æ’é™¤å…³é”®è¯", key="save_global_exclusion"):
                    new_keywords = [kw.strip() for kw in new_global_exclusion_str.split(",") if kw.strip()]
                    matching_rules["GLOBAL_SETTINGS"]["global_exclusion_keywords"] = new_keywords
                    
                    try:
                        with open(config_file, 'w', encoding='utf-8') as f:
                            json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                        st.success("âœ… å…¨å±€æ’é™¤å…³é”®è¯å·²ä¿å­˜!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¿å­˜å¤±è´¥: {e}")
            
            # ğŸ”§ æ–°å¢ï¼šæ˜¾ç¤ºåˆ†æ®µçº¦æŸ
            if "max_segments_per_module" in global_settings:
                st.subheader("ğŸ”¢ åˆ†æ®µçº¦æŸè®¾ç½®")
                current_max = global_settings["max_segments_per_module"]
                st.info(f"æ¯ä¸ªæ¨¡å—æœ€å¤§ç‰‡æ®µæ•°: **{current_max}** ä¸ª")
                st.caption("è¿™ä¸ªè®¾ç½®é˜²æ­¢å•ä¸ªæ¨¡å—æœ‰è¿‡å¤šç‰‡æ®µæ‹¼æ¥ï¼Œä¿æŒè§†é¢‘æµç•…æ€§")
                
                new_max = st.number_input(
                    "è®¾ç½®æ¯æ¨¡å—æœ€å¤§ç‰‡æ®µæ•°",
                    min_value=1,
                    max_value=10,
                    value=current_max,
                    key="max_segments_input"
                )
                
                if st.button("ğŸ’¾ ä¿å­˜åˆ†æ®µçº¦æŸ", key="save_max_segments"):
                    matching_rules["GLOBAL_SETTINGS"]["max_segments_per_module"] = new_max
                    
                    try:
                        with open(config_file, 'w', encoding='utf-8') as f:
                            json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                        st.success(f"âœ… åˆ†æ®µçº¦æŸå·²ä¿å­˜: æ¯æ¨¡å—æœ€å¤š {new_max} ä¸ªç‰‡æ®µ!")
                        st.rerun()
                    except Exception as e:
                        st.error(f"ä¿å­˜å¤±è´¥: {e}")
            
            # ä¸ç›¸å…³åœºæ™¯åˆ†ç±»
            st.subheader("ğŸŒ ä¸ç›¸å…³åœºæ™¯åˆ†ç±»")
            irrelevant_categories = global_settings.get("irrelevant_scene_categories", {})
            
            for category, keywords in irrelevant_categories.items():
                with st.expander(f"ğŸš« {category} (å…¨å±€æ’é™¤)", expanded=False):
                    # æ˜¾ç¤ºå½“å‰å…³é”®è¯
                    keywords_str = ", ".join(keywords)
                    new_global_keywords_str = st.text_area(
                        f"ç¼–è¾‘ {category} å…¨å±€æ’é™¤å…³é”®è¯",
                        value=keywords_str,
                        key=f"edit_global_{category}",
                        height=80
                    )
                    
                    if st.button(f"ğŸ’¾ ä¿å­˜ {category} å…¨å±€æ’é™¤", key=f"save_global_{category}"):
                        new_global_keywords_list = [kw.strip() for kw in new_global_keywords_str.split(",") if kw.strip()]
                        
                        # æ›´æ–°é…ç½®
                        matching_rules["GLOBAL_SETTINGS"]["irrelevant_scene_categories"][category] = new_global_keywords_list
                        
                        # ä¿å­˜åˆ°æ–‡ä»¶
                        try:
                            with open(config_file, 'w', encoding='utf-8') as f:
                                json.dump(matching_rules, f, ensure_ascii=False, indent=2)
                            st.success(f"âœ… {category} å…¨å±€æ’é™¤å…³é”®è¯å·²ä¿å­˜!")
                            st.rerun()
                        except Exception as e:
                            st.error(f"ä¿å­˜å¤±è´¥: {e}")
                    
                    # æ£€æŸ¥å…³é”®è¯
                    if any(kw in ["é«˜é€Ÿå…¬è·¯", "çº¢ç»¿ç¯", "é«˜é€Ÿ", "é©¬è·¯", "é“è·¯", "äº¤é€š"] for kw in keywords):
                        st.error("ğŸš¨ **åŒ…å«äº¤é€šç›¸å…³æ’é™¤è¯!** è¿™äº›åº”è¯¥è¢«å…¨å±€è¿‡æ»¤!")
        
        # ğŸ“‹ é…ç½®æ–‡ä»¶éªŒè¯åŒºåŸŸ
        st.markdown("---")
        st.header("ğŸ“‹ é…ç½®æ–‡ä»¶éªŒè¯")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ“ æ–‡ä»¶çŠ¶æ€æ£€æŸ¥")
            if st.button("ğŸ” æ£€æŸ¥é…ç½®æ–‡ä»¶", key="check_config_file"):
                try:
                    # æ£€æŸ¥ä¸¤ä¸ªå¯èƒ½çš„é…ç½®æ–‡ä»¶ä½ç½®
                    configs = [
                        ("é¡¹ç›®æ ¹ç›®å½•", "../config/matching_rules.json"),
                        ("Streamlitç›®å½•", "config/matching_rules.json")
                    ]
                    
                    for name, path in configs:
                        if os.path.exists(path):
                            stat = os.stat(path)
                            mod_time = datetime.fromtimestamp(stat.st_mtime)
                            st.success(f"âœ… {name}: {path}")
                            st.info(f"   ğŸ“… ä¿®æ”¹æ—¶é—´: {mod_time.strftime('%Y-%m-%d %H:%M:%S')}")
                            st.info(f"   ğŸ“¦ æ–‡ä»¶å¤§å°: {stat.st_size} bytes")
                        else:
                            st.error(f"âŒ {name}: {path} ä¸å­˜åœ¨")
                except Exception as e:
                    st.error(f"æ£€æŸ¥å¤±è´¥: {e}")
        
        with col2:
            st.subheader("ğŸ“ é…ç½®å¤‡ä»½")
            if st.button("ğŸ’¾ åˆ›å»ºé…ç½®å¤‡ä»½", key="backup_config"):
                try:
                    import shutil
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    backup_path = f"../config/matching_rules_backup_{timestamp}.json"
                    shutil.copy2(config_file, backup_path)
                    st.success(f"âœ… å¤‡ä»½å·²åˆ›å»º: {backup_path}")
                except Exception as e:
                    st.error(f"å¤‡ä»½å¤±è´¥: {e}")
        
        # ğŸ§ª å¿«é€Ÿæµ‹è¯•åŒºåŸŸ
        st.markdown("---")
        st.header("ğŸ§ª è§„åˆ™æµ‹è¯•éªŒè¯")
        st.info("ä¿®æ”¹è§„åˆ™åï¼Œç«‹å³æµ‹è¯•æ•ˆæœ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("ğŸ¯ å¿«é€Ÿæµ‹è¯•")
            quick_test_tags = st.text_input(
                "è¾“å…¥æµ‹è¯•æ ‡ç­¾ (é€—å·åˆ†éš”)",
                value="é«˜é€Ÿå…¬è·¯, çº¢ç»¿ç¯",
                key="quick_test_input"
            )
            
            if st.button("âš¡ å¿«é€Ÿæµ‹è¯•", key="quick_test_btn"):
                if quick_test_tags.strip():
                    test_tags = [tag.strip() for tag in quick_test_tags.split(",") if tag.strip()]
                    st.write("**æµ‹è¯•ç»“æœ:**")
                    
                    # æ‰§è¡Œæµ‹è¯•
                    try:
                        from streamlit_app.modules.mapper import VideoSegmentMapper
                        mapper = VideoSegmentMapper()
                        
                        result = mapper.classify_segment(test_tags)
                        tags_text = " ".join(test_tags).lower()
                        excluded = mapper._is_excluded_by_negative_keywords(tags_text)
                        
                        if excluded:
                            st.error(f"ğŸš« è¢«æ’é™¤è¿‡æ»¤: **{result}**")
                        else:
                            st.success(f"âœ… åˆ†ç±»ç»“æœ: **{result}**")
                    
                    except Exception as e:
                        st.error(f"æµ‹è¯•å¤±è´¥: {e}")
        
        with col2:
            st.subheader("ğŸ“Š é…ç½®çŠ¶æ€")
            st.metric("é…ç½®æ¨¡å—", len(modules))
            st.metric("å…¨å±€æ’é™¤ç±»åˆ«", len(irrelevant_categories) if "GLOBAL_SETTINGS" in matching_rules else 0)
            
            # æ˜¾ç¤ºæœ€è¿‘ä¿®æ”¹æ—¶é—´
            try:
                if os.path.exists(config_file):
                    mtime = os.path.getmtime(config_file)
                    mod_time = datetime.fromtimestamp(mtime).strftime("%Y-%m-%d %H:%M:%S")
                    st.info(f"é…ç½®æ–‡ä»¶æœ€åä¿®æ”¹: {mod_time}")
            except Exception as e:
                st.warning(f"æ— æ³•è·å–æ–‡ä»¶ä¿®æ”¹æ—¶é—´: {e}")
    
    except Exception as e:
        st.error(f"å¤„ç†é…ç½®æ–‡ä»¶æ—¶å‡ºç°é”™è¯¯: {e}")
        st.info("è¯·æ£€æŸ¥é…ç½®æ–‡ä»¶æ ¼å¼å’Œæƒé™...")

# å®æ—¶ç‰‡æ®µåˆ†æåŠŸèƒ½å·²åˆ é™¤ - å­˜åœ¨è·¯å¾„è¯†åˆ«é—®é¢˜

def analyze_single_segment(tags_list: List[str]):
    """åˆ†æå•ä¸ªç‰‡æ®µçš„è¯¦ç»†è¿‡ç¨‹"""
    st.subheader("ğŸ”¬ è¯¦ç»†åˆ†æè¿‡ç¨‹")
    
    # æ˜¾ç¤ºè¾“å…¥æ ‡ç­¾
    st.write("**è¾“å…¥æ ‡ç­¾:**")
    st.code(", ".join(tags_list))
    
    # æ‰§è¡Œåˆ†ç±»
    try:
        from streamlit_app.modules.mapper import VideoSegmentMapper
        mapper = VideoSegmentMapper()
        
        # åˆ†æ­¥éª¤åˆ†æ
        st.markdown("---")
        st.subheader("ğŸ“Š åˆ†ç±»æ­¥éª¤")
        
        # ç¬¬ä¸€æ­¥ï¼šæ£€æŸ¥æ’é™¤å…³é”®è¯
        st.write("**ğŸš« ç¬¬ä¸€æ­¥ï¼šæ’é™¤å…³é”®è¯æ£€æŸ¥**")
        
        # åŠ è½½æ’é™¤è§„åˆ™
        config_file = "../config/matching_rules.json"  # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®æ–‡ä»¶
        with open(config_file, 'r', encoding='utf-8') as f:
            matching_rules = json.load(f)
        
        exclusion_hits = []
        tags_text = " ".join(tags_list).lower()
        
        # æ£€æŸ¥æ¯ä¸ªæ¨¡å—çš„æ’é™¤å…³é”®è¯
        for module in ["ç—›ç‚¹", "è§£å†³æ–¹æ¡ˆå¯¼å…¥", "å–ç‚¹Â·æˆåˆ†&é…æ–¹", "ä¿ƒé”€æœºåˆ¶"]:
            if module in matching_rules:
                negative_keywords = matching_rules[module].get("negative_keywords", [])
                module_hits = []
                
                for neg_kw in negative_keywords:
                    if neg_kw.lower() in tags_text:
                        module_hits.append(neg_kw)
                
                if module_hits:
                    exclusion_hits.append((module, module_hits))
                    st.error(f"âŒ **{module}** è¢«æ’é™¤ - å‘½ä¸­å…³é”®è¯: {', '.join(module_hits)}")
                else:
                    st.success(f"âœ… **{module}** é€šè¿‡æ’é™¤æ£€æŸ¥")
        
        # æ£€æŸ¥å…¨å±€æ’é™¤
        st.write("**ğŸŒ å…¨å±€æ’é™¤æ£€æŸ¥:**")
        global_exclusions = []
        if "GLOBAL_SETTINGS" in matching_rules:
            irrelevant_categories = matching_rules["GLOBAL_SETTINGS"].get("irrelevant_scene_categories", {})
            
            for category, keywords in irrelevant_categories.items():
                category_hits = []
                for kw in keywords:
                    if kw.lower() in tags_text:
                        category_hits.append(kw)
                
                if category_hits:
                    global_exclusions.append((category, category_hits))
                    st.error(f"ğŸš¨ **å…¨å±€æ’é™¤ - {category}** å‘½ä¸­: {', '.join(category_hits)}")
        
        if not global_exclusions:
            st.success("âœ… é€šè¿‡å…¨å±€æ’é™¤æ£€æŸ¥")
        
        # ç¬¬äºŒæ­¥ï¼šå…³é”®è¯åˆ†ç±»
        st.markdown("---")
        st.write("**ğŸ¯ ç¬¬äºŒæ­¥ï¼šå…³é”®è¯åˆ†ç±»**")
        
        keyword_result = mapper.classify_segment_by_tags(tags_list)
        if keyword_result:
            st.success(f"âœ… å…³é”®è¯åˆ†ç±»ç»“æœ: **{keyword_result}**")
        else:
            st.warning("âš ï¸ å…³é”®è¯åˆ†ç±»æ— ç»“æœï¼Œå°†ä½¿ç”¨AIåˆ†ç±»")
        
        # ç¬¬ä¸‰æ­¥ï¼šAIåˆ†ç±» (å¦‚æœå…³é”®è¯åˆ†ç±»å¤±è´¥)
        if not keyword_result:
            st.write("**ğŸ¤– ç¬¬ä¸‰æ­¥ï¼šAIåˆ†ç±»**")
            ai_result = mapper.classify_segment_by_deepseek(tags_list)
            st.info(f"ğŸ¤– AIåˆ†ç±»ç»“æœ: **{ai_result}**")
        
        # æœ€ç»ˆç»“æœ
        st.markdown("---")
        st.subheader("ğŸ¯ æœ€ç»ˆåˆ†ç±»ç»“æœ")
        
        final_result = mapper.classify_segment(tags_list)
        
        # æ ¹æ®æ’é™¤æƒ…å†µç»™å‡ºè­¦å‘Š
        if exclusion_hits or global_exclusions:
            st.error(f"âš ï¸ **è­¦å‘Š**: ç‰‡æ®µè¢«åˆ†ç±»ä¸º **{final_result}**ï¼Œä½†å­˜åœ¨æ’é™¤å…³é”®è¯å†²çª!")
            st.error("**è¿™è¡¨æ˜æ’é™¤å…³é”®è¯è¿‡æ»¤æœºåˆ¶æ²¡æœ‰æ­£å¸¸å·¥ä½œ!**")
            
            # è¯¦ç»†è¯´æ˜é—®é¢˜
            st.markdown("**ğŸ› å‘ç°çš„é—®é¢˜:**")
            for module, hits in exclusion_hits:
                st.write(f"- {module} åº”è¯¥è¢«æ’é™¤ï¼Œä½†ä»å¯èƒ½è¢«é€‰ä¸­ (æ’é™¤è¯: {', '.join(hits)})")
            
            for category, hits in global_exclusions:
                st.write(f"- å…¨å±€æ’é™¤ {category} å‘½ä¸­ (æ’é™¤è¯: {', '.join(hits)})")
        else:
            st.success(f"ğŸ‰ æœ€ç»ˆåˆ†ç±»ç»“æœ: **{final_result}**")
    
    except Exception as e:
        st.error(f"åˆ†æè¿‡ç¨‹å‡ºé”™: {e}")
        st.exception(e)

def analyze_segment_detailed(segment: Dict[str, Any]):
    """è¯¦ç»†åˆ†æå·²æœ‰ç‰‡æ®µ"""
    st.subheader(f"ğŸ” ç‰‡æ®µè¯¦ç»†åˆ†æ: {segment.get('file_name', 'æœªçŸ¥')}")
    
    # æ˜¾ç¤ºç‰‡æ®µåŸºæœ¬ä¿¡æ¯
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("å½“å‰åˆ†ç±»", segment.get('category', 'æœªåˆ†ç±»'))
        st.metric("è´¨é‡åˆ†æ•°", f"{segment.get('combined_quality', 0):.2f}")
    
    with col2:
        st.metric("æ—¶é•¿", f"{segment.get('duration', 0):.1f}s")
        st.metric("ç½®ä¿¡åº¦", f"{segment.get('confidence', 0):.2f}")
    
    with col3:
        st.metric("äººè„¸ç‰¹å†™", "æ˜¯" if segment.get('is_face_close_up') else "å¦")
        st.metric("ä¸å¯ç”¨", "æ˜¯" if segment.get('unusable') else "å¦")
    
    # æ˜¾ç¤ºæ ‡ç­¾
    st.subheader("ğŸ·ï¸ ç‰‡æ®µæ ‡ç­¾")
    all_tags = segment.get('all_tags', [])
    if all_tags:
        st.code(", ".join(all_tags))
        
        # é‡æ–°åˆ†æè¿™äº›æ ‡ç­¾
        if st.button("ğŸ”„ é‡æ–°åˆ†æè¿™äº›æ ‡ç­¾"):
            analyze_single_segment(all_tags)
    else:
        st.warning("æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯")
    
    # æ˜¾ç¤ºè½¬å½•æ–‡æœ¬
    if segment.get('transcription'):
        st.subheader("ğŸ“ è½¬å½•æ–‡æœ¬")
        st.text_area("", segment['transcription'], height=100, disabled=True)

def render_filter_mechanism_debug():
    """æ¸²æŸ“è¿‡æ»¤æœºåˆ¶è°ƒè¯•ç•Œé¢"""
    st.header("ğŸ”¬ è¿‡æ»¤æœºåˆ¶æµ‹è¯•")
    
    st.info("æµ‹è¯•æ’é™¤å…³é”®è¯å’Œè¿‡æ»¤è§„åˆ™æ˜¯å¦æ­£å¸¸å·¥ä½œ")
    
    # æµ‹è¯•é…ç½®
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“‹ é€‰æ‹©æµ‹è¯•åœºæ™¯")
        
        test_scenarios = {
            "é«˜é€Ÿå…¬è·¯åœºæ™¯": ["æ±½è½¦", "é«˜é€Ÿå…¬è·¯", "é©¾é©¶", "æ–¹å‘ç›˜", "è½¦å†…"],
            "çº¢ç»¿ç¯åœºæ™¯": ["çº¢ç»¿ç¯", "äº¤é€š", "é©¬è·¯", "ç­‰å¾…", "è½¦è¾†"],
            "åŒ»é™¢åœºæ™¯": ["åŒ»é™¢", "ç—…æˆ¿", "æ‰“ç‚¹æ»´", "åŒ»ç”Ÿ", "ç—…åºŠ"],
            "æ­£å¸¸è‚²å„¿åœºæ™¯": ["å¦ˆå¦ˆ", "å®å®", "å¥¶ç²‰", "å®¢å…", "æ¸©é¦¨"],
            "å“ç‰Œå±•ç¤ºåœºæ™¯": ["å¯èµ‹", "å¥¶ç²‰ç½", "è¥å…»è¡¨", "é…æ–¹", "å“è´¨"]
        }
        
        selected_scenario = st.selectbox("é€‰æ‹©æµ‹è¯•åœºæ™¯", list(test_scenarios.keys()))
        scenario_tags = test_scenarios[selected_scenario]
        
        st.write("**åœºæ™¯æ ‡ç­¾:**")
        st.code(", ".join(scenario_tags))
    
    with col2:
        st.subheader("âš™ï¸ è‡ªå®šä¹‰æµ‹è¯•")
        
        custom_tags = st.text_area(
            "è‡ªå®šä¹‰æ ‡ç­¾ (é€—å·åˆ†éš”)",
            value="",
            height=100
        )
        
        use_custom = st.checkbox("ä½¿ç”¨è‡ªå®šä¹‰æ ‡ç­¾")
    
    # æ‰§è¡Œæµ‹è¯•
    if st.button("ğŸ§ª æ‰§è¡Œè¿‡æ»¤æµ‹è¯•", type="primary"):
        test_tags = custom_tags.split(",") if use_custom and custom_tags.strip() else scenario_tags
        test_tags = [tag.strip() for tag in test_tags if tag.strip()]
        
        st.markdown("---")
        st.subheader("ğŸ§ª æµ‹è¯•ç»“æœ")
        
        # åŠ è½½è§„åˆ™å¹¶æµ‹è¯•
        try:
            config_file = "../config/matching_rules.json"  # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„é…ç½®æ–‡ä»¶
            with open(config_file, 'r', encoding='utf-8') as f:
                matching_rules = json.load(f)
            
            tags_text = " ".join(test_tags).lower()
            
            # æµ‹è¯•æ¯ä¸ªæ¨¡å—çš„è¿‡æ»¤
            st.write("**ğŸ“‹ å„æ¨¡å—è¿‡æ»¤æµ‹è¯•:**")
            
            for module in ["ç—›ç‚¹", "è§£å†³æ–¹æ¡ˆå¯¼å…¥", "å–ç‚¹Â·æˆåˆ†&é…æ–¹", "ä¿ƒé”€æœºåˆ¶"]:
                if module in matching_rules:
                    negative_keywords = matching_rules[module].get("negative_keywords", [])
                    
                    blocked = False
                    blocking_keywords = []
                    
                    for neg_kw in negative_keywords:
                        if neg_kw.lower() in tags_text:
                            blocked = True
                            blocking_keywords.append(neg_kw)
                    
                    if blocked:
                        st.error(f"âŒ **{module}** - è¢«é˜»æ­¢ (å…³é”®è¯: {', '.join(blocking_keywords)})")
                    else:
                        st.success(f"âœ… **{module}** - é€šè¿‡è¿‡æ»¤")
            
            # æµ‹è¯•å…¨å±€è¿‡æ»¤
            st.write("**ğŸŒ å…¨å±€è¿‡æ»¤æµ‹è¯•:**")
            
            if "GLOBAL_SETTINGS" in matching_rules:
                irrelevant_categories = matching_rules["GLOBAL_SETTINGS"].get("irrelevant_scene_categories", {})
                
                any_global_blocked = False
                
                for category, keywords in irrelevant_categories.items():
                    blocked_by_category = []
                    
                    for kw in keywords:
                        if kw.lower() in tags_text:
                            blocked_by_category.append(kw)
                    
                    if blocked_by_category:
                        any_global_blocked = True
                        st.error(f"ğŸš¨ **{category}** - å…¨å±€é˜»æ­¢ (å…³é”®è¯: {', '.join(blocked_by_category)})")
                
                if not any_global_blocked:
                    st.success("âœ… é€šè¿‡æ‰€æœ‰å…¨å±€è¿‡æ»¤")
            
            # å®é™…åˆ†ç±»æµ‹è¯•
            st.markdown("---")
            st.write("**ğŸ¯ å®é™…åˆ†ç±»æµ‹è¯•:**")
            
            from streamlit_app.modules.mapper import VideoSegmentMapper
            mapper = VideoSegmentMapper()
            
            actual_result = mapper.classify_segment(test_tags)
            
            st.info(f"ğŸ¤– å®é™…åˆ†ç±»ç»“æœ: **{actual_result}**")
            
            # åˆ†æç»“æœ
            expected_blocked = any("é«˜é€Ÿ" in tag or "çº¢ç»¿ç¯" in tag or "åŒ»é™¢" in tag for tag in test_tags)
            
            if expected_blocked and actual_result not in ["å…¶ä»–", None]:
                st.error("ğŸš¨ **è¿‡æ»¤æœºåˆ¶å¤±æ•ˆ!** åº”è¯¥è¢«æ’é™¤çš„å†…å®¹ä»ç„¶è¢«åˆ†ç±»")
            elif not expected_blocked and actual_result:
                st.success("âœ… è¿‡æ»¤æœºåˆ¶æ­£å¸¸å·¥ä½œ")
            else:
                st.info("â„¹ï¸ æµ‹è¯•ç»“æœéœ€è¦è¿›ä¸€æ­¥éªŒè¯")
        
        except Exception as e:
            st.error(f"æµ‹è¯•å¤±è´¥: {e}")

def render_selection_decision_log():
    """æ¸²æŸ“é€‰ç‰‡å†³ç­–æ—¥å¿—ç•Œé¢"""
    st.header("ğŸ¬ é€‰ç‰‡å†³ç­–æ—¥å¿—åˆ†æ")
    
    st.markdown("""
    **ğŸ¯ é€‰ç‰‡å†³ç­–æ—¥å¿—çš„ä»·å€¼:**
    
    1. **ğŸ” å†³ç­–é€æ˜åŒ–** - è¯¦ç»†è®°å½•æ¯ä¸ªç‰‡æ®µçš„é€‰æ‹©ç†ç”±
    2. **ğŸš« æ’é™¤åŸå› è¿½è¸ª** - æ˜ç¡®æ˜¾ç¤ºç‰‡æ®µè¢«æ’é™¤çš„å…·ä½“åŸå›   
    3. **ğŸ¯ å…³é”®è¯åŒ¹é…åˆ†æ** - æŸ¥çœ‹å“ªäº›å…³é”®è¯è§¦å‘äº†åˆ†ç±»
    4. **ğŸ¤– AIåˆ†ç±»è¿‡ç¨‹** - ç›‘æ§AIåˆ†ç±»çš„å†³ç­–è¿‡ç¨‹å’Œç½®ä¿¡åº¦
    5. **ğŸ“Š è´¨é‡è¯„ä¼°è¯¦æƒ…** - äº†è§£è´¨é‡è¯„åˆ†çš„å…·ä½“è®¡ç®—è¿‡ç¨‹
    
    **ğŸ’¡ æ ¸å¿ƒåŠŸèƒ½: å›ç­”"ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªç‰‡æ®µ"çš„é—®é¢˜**
    """)
    
    # æ—¥å¿—ä¼šè¯ç®¡ç†
    col1, col2 = st.columns(2)
    
    with col1:
        if st.button("ğŸ”„ å¯åŠ¨æ–°çš„é€‰ç‰‡æ—¥å¿—ä¼šè¯", type="primary"):
            try:
                # å…¼å®¹ä¸åŒçš„è¿è¡Œç¯å¢ƒ
                try:
                    from modules.selection_logger import start_new_session
                except ImportError:
                    from streamlit_app.modules.selection_logger import start_new_session
                
                logger = start_new_session()
                st.success(f"âœ… æ–°æ—¥å¿—ä¼šè¯å·²å¯åŠ¨: {logger.session_id}")
                st.info("ğŸ’¡ ç°åœ¨å»æ··å‰ªå·¥å‚ç”Ÿæˆè§†é¢‘ï¼Œæ‰€æœ‰é€‰ç‰‡å†³ç­–éƒ½ä¼šè¢«è¯¦ç»†è®°å½•")
            except Exception as e:
                st.error(f"å¯åŠ¨é€‰ç‰‡æ—¥å¿—å¤±è´¥: {e}")
                st.info("ğŸ’¡ è¯·ç¡®ä¿selection_loggeræ¨¡å—å·²æ­£ç¡®é…ç½®")
    
    with col2:
        if st.button("ğŸ“Š æŸ¥çœ‹å½“å‰ä¼šè¯çŠ¶æ€"):
            try:
                # å…¼å®¹ä¸åŒçš„è¿è¡Œç¯å¢ƒ
                try:
                    from modules.selection_logger import get_selection_logger
                except ImportError:
                    from streamlit_app.modules.selection_logger import get_selection_logger
                
                logger = get_selection_logger()
                summary = logger.get_session_summary()
                st.success(f"ğŸ“‹ å½“å‰ä¼šè¯: {summary['session_id']}")
                st.info(f"ğŸ“Š å·²åˆ†æç‰‡æ®µ: {summary['segments_analyzed']} ä¸ª")
            except Exception as e:
                st.error(f"è·å–ä¼šè¯çŠ¶æ€å¤±è´¥: {e}")
                st.info("ğŸ’¡ è¯·ç¡®ä¿selection_loggeræ¨¡å—å·²æ­£ç¡®é…ç½®")
    
    # ä¸“æ³¨äºé€‰ç‰‡å†³ç­–æ—¥å¿—
    st.markdown("---")
    st.subheader("ğŸ“‹ é€‰ç‰‡å†³ç­–æ—¥å¿—æ–‡ä»¶")
    
    # æŸ¥æ‰¾é€‰ç‰‡å†³ç­–æ—¥å¿— - æ™ºèƒ½è·¯å¾„æ£€æµ‹
    # è·å–å½“å‰å·¥ä½œç›®å½•ï¼Œç¡®å®šæ­£ç¡®çš„è·¯å¾„
    current_dir = os.getcwd()
    
    # ğŸ”§ æ™ºèƒ½æ£€æµ‹è·¯å¾„ï¼šæ ¹æ®å½“å‰å·¥ä½œç›®å½•åŠ¨æ€è®¡ç®—
    current_work_dir = os.getcwd()
    st.info(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: {current_work_dir}")
    
    if current_work_dir.endswith("streamlit_app"):
        # å¦‚æœå·²ç»åœ¨streamlit_appç›®å½•ä¸­
        possible_log_dirs = [
            "logs/selection",  # å½“å‰ç›®å½•
            "../logs/selection",  # ä¸Šçº§ç›®å½•
        ]
    else:
        # å¦‚æœåœ¨é¡¹ç›®æ ¹ç›®å½•
        possible_log_dirs = [
            "logs/selection",  # é¡¹ç›®æ ¹ç›®å½•
            "streamlit_app/logs/selection",  # streamlit_appå­ç›®å½•
        ]
    
    # å¯»æ‰¾å­˜åœ¨çš„æ—¥å¿—ç›®å½•
    selection_log_dir = None
    for log_dir in possible_log_dirs:
        if os.path.exists(log_dir):
            try:
                files = os.listdir(log_dir)
                log_files_count = len([f for f in files if f.endswith(('.jsonl', '.log'))])
                if log_files_count > 0:
                    selection_log_dir = log_dir
                    st.success(f"âœ… æ‰¾åˆ°é€‰ç‰‡æ—¥å¿—ç›®å½•: {log_dir} (åŒ…å« {log_files_count} ä¸ªæ—¥å¿—æ–‡ä»¶)")
                    break
            except Exception as e:
                continue
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ—¥å¿—ç›®å½•
    if not selection_log_dir:
        st.warning("ğŸ“ æœªæ‰¾åˆ°åŒ…å«æ—¥å¿—æ–‡ä»¶çš„ç›®å½•")
        st.info("ğŸ’¡ å¯èƒ½çš„åŸå› ï¼šæ—¥å¿—ç›®å½•ä¸ºç©ºæˆ–æƒé™é—®é¢˜")
    
    if selection_log_dir:
        # æŸ¥æ‰¾ .jsonl å’Œ .log æ–‡ä»¶
        jsonl_files = [f for f in os.listdir(selection_log_dir) if f.endswith('.jsonl')]
        log_files = [f for f in os.listdir(selection_log_dir) if f.endswith('.log')]
        
        if jsonl_files or log_files:
            col1, col2 = st.columns(2)
            
            with col1:
                st.write("**ğŸ“Š ç»“æ„åŒ–å†³ç­–æ—¥å¿— (.jsonl)**")
                if jsonl_files:
                    selected_jsonl = st.selectbox(
                        "é€‰æ‹©å†³ç­–æ—¥å¿—æ–‡ä»¶",
                        sorted(jsonl_files, reverse=True),
                        key="jsonl_selector"
                    )
                    
                    if st.button("ğŸ“Š åˆ†æå†³ç­–è¿‡ç¨‹", key="analyze_decisions"):
                        _analyze_decision_log(os.path.join(selection_log_dir, selected_jsonl))
                else:
                    st.info("æš‚æ— ç»“æ„åŒ–å†³ç­–æ—¥å¿—")
            
            with col2:
                st.write("**ğŸ“ æ–‡æœ¬æ—¥å¿— (.log)**")
                if log_files:
                    selected_log = st.selectbox(
                        "é€‰æ‹©æ–‡æœ¬æ—¥å¿—æ–‡ä»¶",
                        sorted(log_files, reverse=True),
                        key="log_selector"
                    )
                    
                    if st.button("ğŸ“– æŸ¥çœ‹è¯¦ç»†æ—¥å¿—", key="view_detailed_log"):
                        _show_detailed_log(os.path.join(selection_log_dir, selected_log))
                else:
                    st.info("æš‚æ— æ–‡æœ¬æ—¥å¿—")
        else:
            st.warning("ğŸ“ é€‰ç‰‡æ—¥å¿—ç›®å½•ä¸ºç©º")
            st.info("ğŸ’¡ è¯·å…ˆè¿è¡Œæ··å‰ªå·¥å‚ç”Ÿæˆè§†é¢‘ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è®°å½•é€‰ç‰‡å†³ç­–è¿‡ç¨‹")
    else:
        st.warning("ğŸ“ æœªæ‰¾åˆ°é€‰ç‰‡æ—¥å¿—ç›®å½•")
        st.info("ğŸ’¡ æ—¥å¿—ç›®å½•ä¼šåœ¨ç¬¬ä¸€æ¬¡è¿è¡Œé€‰ç‰‡æ—¶è‡ªåŠ¨åˆ›å»º")
        
        # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
        if st.checkbox("ğŸ” æ˜¾ç¤ºè·¯å¾„è°ƒè¯•ä¿¡æ¯", key="debug_log_paths"):
            st.subheader("ğŸ”§ è·¯å¾„è°ƒè¯•ä¿¡æ¯")
            st.write(f"ğŸ” å½“å‰å·¥ä½œç›®å½•: `{current_work_dir}`")
            
            st.write("**æ£€æŸ¥çš„æ—¥å¿—è·¯å¾„:**")
            for i, log_dir in enumerate(possible_log_dirs):
                exists = os.path.exists(log_dir)
                st.write(f"{i+1}. `{log_dir}` â†’ {'âœ… å­˜åœ¨' if exists else 'âŒ ä¸å­˜åœ¨'}")
                if exists:
                    try:
                        files = os.listdir(log_dir)
                        log_files = [f for f in files if f.endswith(('.jsonl', '.log'))]
                        st.write(f"   ğŸ“ åŒ…å« {len(log_files)} ä¸ªæ—¥å¿—æ–‡ä»¶")
                        for log_file in log_files[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                            file_path = os.path.join(log_dir, log_file)
                            file_size = os.path.getsize(file_path)
                            st.write(f"   ğŸ“„ {log_file} ({file_size:,} bytes)")
                    except Exception as e:
                        st.write(f"   âš ï¸ æ— æ³•è¯»å–ç›®å½•: {e}")
    
    # å®æ—¶ç›‘æ§å’Œå¸®åŠ©
    st.markdown("---")
    st.subheader("ğŸ”§ å®æ—¶ç›‘æ§å»ºè®®")
    
    st.markdown("""
    **ğŸ–¥ï¸ æœ€ä½³è°ƒè¯•æ–¹å¼:**
    
    1. **ç»ˆç«¯å®æ—¶è¾“å‡º** - è¿è¡Œæ··å‰ªå·¥å‚æ—¶è§‚å¯Ÿæ§åˆ¶å°ï¼Œæœ‰å®æ—¶çš„é€‰ç‰‡å†³ç­–ä¿¡æ¯
    2. **å¯åŠ¨æ—¥å¿—ä¼šè¯** - ç‚¹å‡»ä¸Šæ–¹"å¯åŠ¨æ–°çš„é€‰ç‰‡æ—¥å¿—ä¼šè¯"æŒ‰é’®
    3. **ç”Ÿæˆè§†é¢‘** - å»æ··å‰ªå·¥å‚é¡µé¢ç”Ÿæˆè§†é¢‘ï¼Œæ‰€æœ‰å†³ç­–éƒ½ä¼šè¢«è®°å½•
    4. **åˆ†æç»“æœ** - å›åˆ°è¿™é‡ŒæŸ¥çœ‹è¯¦ç»†çš„é€‰ç‰‡å†³ç­–åˆ†æ
    
    **ğŸ“‹ æœ‰ç”¨çš„æ—¥å¿—æ ‡è®°:**
    - ğŸ¯ å…³é”®è¯åˆ†ç±»æˆåŠŸ
    - ğŸ¤– AIåˆ†ç±»ç»“æœ  
    - ğŸš« ç‰‡æ®µè¢«æ’é™¤
    - âœ… è´¨é‡æ£€æŸ¥é€šè¿‡
    - ğŸ“Š è´¨é‡è¯„åˆ†è¯¦æƒ…
    """)

def _analyze_decision_log(log_path: str):
    """åˆ†æé€‰ç‰‡å†³ç­–æ—¥å¿—æ–‡ä»¶"""
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        segment_analyses = []
        module_selections = []
        
        for line in lines:
            if line.strip():
                data = json.loads(line)
                if data.get("segment_id"):
                    segment_analyses.append(data)
                elif data.get("log_type") == "module_selection":
                    module_selections.append(data)
        
        st.success(f"ğŸ“Š æ—¥å¿—åˆ†æå®Œæˆ: {os.path.basename(log_path)}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç‰‡æ®µåˆ†æ", len(segment_analyses))
        with col2:
            st.metric("æ¨¡å—é€‰ç‰‡", len(module_selections))
        with col3:
            st.metric("å†³ç­–æ­¥éª¤", sum(len(s.get("analysis_steps", [])) for s in segment_analyses))
        
        # æ˜¾ç¤ºæœ€è¿‘çš„å‡ ä¸ªå†³ç­–
        if segment_analyses:
            st.subheader("ğŸ” æœ€è¿‘çš„ç‰‡æ®µå†³ç­–")
            for analysis in segment_analyses[-5:]:  # æ˜¾ç¤ºæœ€å5ä¸ª
                with st.expander(f"ğŸ¬ {analysis['segment_info']['file_name']} â†’ {analysis['final_result']}"):
                    st.write(f"**å†³ç­–åŸå› :** {analysis['decision_reason']}")
                    st.write(f"**æ ‡ç­¾:** {', '.join(analysis['segment_info']['all_tags'])}")
                    st.write(f"**åˆ†ææ­¥éª¤:** {len(analysis['analysis_steps'])} æ­¥")
                    
                    for step in analysis['analysis_steps']:
                        step_type = step['step_type']
                        if step_type == "exclusion_check":
                            if step['exclusion_results']['is_excluded']:
                                st.error(f"ğŸš« æ’é™¤æ£€æŸ¥: {step['exclusion_results']['exclusion_reasons']}")
                            else:
                                st.success("âœ… é€šè¿‡æ’é™¤æ£€æŸ¥")
                        elif step_type == "keyword_classification":
                            if step['classification_result']:
                                st.info(f"ğŸ¯ å…³é”®è¯åˆ†ç±»: {step['classification_result']}")
                            else:
                                st.warning("âš ï¸ å…³é”®è¯åˆ†ç±»æ— ç»“æœ")
                        elif step_type == "ai_classification":
                            st.info(f"ğŸ¤– AIåˆ†ç±»: {step['ai_result']} (è€—æ—¶: {step['api_call_info'].get('duration', 0):.2f}s)")
        
        # æ˜¾ç¤ºæ¨¡å—é€‰ç‰‡ç»“æœ
        if module_selections:
            st.subheader("ğŸ¬ æ¨¡å—é€‰ç‰‡ç»“æœ")
            for selection in module_selections[-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ª
                st.write(f"**{selection['module_name']}:** {selection['selected_count']}/{selection['candidates_count']} ç‰‡æ®µè¢«é€‰ä¸­")
            
    except Exception as e:
        st.error(f"åˆ†ææ—¥å¿—å¤±è´¥: {e}")

def _show_detailed_log(log_path: str):
    """æ˜¾ç¤ºè¯¦ç»†çš„æ–‡æœ¬æ—¥å¿—"""
    try:
        with open(log_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è¿‡æ»¤ç›¸å…³çš„é€‰ç‰‡å†³ç­–æ—¥å¿—
        lines = content.split('\n')
        decision_lines = []
        
        keywords = ["ğŸ¯", "ğŸ¤–", "ğŸš«", "âœ…", "ğŸ“Š", "âš ï¸", "ç‰‡æ®µåˆ†æ", "åˆ†ç±»", "æ’é™¤", "è´¨é‡"]
        
        for line in lines:
            if any(keyword in line for keyword in keywords):
                decision_lines.append(line)
        
        if decision_lines:
            st.subheader(f"ğŸ“‹ é€‰ç‰‡å†³ç­–æ—¥å¿— (å…± {len(decision_lines)} æ¡)")
            st.text_area(
                "å†³ç­–æ—¥å¿—å†…å®¹",
                "\n".join(decision_lines[-100:]),  # æ˜¾ç¤ºæœ€å100æ¡
                height=400,
                key="decision_log_content"
            )
            st.info(f"ğŸ“Š ä» {len(lines)} è¡Œæ—¥å¿—ä¸­ç­›é€‰å‡º {len(decision_lines)} æ¡ç›¸å…³å†³ç­–è®°å½•")
        else:
            st.warning("æœªæ‰¾åˆ°é€‰ç‰‡å†³ç­–ç›¸å…³çš„æ—¥å¿—å†…å®¹")
            
    except Exception as e:
        st.error(f"è¯»å–æ—¥å¿—å¤±è´¥: {e}")
    
    # å®æ—¶æ—¥å¿—ç›‘æ§
    st.markdown("---")
    st.subheader("ğŸ”´ å®æ—¶æ—¥å¿—ç›‘æ§")
    
    if st.checkbox("å¼€å¯å®æ—¶ç›‘æ§"):
        st.info("å®æ—¶ç›‘æ§åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥å¼€å‘...")

# show_all_segments_table å‡½æ•°å·²åˆ é™¤ - å­˜åœ¨å¤æ‚çš„è·¯å¾„è¯†åˆ«é—®é¢˜

def _show_fallback_srt_based_table(video_filename: str, video_duration: float, selected_segments: Dict[str, List[Dict]] = None):
    """æ˜¾ç¤ºåŸºäºSRTçš„è¡¨æ ¼ - ä¼˜å…ˆä½¿ç”¨å®é™…åˆæˆç‰‡æ®µï¼Œå›é€€åˆ°è§†é¢‘æ± åŒ¹é…"""
    if selected_segments:
        st.subheader(f"ğŸ“‹ {video_filename} - åŸºäºæ ‡æ†è§†é¢‘SRTæ—¶é—´è½´çš„åˆæˆç‰‡æ®µæ˜ å°„")
    else:
        st.subheader(f"ğŸ“‹ {video_filename} - åŸºäºæ ‡æ†è§†é¢‘SRTçš„å®é™…ç‰‡æ®µæ„æˆ")
    
    try:
        # è¯»å–æ ‡æ†è§†é¢‘çš„SRTæ–‡ä»¶ - ä½¿ç”¨ç»å¯¹è·¯å¾„
        current_file_dir = os.path.dirname(os.path.abspath(__file__))  # streamlit_app/pages
        streamlit_app_dir = os.path.dirname(current_file_dir)  # streamlit_app
        project_root = os.path.dirname(streamlit_app_dir)  # é¡¹ç›®æ ¹ç›®å½•
        srt_file_path = os.path.join(project_root, "data", "input", "test_videos", "é€šç”¨-ä¿æŠ¤è–„å¼±æœŸ-HMO&è‡ªå¾¡åŠ›-å¯èµ‹-CTA7.srt")
        
        if not os.path.exists(srt_file_path):
            st.error(f"æ ‡æ†è§†é¢‘SRTæ–‡ä»¶ä¸å­˜åœ¨: {srt_file_path}")
            return
        
        # è§£æSRTæ–‡ä»¶
        srt_segments = []
        with open(srt_file_path, 'r', encoding='utf-8') as f:
            content = f.read().strip()
            
        # åˆ†å‰²SRTç‰‡æ®µ
        srt_blocks = content.split('\n\n')
        
        for block in srt_blocks:
            lines = block.strip().split('\n')
            if len(lines) >= 3:
                index = lines[0]
                time_range = lines[1]
                text = ' '.join(lines[2:])
                
                srt_segments.append({
                    'index': int(index),
                    'time_range': time_range,
                    'text': text
                })
        
        # å®šä¹‰æ¨¡å—æ˜ å°„
        srt_module_mapping = {
            1: {"module": "ç—›ç‚¹", "icon": "ğŸ”´"},
            2: {"module": "ç—›ç‚¹", "icon": "ğŸ”´"},
            3: {"module": "è§£å†³æ–¹æ¡ˆå¯¼å…¥", "icon": "ğŸŸ¢"},
            4: {"module": "å–ç‚¹Â·æˆåˆ†&é…æ–¹", "icon": "ğŸŸ¡"},
            5: {"module": "ä¿ƒé”€æœºåˆ¶", "icon": "ğŸŸ "}
        }
        
        # ğŸ”§ ä¼˜å…ˆä½¿ç”¨ä¼ å…¥çš„åˆæˆç‰‡æ®µæ•°æ®ï¼Œå¦åˆ™åŠ è½½è§†é¢‘æ± æ•°æ®
        if selected_segments:
            # ä½¿ç”¨å®é™…åˆæˆçš„ç‰‡æ®µæ•°æ®
            pool_by_module = selected_segments.copy()
            pool_segments = []
            for segments_list in selected_segments.values():
                pool_segments.extend(segments_list)
            st.success(f"âœ… ä½¿ç”¨å®é™…åˆæˆç‰‡æ®µæ•°æ®: {len(pool_segments)} ä¸ªç‰‡æ®µ")
        else:
            # å›é€€åˆ°åŠ è½½è§†é¢‘æ± æ•°æ®
            video_pool_path = "data/output/google_video/video_pool"
            pool_segments = []
        
            if os.path.exists(video_pool_path):
                with st.spinner("åŠ è½½è§†é¢‘æ± æ•°æ®..."):
                    try:
                        from streamlit_app.modules.mapper import VideoSegmentMapper
                        mapper = VideoSegmentMapper()
                        pool_segments = mapper.scan_video_pool(video_pool_path)
                        st.success(f"âœ… æˆåŠŸåŠ è½½ {len(pool_segments)} ä¸ªè§†é¢‘æ± ç‰‡æ®µ")
                    except Exception as e:
                        st.warning(f"âš ï¸ åŠ è½½è§†é¢‘æ± å¤±è´¥: {e}")
            else:
                st.warning("âš ï¸ è§†é¢‘æ± ç›®å½•ä¸å­˜åœ¨ï¼Œå°†æ˜¾ç¤ºç†è®ºç‰‡æ®µå")
        
            # ğŸ¯ æŒ‰æ¨¡å—åˆ†ç»„è§†é¢‘æ± ç‰‡æ®µ
            pool_by_module = {
                "ç—›ç‚¹": [],
                "è§£å†³æ–¹æ¡ˆå¯¼å…¥": [],
                "å–ç‚¹Â·æˆåˆ†&é…æ–¹": [],
                "ä¿ƒé”€æœºåˆ¶": []
            }
        
        for segment in pool_segments:
            category = segment.get('category', 'æœªåˆ†ç±»')
            if category in pool_by_module:
                pool_by_module[category].append(segment)
        
        # åˆ›å»ºè¡¨æ ¼è¡¨å¤´
        header_col1, header_col2, header_col3, header_col4, header_col5 = st.columns([0.8, 2.5, 2, 2.5, 0.8])
        
        with header_col1:
            st.markdown("**æ¨¡å—**")
        with header_col2:
            st.markdown("**SRTæ—¶é—´**")
        with header_col3:
            st.markdown("**å®é™…åŒ¹é…ç‰‡æ®µ**")
        with header_col4:
            st.markdown("**å†…å®¹æè¿°**")
        with header_col5:
            st.markdown("**è´¨é‡è¯„ä¼°**")
        
        st.markdown("---")
        
        # ä¸ºæ¯ä¸ªæ¨¡å—ç»´æŠ¤å·²ä½¿ç”¨çš„ç‰‡æ®µç´¢å¼•
        module_usage_count = {
            "ç—›ç‚¹": 0,
            "è§£å†³æ–¹æ¡ˆå¯¼å…¥": 0,
            "å–ç‚¹Â·æˆåˆ†&é…æ–¹": 0,
            "ä¿ƒé”€æœºåˆ¶": 0
        }
        
        # æ˜¾ç¤ºæ¯ä¸ªSRTç‰‡æ®µ
        for srt_seg in srt_segments:
            index = srt_seg['index']
            time_range = srt_seg['time_range']
            text = srt_seg['text']
            
            # è·å–æ¨¡å—ä¿¡æ¯
            module_info = srt_module_mapping.get(index, {"module": "å…¶ä»–", "icon": "âšª"})
            module = module_info["module"]
            icon = module_info["icon"]
            
            # ğŸ¯ è·å–è¯¥æ¨¡å—æ‰€æœ‰åŒ¹é…çš„ç‰‡æ®µ
            module_segments = pool_by_module.get(module, [])

            # åˆ›å»ºä¸€ä¸ªå®¹å™¨æ¥å±•ç¤ºæ•´ä¸ªSRTæ¨¡å—
            with st.container():
                # ç¬¬ä¸€è¡Œï¼šæ˜¾ç¤ºæ¨¡å—ã€SRTæ—¶é—´å’Œå†…å®¹æè¿°
                col1, col2, col4 = st.columns([0.8, 2.5, 2.5])
                with col1:
                    st.markdown(f"{icon} **{module}**")
                with col2:
                    st.markdown(f"**{time_range}**")
                with col4:
                    display_text = text[:50] + "..." if len(text) > 50 else text
                    st.markdown(f"**{display_text}**")
            
                # åç»­è¡Œï¼šæ˜¾ç¤ºè¯¥æ¨¡å—ä¸‹çš„æ‰€æœ‰ç‰‡æ®µ
                if not module_segments:
                     # å¦‚æœæ²¡æœ‰åŒ¹é…çš„ç‰‡æ®µ
                    _, _, seg_col3, _, seg_col5 = st.columns([0.8, 2.5, 2, 2.5, 0.8])
                    with seg_col3:
                        st.markdown("*ç†è®º-æ— åŒ¹é…ç‰‡æ®µ*")
                    with seg_col5:
                        st.markdown("N/A")
                else:
                    for segment_in_module in module_segments:
                        video_id = segment_in_module.get('video_id', 'unknown')
                        file_name = segment_in_module.get('file_name', 'segment.mp4')
                        quality = segment_in_module.get('combined_quality', 0.75)
                        
                        if video_id != 'unknown' and not file_name.startswith(f"{video_id}-"):
                            actual_filename = f"{video_id}-{file_name}"
                        else:
                            actual_filename = file_name
                        
                        # ä¸ºæ¯ä¸ªç‰‡æ®µåˆ›å»ºä¸€è¡Œ
                        _, _, seg_col3, _, seg_col5 = st.columns([0.8, 2.5, 2, 2.5, 0.8])
                        with seg_col3:
                            st.markdown(f"**{actual_filename}**")
                        with seg_col5:
                            st.markdown(f"**{quality:.2f}**")
            
            # æ¸…é™¤è¯¥æ¨¡å—çš„ç‰‡æ®µï¼Œé˜²æ­¢åœ¨å…¶ä»–SRTæ¡ç›®ä¸­é‡å¤æ˜¾ç¤º
            if module in pool_by_module:
                pool_by_module[module] = []

            st.markdown("---")
        
        # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
        st.markdown("---")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("SRTç‰‡æ®µæ•°", len(srt_segments))
        
        with col2:
            actual_matches = sum(len(segments) for segments in pool_by_module.values())
            st.metric("å¯ç”¨æ± ç‰‡æ®µ", actual_matches)
        
        with col3:
            st.metric("è§†é¢‘æ—¶é•¿", f"{video_duration:.1f}ç§’")
        
        # æ˜¾ç¤ºæ¨¡å—åŒ¹é…ç»Ÿè®¡
        st.subheader("ğŸ“Š æ¨¡å—åŒ¹é…ç»Ÿè®¡")
        
        module_stats = []
        for module, segments in pool_by_module.items():
            srt_count = sum(1 for seg in srt_segments 
                           if srt_module_mapping.get(seg['index'], {}).get('module') == module)
            
            module_stats.append({
                "æ¨¡å—": f"{srt_module_mapping.get(1, {}).get('icon', 'âšª')} {module}" if module == "ç—›ç‚¹" 
                       else f"{srt_module_mapping.get(3, {}).get('icon', 'âšª')} {module}" if module == "è§£å†³æ–¹æ¡ˆå¯¼å…¥"
                       else f"{srt_module_mapping.get(4, {}).get('icon', 'âšª')} {module}" if module == "å–ç‚¹Â·æˆåˆ†&é…æ–¹"
                       else f"{srt_module_mapping.get(5, {}).get('icon', 'âšª')} {module}",
                "SRTéœ€æ±‚": srt_count,
                "æ± ä¸­å¯ç”¨": len(segments),
                "åŒ¹é…çŠ¶æ€": "âœ… å……è¶³" if len(segments) >= srt_count else f"âš ï¸ ä¸è¶³({len(segments)}/{srt_count})"
            })
        
        if module_stats:
            import pandas as pd
            df = pd.DataFrame(module_stats)
            st.dataframe(df, use_container_width=True, hide_index=True)
        
        # æç¤ºä¿¡æ¯
        if pool_segments:
            st.info("â„¹ï¸ æ­¤è¡¨æ ¼åŸºäºæ ‡æ†è§†é¢‘SRTçš„æ—¶é—´è½´ï¼Œæ˜¾ç¤ºå®é™…ä»è§†é¢‘æ± åŒ¹é…çš„ç‰‡æ®µæ–‡ä»¶å")
        else:
            st.warning("âš ï¸ æœªåŠ è½½è§†é¢‘æ± æ•°æ®ï¼Œæ˜¾ç¤ºçš„æ˜¯ç†è®ºç‰‡æ®µæ„æˆã€‚è¯·å…ˆåœ¨æ··å‰ªå·¥å‚ä¸­å®Œæˆæ˜ å°„ã€‚")
        
    except Exception as e:
        st.error(f"æ˜¾ç¤ºå›é€€è¡¨æ ¼å¤±è´¥: {e}")

def _show_real_composition_table(comp_result: Dict[str, Any], selected_segments: Dict[str, List[Dict]], metadata: Dict[str, Any]) -> None:
    """æ˜¾ç¤ºçœŸå®çš„åˆæˆè§†é¢‘ç‰‡æ®µè¡¨æ ¼ - åŸºäºJSONæ–‡ä»¶æ•°æ®"""
    st.header("ğŸ“‹ æ··å‰ªå·¥å‚åˆæˆè§†é¢‘ç‰‡æ®µè¡¨ (çœŸå®æ•°æ®)")
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
    st.success(f"âœ… åˆæˆè§†é¢‘: **{metadata.get('video_filename', 'æœªçŸ¥æ–‡ä»¶å')}**")
    
    # æ·»åŠ æ˜¾ç¤ºæ–¹å¼é€‰æ‹©
    display_mode = st.radio(
        "ğŸ¯ é€‰æ‹©æ˜¾ç¤ºæ–¹å¼ï¼š",
        ["ğŸ“„ åŸºäºSRTæ ‡æ†è§†é¢‘æ—¶é—´è½´", "ğŸ¬ åŸºäºåˆæˆè§†é¢‘æ—¶é—´è½´"],
        index=0,  # é»˜è®¤é€‰æ‹©SRTæ–¹å¼
        horizontal=True
    )
    
    if display_mode == "ğŸ“„ åŸºäºSRTæ ‡æ†è§†é¢‘æ—¶é—´è½´":
        # è°ƒç”¨SRTåŸºç¡€çš„æ˜¾ç¤ºå‡½æ•°ï¼Œä¼ å…¥å®é™…åˆæˆçš„ç‰‡æ®µ
        video_filename = metadata.get('video_filename', 'æœªçŸ¥æ–‡ä»¶å')
        video_duration = comp_result.get('duration', 0)
        _show_fallback_srt_based_table(video_filename, video_duration, selected_segments)
        return
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ğŸ¬ æ€»æ—¶é•¿", f"{comp_result.get('duration', 0):.1f}ç§’")
    with col2:
        total_segments = sum(len(segs) for segs in selected_segments.values())
        st.metric("ğŸ“¦ æ€»ç‰‡æ®µæ•°", total_segments)
    with col3:
        st.metric("ğŸ¯ åˆæˆç­–ç•¥", metadata.get('strategy', 'æœªçŸ¥'))
    with col4:
        file_size_mb = comp_result.get('file_size', 0) / (1024*1024) if comp_result.get('file_size') else 0
        st.metric("ğŸ“ æ–‡ä»¶å¤§å°", f"{file_size_mb:.1f}MB")
    
    # å®šä¹‰æ¨¡å—å›¾æ ‡
    module_icons = {
        "ç—›ç‚¹": "ğŸ”´",
        "è§£å†³æ–¹æ¡ˆå¯¼å…¥": "ğŸŸ¢", 
        "å–ç‚¹Â·æˆåˆ†&é…æ–¹": "ğŸŸ¡",
        "ä¿ƒé”€æœºåˆ¶": "ğŸŸ "
    }
    
    # åˆ›å»ºè¡¨æ ¼è¡¨å¤´
    header_col1, header_col2, header_col3, header_col4, header_col5 = st.columns([0.8, 2.5, 2, 2.5, 0.8])
    
    with header_col1:
        st.markdown("**æ¨¡å—**")
    with header_col2:
        st.markdown("**æ—¶é—´ä½ç½®**")
    with header_col3:
        st.markdown("**é€‰ä¸­ç‰‡æ®µåç§°**")
    with header_col4:
        st.markdown("**ç‰‡æ®µæ ‡ç­¾**")
    with header_col5:
        st.markdown("**è´¨é‡åˆ†æ•°**")
    
    st.markdown("---")
    
    # æŒ‰æ¨¡å—é¡ºåºæ˜¾ç¤ºç‰‡æ®µ
    modules = ["ç—›ç‚¹", "è§£å†³æ–¹æ¡ˆå¯¼å…¥", "å–ç‚¹Â·æˆåˆ†&é…æ–¹", "ä¿ƒé”€æœºåˆ¶"]
    current_time = 0.0
    
    for module in modules:
        if module not in selected_segments:
            continue
            
        module_segments = selected_segments[module]
        if not module_segments:
            continue
        
        icon = module_icons.get(module, "âšª")
        
        # ä¸ºæ¯ä¸ªæ¨¡å—çš„ç‰‡æ®µæ˜¾ç¤ºä¿¡æ¯
        for segment_idx, segment in enumerate(module_segments):
            # è·å–ç‰‡æ®µä¿¡æ¯
            file_name = segment.get('file_name', f'segment_{segment_idx+1}.mp4')
            video_id = segment.get('video_id', 'unknown')
            duration = segment.get('duration', 0)
            all_tags = segment.get('all_tags', [])
            quality = segment.get('combined_quality', 0.75)
            transcription = segment.get('transcription', '')
            
            # è®¡ç®—æ—¶é—´èŒƒå›´
            start_time = current_time
            end_time = current_time + duration
            time_range = f"{int(start_time//60):02d}:{int(start_time%60):02d} - {int(end_time//60):02d}:{int(end_time%60):02d}"
            
            # æ„å»ºæ˜¾ç¤ºæ–‡ä»¶åï¼ˆæ·»åŠ è§†é¢‘IDå‰ç¼€ï¼‰
            if video_id != 'unknown' and not file_name.startswith(f"{video_id}-"):
                display_filename = f"{video_id}-{file_name}"
            else:
                display_filename = file_name
            
            # å¤„ç†æ ‡ç­¾ - ä¼˜å…ˆä½¿ç”¨çœŸå®æ ‡ç­¾
            if all_tags:
                main_tags = all_tags[:4]  # æ˜¾ç¤ºå‰4ä¸ªæ ‡ç­¾
                tags_display = ", ".join(main_tags)
            elif transcription:
                # å¦‚æœæœ‰è½¬å½•æ–‡æœ¬ï¼Œæå–å…³é”®è¯ä½œä¸ºæ ‡ç­¾
                keywords = transcription.split()[:4]
                tags_display = ", ".join(keywords)
            else:
                # æ ¹æ®æ¨¡å—ç”Ÿæˆé»˜è®¤æ ‡ç­¾
                module_default_tags = {
                    "ç—›ç‚¹": ["å¦ˆå¦ˆ", "å®å®", "æ‹…å¿§", "é—®é¢˜"],
                    "è§£å†³æ–¹æ¡ˆå¯¼å…¥": ["å¦ˆå¦ˆ", "å®å®", "å¥¶ç²‰", "è§£å†³"],
                    "å–ç‚¹Â·æˆåˆ†&é…æ–¹": ["å¥¶ç²‰", "è¥å…»", "é…æ–¹", "æˆåˆ†"],
                    "ä¿ƒé”€æœºåˆ¶": ["ä¼˜æƒ ", "ä¿ƒé”€", "æ´»åŠ¨", "è¯•å–"]
                }
                tags_display = ", ".join(module_default_tags.get(module, ["å¦ˆå¦ˆ", "å®å®", "å¥¶ç²‰"]))
            
            # åˆ›å»º5åˆ—è¡¨æ ¼å¸ƒå±€
            col1, col2, col3, col4, col5 = st.columns([0.8, 2.5, 2, 2.5, 0.8])
            
            with col1:
                if segment_idx == 0:  # åªåœ¨ç¬¬ä¸€ä¸ªç‰‡æ®µæ˜¾ç¤ºæ¨¡å—å
                    st.markdown(f"{icon} **{module}**")
                else:
                    st.markdown("")  # ç©ºç™½ï¼Œä¿æŒå¯¹é½
            
            with col2:
                st.markdown(f"**{time_range}**")
                # æ˜¾ç¤ºç‰‡æ®µæ—¶é•¿
                st.markdown(f"<div style='color: #666; font-size: 12px; margin-top: 2px;'>â± {duration:.1f}ç§’</div>", unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"**{display_filename}**")
                # å¦‚æœæœ‰è½¬å½•æ–‡æœ¬ï¼Œæ˜¾ç¤ºé¢„è§ˆ
                if transcription:
                    preview = transcription[:30] + "..." if len(transcription) > 30 else transcription
                    st.markdown(f"<div style='color: #999; font-size: 11px; margin-top: 2px;'>ğŸ’¬ {preview}</div>", unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"**{tags_display}**")
            
            with col5:
                # è´¨é‡åˆ†æ•°å½©è‰²æ˜¾ç¤º
                if quality >= 0.8:
                    color = "#22c55e"  # ç»¿è‰²
                elif quality >= 0.6:
                    color = "#f59e0b"  # é»„è‰²
                else:
                    color = "#ef4444"  # çº¢è‰²
                st.markdown(f"<div style='color: {color}; font-weight: bold;'>{quality:.2f}</div>", unsafe_allow_html=True)
            
            # æ›´æ–°å½“å‰æ—¶é—´
            current_time = end_time
    
    # æ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
    st.markdown("---")
    st.subheader("ğŸ“Š è¯¦ç»†ç»Ÿè®¡")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**æ¨¡å—åˆ†å¸ƒ:**")
        for module in modules:
            if module in selected_segments:
                count = len(selected_segments[module])
                duration_total = sum(seg.get('duration', 0) for seg in selected_segments[module])
                st.write(f"â€¢ {module}: {count}ç‰‡æ®µ, {duration_total:.1f}ç§’")
    
    with col2:
        st.write("**è´¨é‡åˆ†æ:**")
        all_qualities = []
        for segments in selected_segments.values():
            for seg in segments:
                quality = seg.get('combined_quality', 0)
                if quality > 0:
                    all_qualities.append(quality)
        
        if all_qualities:
            avg_quality = sum(all_qualities) / len(all_qualities)
            max_quality = max(all_qualities)
            min_quality = min(all_qualities)
            st.write(f"â€¢ å¹³å‡è´¨é‡: {avg_quality:.3f}")
            st.write(f"â€¢ æœ€é«˜è´¨é‡: {max_quality:.3f}")
            st.write(f"â€¢ æœ€ä½è´¨é‡: {min_quality:.3f}")
    
    with col3:
        st.write("**åˆæˆä¿¡æ¯:**")
        timestamp = metadata.get('timestamp', '')
        if timestamp:
            from datetime import datetime
            try:
                dt = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                st.write(f"â€¢ åˆæˆæ—¶é—´: {dt.strftime('%Y-%m-%d %H:%M')}")
            except:
                st.write(f"â€¢ åˆæˆæ—¶é—´: {timestamp}")
        
        audio_strategy = comp_result.get('audio_strategy', 'æœªçŸ¥')
        st.write(f"â€¢ éŸ³é¢‘ç­–ç•¥: {audio_strategy}")
        
        quality_settings = metadata.get('quality_settings', {})
        if quality_settings:
            resolution = quality_settings.get('resolution', 'æœªçŸ¥')
            st.write(f"â€¢ è¾“å‡ºåˆ†è¾¨ç‡: {resolution}")


if __name__ == "__main__":
    main() 