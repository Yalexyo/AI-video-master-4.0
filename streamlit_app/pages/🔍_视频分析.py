import streamlit as st
import os
import sys
from pathlib import Path
import logging # æ·»åŠ loggingå¯¼å…¥
import shutil # æ·»åŠ shutilå¯¼å…¥
from datetime import datetime
# import json # ä¸å†ç›´æ¥åœ¨æ­¤å¤„ä½¿ç”¨jsonæ¥ä¿å­˜å…ƒæ•°æ®

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),  # è¾“å‡ºåˆ°æ§åˆ¶å°
        logging.FileHandler(os.path.join('logs', 'app.log'))  # è¾“å‡ºåˆ°æ–‡ä»¶
    ]
)
logger = logging.getLogger(__name__) # åœ¨æ¨¡å—çº§åˆ«è·å–logger

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
ROOT_DIR = Path(__file__).parent.parent
sys.path.append(str(ROOT_DIR))

# ä¿®æ”¹å¯¼å…¥è·¯å¾„
from streamlit_app.config.config import get_config, get_semantic_segment_types, get_semantic_modules, TARGET_GROUPS
from streamlit_app.modules.data_loader.video_loader import find_videos
from streamlit_app.modules.analysis.intent_analyzer import main_analysis_pipeline, SemanticAnalyzer
# æ·»åŠ è§†é¢‘ç»„ç»‡å™¨æ¨¡å—çš„å¯¼å…¥
from streamlit_app.modules.data_process.video_organizer import organize_segments_by_type
# æ–°å¢ï¼šå¯¼å…¥å…ƒæ•°æ®å¤„ç†å™¨
from streamlit_app.modules.data_process.metadata_processor import save_detailed_segments_metadata, create_srt_files_for_segments, update_metadata_with_analysis_results
# æ–°å¢ï¼šå¯¼å…¥ç»“æœå±•ç¤ºç•Œé¢å‡½æ•°
from streamlit_app.modules.visualization.result_display import display_results_interface
# æ–°å¢ï¼šå¯¼å…¥ç‰‡æ®µåˆ†æå™¨
from streamlit_app.modules.analysis.segment_analyzer import analyze_segments_batch

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="è§†é¢‘åˆ†æå¤§å¸ˆ 1.0",
    page_icon="ğŸ¥",
    layout="wide"
)

# --- è‡ªå®šä¹‰CSS ---
st.markdown("""
<style>
    .main .block-container {
        padding-top: 2rem;
        padding-bottom: 2rem;
    }
    .stButton button {
        height: 2.5rem;
        vertical-align: middle !important;
        margin-top: 0.2rem;
    }
    .stTextInput input {
        height: 2.5rem;
    }
    .upload-section {
        display: flex;
        align-items: center;
    }
    .video-card {
        border: 1px solid #e6e6e6;
        border-radius: 5px;
        padding: 10px;
        margin-bottom: 15px;
    }
    .segment-row {
        margin-bottom: 10px;
        padding: 5px;
    }
    .segment-row:hover {
        background-color: #f0f2f6;
    }
    .product-tag {
        display: inline-block;
        padding: 3px 10px;
        border-radius: 12px;
        margin-right: 6px;
        margin-bottom: 5px;
        font-size: 0.85em;
        font-weight: 500;
        color: white;
    }
    .tag {
        display: inline-block;
        padding: 3px 10px;
        border-radius: 12px;
        margin-right: 6px;
        margin-bottom: 5px;
        font-size: 0.85em;
        font-weight: 500;
        color: white;
    }
    .tag-æ°´å¥¶ {
        background-color: #4CAF50;
    }
    .tag-è•´æ·³ {
        background-color: #2196F3;
    }
    .tag-è“é’» {
        background-color: #9C27B0;
    }
    .tag-default {
        background-color: #757575;
        color: #f0f0f0;
    }
    .tag-audience {
        background-color: white; /* ç™½è‰²èƒŒæ™¯ */
        color: black; /* é»‘è‰²æ–‡å­— */
        border: 1px solid black; /* é»‘è‰²è¾¹æ¡† */
    }
    
    /* ç›®æ ‡äººç¾¤æ ‡ç­¾æ ·å¼ */
    .tag-å­•æœŸå¦ˆå¦ˆ {
        background-color: #E91E63; /* ç²‰çº¢è‰² */
    }
    .tag-äºŒèƒå¦ˆå¦ˆ {
        background-color: #FF9800; /* æ©™è‰² */
    }
    .tag-æ··å…»å¦ˆå¦ˆ {
        background-color: #4CAF50; /* ç»¿è‰² */
    }
    .tag-æ–°æ‰‹çˆ¸å¦ˆ {
        background-color: #2196F3; /* è“è‰² */
    }
    .tag-è´µå¦‡å¦ˆå¦ˆ {
        background-color: #9C27B0; /* ç´«è‰² */
    }
    
    /* äº§å“ç±»å‹æ ‡ç­¾æ ·å¼ */
    .tag-å¯èµ‹æ°´å¥¶ {
        background-color: #4CAF50; /* ç»¿è‰² */
    }
    .tag-å¯èµ‹è•´æ·³ {
        background-color: #2196F3; /* è“è‰² */
    }
    .tag-å¯èµ‹è“é’» {
        background-color: #9C27B0; /* ç´«è‰² */
    }
    
    /* ä¾§è¾¹æ å®½åº¦æ§åˆ¶ */
    .css-1d391kg {
        width: 180px !important;
        min-width: 180px !important;
        max-width: 180px !important;
    }
    
    /* ä¾§è¾¹æ å†…å®¹åŒºåŸŸ */
    .css-1lcbmhc {
        width: 180px !important;
        min-width: 180px !important;
        max-width: 180px !important;
    }
    
    /* ä¸»å†…å®¹åŒºåŸŸè‡ªé€‚åº” */
    .css-18e3th9 {
        padding-left: 200px !important;
    }
    
    /* æ›´é€šç”¨çš„ä¾§è¾¹æ æ ·å¼æ§åˆ¶ */
    section[data-testid="stSidebar"] {
        width: 180px !important;
        min-width: 180px !important;
        max-width: 180px !important;
    }
    
    section[data-testid="stSidebar"] > div {
        width: 180px !important;
        min-width: 180px !important;
        max-width: 180px !important;
    }
    
    /* ä¾§è¾¹æ å¯¼èˆªé“¾æ¥æ ·å¼ä¼˜åŒ– */
    .css-1v0mbdj a {
        font-size: 0.9rem !important;
        padding: 0.5rem 0.75rem !important;
    }
    
    /* éšè—ä¾§è¾¹æ è°ƒæ•´æ‰‹æŸ„ */
    .css-1cypcdb {
        display: none !important;
    }
    
    /* è½¬å½•ç¼–è¾‘ç›¸å…³æ ·å¼ */
    .transcript-container {
        border: 1px solid #e6e6e6;
        border-radius: 8px;
        padding: 10px;
        margin: 5px 0;
    }
    
    .transcript-changes {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 4px;
        padding: 8px;
        margin-top: 5px;
    }
    
    .transcript-save-btn {
        background-color: #28a745 !important;
        color: white !important;
        border: none !important;
        border-radius: 4px !important;
        padding: 5px 10px !important;
        font-size: 0.85em !important;
    }
    
    .transcript-reset-btn {
        background-color: #6c757d !important;
        color: white !important;
        border: none !important;
        border-radius: 4px !important;
        padding: 5px 10px !important;
        font-size: 0.85em !important;
    }
    
    /* ğŸ†• ç‰‡æ®µç¼–è¾‘å™¨è¡¨æ ¼æ ·å¼ */
    .segment-editor-table {
        border: 1px solid #e6e6e6;
        border-radius: 8px;
        padding: 10px;
        margin: 10px 0;
        background-color: #fafafa;
    }
    
    .segment-row {
        padding: 8px 0;
        border-bottom: 1px solid #e6e6e6;
    }
    
    .segment-row:last-child {
        border-bottom: none;
    }
    
    .segment-row:hover {
        background-color: #f0f2f6;
        border-radius: 4px;
    }
    
    .segment-file-button {
        background-color: #f8f9fa !important;
        border: 1px solid #dee2e6 !important;
        color: #495057 !important;
        font-size: 0.85em !important;
        padding: 4px 8px !important;
        border-radius: 4px !important;
    }
    
    .segment-file-button:hover {
        background-color: #e9ecef !important;
        border-color: #adb5bd !important;
    }
    
    .segment-modified {
        color: #28a745;
        font-style: italic;
        font-size: 0.85em;
    }
    
    /* ç´§å‡‘çš„è¾“å…¥æ¡†æ ·å¼ */
    .stNumberInput > div > div > input {
        height: 35px !important;
        font-size: 0.85em !important;
    }
    
    .stMultiSelect > div > div {
        min-height: 35px !important;
    }
    
    .stSelectbox > div > div {
        min-height: 35px !important;
    }
</style>""", unsafe_allow_html=True)

# --- åº”ç”¨çŠ¶æ€åˆå§‹åŒ– ---
if 'uploaded_file_path' not in st.session_state:
    st.session_state.uploaded_file_path = None
if 'video_files' not in st.session_state:
    st.session_state.video_files = []
if 'current_folder' not in st.session_state:
    st.session_state.current_folder = None
if 'all_videos_analysis_data' not in st.session_state:
    st.session_state.all_videos_analysis_data = None
if 'selected_segment' not in st.session_state:
    st.session_state.selected_segment = None
if 'selected_selling_points' not in st.session_state:
    st.session_state.selected_selling_points = []
if 'selected_segment_filter' not in st.session_state: # ä¸º result_display.py åˆå§‹åŒ–ç­›é€‰å™¨çŠ¶æ€
    st.session_state.selected_segment_filter = "æ˜¾ç¤ºå…¨éƒ¨"

# --- åŠ è½½é…ç½® ---
app_config = get_config()
# åˆå§‹åŒ– SemanticAnalyzer å•ä¾‹
sa_analyzer = SemanticAnalyzer()

# --- è®¾ç½®é»˜è®¤è§†é¢‘ç›®å½• ---
DEFAULT_VIDEO_DIR = os.path.join(ROOT_DIR, "data/input/test_videos")
if 'folder_path' not in st.session_state:
    st.session_state.folder_path = DEFAULT_VIDEO_DIR

# --- è‡ªåŠ¨åŠ è½½é»˜è®¤ç›®å½•ä¸‹çš„è§†é¢‘æ–‡ä»¶ ---
if not st.session_state.video_files and os.path.exists(DEFAULT_VIDEO_DIR):
    video_files = find_videos(DEFAULT_VIDEO_DIR)
    if video_files:
        st.session_state.video_files = video_files
        st.session_state.current_folder = DEFAULT_VIDEO_DIR
        print(f"DEBUG: Initial video files loaded: {st.session_state.video_files}") # æ·»åŠ æ—¥å¿—

# --- UI ç•Œé¢ ---
st.title("ğŸ”åˆ†æ")

# æ˜¾ç¤ºå·²åŠ è½½çš„è§†é¢‘æ–‡ä»¶æ•°é‡
if st.session_state.video_files:
    file_count = len(st.session_state.video_files)
    st.success(f"å·²åŠ è½½ {file_count} ä¸ªè§†é¢‘æ–‡ä»¶ - æ¥è‡ªç›®å½•: {st.session_state.current_folder}")

# --- é¡¶éƒ¨è¾“å…¥åŒºåŸŸï¼Œä½¿ç”¨å®¹å™¨ç¡®ä¿ç´§å‡‘ ---
input_container = st.container()
with input_container:
    # ä½¿ç”¨ä¸€è¡Œå¸ƒå±€
    col1, col2, col3 = st.columns([6, 3, 1])
    
    with col1:
        # æ–‡ä»¶ä¸Šä¼ åŒº
        if 'folder_path' not in st.session_state:
            st.session_state.folder_path = ""
            
        uploaded_files = st.file_uploader(
            "è§†é¢‘æ–‡ä»¶",
            type=["mp4", "avi", "mov", "mkv", "mpeg4"],
            accept_multiple_files=True,
            label_visibility="collapsed"
        )
        
        if uploaded_files:
            temp_dir = os.path.join(app_config.get("temp_dir", "data/temp"), "uploads")
            os.makedirs(temp_dir, exist_ok=True)
            
            st.session_state.video_files = []
            for uploaded_file in uploaded_files:
                file_path = os.path.join(temp_dir, uploaded_file.name)
                with open(file_path, "wb") as f:
                    f.write(uploaded_file.getbuffer())
                st.session_state.video_files.append(file_path)
            
            st.session_state.current_folder = temp_dir
            st.session_state.folder_path = temp_dir
            st.info(f"å·²ä¸Šä¼  {len(uploaded_files)} ä¸ªè§†é¢‘æ–‡ä»¶")
    
    with col2:
        # æ·»åŠ è¾“å…¥è·¯å¾„çš„æ–‡æœ¬æ¡†ï¼Œæ˜¾ç¤ºé»˜è®¤ç›®å½•
        folder_path = st.text_input(
            "è§†é¢‘è·¯å¾„",
            value=st.session_state.folder_path,
            placeholder="æˆ–è¾“å…¥è§†é¢‘æ–‡ä»¶å¤¹è·¯å¾„",
            label_visibility="hidden"
        )
    
    with col3:
        # å¯¼å…¥æŒ‰é’®
        import_btn = st.button("å¯¼å…¥", use_container_width=True)
        
        if import_btn and folder_path:
            if os.path.exists(folder_path):
                if os.path.isdir(folder_path):
                    video_files = find_videos(folder_path)
                    if video_files:
                        st.session_state.video_files = video_files
                        st.session_state.current_folder = folder_path
                        st.session_state.folder_path = folder_path
                        print(f"DEBUG: Video files after import button: {st.session_state.video_files}") # æ·»åŠ æ—¥å¿—
                        st.success(f"æˆåŠŸå¯¼å…¥æ–‡ä»¶å¤¹: {folder_path}ï¼Œæ‰¾åˆ°{len(video_files)}ä¸ªè§†é¢‘æ–‡ä»¶")
                    else:
                        st.warning(f"åœ¨{folder_path}ä¸­æœªæ‰¾åˆ°è§†é¢‘æ–‡ä»¶")
                else:
                    if any(folder_path.lower().endswith(ext) for ext in ['.mp4', '.avi', '.mov', '.mkv']):
                        st.session_state.uploaded_file_path = folder_path
                        st.session_state.video_files = [folder_path]
                        st.success(f"æˆåŠŸå¯¼å…¥å•ä¸ªæ–‡ä»¶: {folder_path}")
                    else:
                        st.error("è¯·é€‰æ‹©è§†é¢‘æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼")
            else:
                st.error("æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨ï¼")

# åˆ†ææŒ‰é’®åŒºåŸŸ
st.markdown("<div style='margin-top: 1rem;'></div>", unsafe_allow_html=True)
col1, col2, col3 = st.columns([1, 1, 1])
with col2:
    analyze_button = st.button("ğŸ” åˆ†æ", use_container_width=True, type="primary")

st.markdown("---")

# --- åˆ†æä¸ç»“æœå±•ç¤ºåŒºåŸŸ ---
if analyze_button and st.session_state.video_files:
    with st.spinner("æ­£åœ¨åˆ†æè§†é¢‘ï¼Œè¯·ç¨å€™..."):
        all_videos_analysis_data = [] # ç”¨äºå­˜å‚¨æ¯ä¸ªè§†é¢‘çš„å®Œæ•´åˆ†ææ•°æ®
        
        from streamlit_app.config.config import SELLING_POINTS as current_selling_points_config
        selling_points_for_cache = tuple(current_selling_points_config) 
        
        for video_path in st.session_state.video_files:
            video_file_name = os.path.basename(video_path)
            st.write(f"--- å¼€å§‹å¤„ç†è§†é¢‘: {video_file_name} ---")
            
            raw_segments, full_transcript_data = main_analysis_pipeline(
                video_path,
                None, 
                None, 
                selling_points_config_representation=selling_points_for_cache,
                additional_info=""  
            )
            
            semantic_segments_for_ui = {module: [] for module in get_semantic_modules()}
            if raw_segments:
                for segment_data in raw_segments:
                    semantic_type = segment_data.get("semantic_type", "æœªçŸ¥")
                    if semantic_type in get_semantic_segment_types():
                        semantic_segments_for_ui[semantic_type].append(segment_data)
            
            video_target_audiences = set()

            srt_content_for_llm = None
            if full_transcript_data:
                if 'srt_content' in full_transcript_data and full_transcript_data['srt_content']:
                    srt_content_for_llm = full_transcript_data['srt_content']
                    logger.info(f"ä½¿ç”¨ full_transcript_data ä¸­çš„SRTå†…å®¹è¿›è¡ŒLLMç›®æ ‡äººç¾¤åˆ†æ: {video_file_name}")
                elif 'srt_file_path' in full_transcript_data and full_transcript_data['srt_file_path']:
                    srt_path = full_transcript_data['srt_file_path']
                    logger.info(f"å°è¯•ä» srt_file_path è¯»å–SRTå†…å®¹: {srt_path} for video: {video_file_name}")
                    if os.path.exists(srt_path) and os.path.isfile(srt_path):
                        try:
                            with open(srt_path, 'r', encoding='utf-8') as f_srt:
                                srt_content_for_llm = f_srt.read()
                            if srt_content_for_llm:
                                logger.info(f"æˆåŠŸä»æ–‡ä»¶ {srt_path} è¯»å–SRTå†…å®¹è¿›è¡ŒLLMç›®æ ‡äººç¾¤åˆ†æ: {video_file_name}")
                            else:
                                logger.warning(f"SRTæ–‡ä»¶ {srt_path} ä¸ºç©ºã€‚")
                        except Exception as e_read_srt:
                            logger.error(f"è¯»å–SRTæ–‡ä»¶ {srt_path} å¤±è´¥: {e_read_srt}")
                    else:
                        logger.warning(f"SRTæ–‡ä»¶è·¯å¾„å­˜åœ¨äºfull_transcript_dataä¸­ï¼Œä½†æ–‡ä»¶æœªæ‰¾åˆ°æˆ–ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆæ–‡ä»¶: {srt_path}")
                else:
                    logger.warning(f"åœ¨ full_transcript_data ä¸­æœªæ‰¾åˆ° 'srt_content' æˆ– 'srt_file_path' é”®ï¼Œæˆ–è€…è·¯å¾„æ— æ•ˆ: {video_file_name}. Keys: {list(full_transcript_data.keys()) if full_transcript_data else 'N/A'}")
            else:
                logger.warning(f"full_transcript_data ä¸ºç©ºï¼Œæ— æ³•è·å–SRTå†…å®¹è¿›è¡ŒLLMç›®æ ‡äººç¾¤åˆ†æ: {video_file_name}")

            if srt_content_for_llm:
                try:
                    logger.info(f"å¯¹SRTå†…å®¹è¿›è¡ŒLLMåˆ†æä»¥è¯†åˆ«ç›®æ ‡äººç¾¤: {video_file_name}")
                    summary_results = sa_analyzer.analyze_video_summary(srt_content_for_llm)
                    
                    if summary_results and 'target_audience' in summary_results:
                        target_audience = summary_results['target_audience']
                        # ç¡®ä¿åªè¿”å›ä¸€ä¸ªç›®æ ‡äººç¾¤
                        if target_audience and target_audience in TARGET_GROUPS:
                            video_target_audiences.add(target_audience)

                    # å…œåº•æœºåˆ¶ï¼šå¦‚æœLLMæ²¡æœ‰è¯†åˆ«å‡ºç›®æ ‡äººç¾¤ï¼ŒåŸºäºå…³é”®è¯è¿›è¡Œå…œåº•åˆ†æ
                    if not video_target_audiences:
                        logger.warning(f"LLMæœªèƒ½è¯†åˆ«å‡ºç›®æ ‡äººç¾¤ï¼Œå¯ç”¨å…³é”®è¯å…œåº•æœºåˆ¶: {video_file_name}")
                        srt_lower = srt_content_for_llm.lower()
                        
                        # å…³é”®è¯æ˜ å°„è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰
                        priority_mapping = [
                            ("äºŒèƒå¦ˆå¦ˆ", ["äºŒèƒ", "è€å¤§", "è€äºŒ", "ä¸¤ä¸ªå­©å­", "å¤§å®", "äºŒå®"]),
                            ("å­•æœŸå¦ˆå¦ˆ", ["åˆšç”Ÿå®Œ", "äº§å", "å¾…äº§åŒ…", "äº§æ£€", "å»ºæ¡£", "å‡†å¦ˆå¦ˆ", "å¸è´§", "åˆ†å¨©", "ç”Ÿäº§", "äº§ç§‘", "æ–°ç”Ÿå®å®", "å‡ºç”Ÿå"]),
                            ("æ··å…»å¦ˆå¦ˆ", ["æ··åˆå–‚å…»", "æ··å–‚", "äº²å–‚", "æ¯ä¹³ä¸è¶³", "å¥¶é‡ä¸å¤Ÿ", "å¥¶æ°´ä¸è¶³"]),
                            ("è´µå¦‡å¦ˆå¦ˆ", ["é«˜ç«¯", "å¥¢å", "ç²¾è‡´", "å“è´¨", "è´µ", "é«˜ä»·", "è¿›å£", "é¡¶çº§"]),
                            ("æ–°æ‰‹çˆ¸å¦ˆ", ["æ–°æ‰‹", "æ²¡æœ‰ç»éªŒ", "ç¬¬ä¸€æ¬¡", "ä¸çŸ¥é“æ€ä¹ˆ", "å­¦ä¹ ", "åˆæ¬¡", "æ–°æ‰‹çˆ¸çˆ¸", "æ–°æ‰‹å¦ˆå¦ˆ"])
                        ]
                        
                        # æŒ‰ä¼˜å…ˆçº§æ£€æŸ¥å…³é”®è¯åŒ¹é…ï¼Œæ‰¾åˆ°ç¬¬ä¸€ä¸ªåŒ¹é…çš„å°±åœæ­¢
                        target_found = False
                        for target_group, keywords in priority_mapping:
                            if not target_found:
                                for keyword in keywords:
                                    if keyword in srt_lower:
                                        video_target_audiences.add(target_group)
                                        logger.info(f"é€šè¿‡å…³é”®è¯ '{keyword}' è¯†åˆ«ç›®æ ‡äººç¾¤ '{target_group}': {video_file_name}")
                                        target_found = True
                                        break
                        
                        # å¦‚æœä»ç„¶æ²¡æœ‰è¯†åˆ«å‡ºç›®æ ‡äººç¾¤ï¼Œä½¿ç”¨æœ€ç»ˆå…œåº•
                        if not target_found:
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«äº§å“ç›¸å…³å†…å®¹ï¼Œå¦‚æœæœ‰åˆ™é»˜è®¤åˆ†é…ç»™"æ–°æ‰‹çˆ¸å¦ˆ"
                            product_keywords = ["å¥¶ç²‰", "å¯èµ‹", "è•´æ·³", "æ°´å¥¶", "æ¯ä¹³ä½èšç³–", "hmo", "a2å¥¶æº"]
                            has_product_content = any(keyword in srt_lower for keyword in product_keywords)
                            
                            if has_product_content:
                                video_target_audiences.add("æ–°æ‰‹çˆ¸å¦ˆ")
                                logger.info(f"åŸºäºäº§å“å†…å®¹ç‰¹å¾ï¼Œé»˜è®¤åˆ†é…ç»™'æ–°æ‰‹çˆ¸å¦ˆ': {video_file_name}")
                            else:
                                # æœ€ç»ˆå…œåº•ï¼šåˆ†é…ç»™æœ€é€šç”¨çš„"æ–°æ‰‹çˆ¸å¦ˆ"
                                video_target_audiences.add("æ–°æ‰‹çˆ¸å¦ˆ")
                                logger.info(f"æœ€ç»ˆå…œåº•æœºåˆ¶ï¼Œåˆ†é…ç»™'æ–°æ‰‹çˆ¸å¦ˆ': {video_file_name}")

                    if video_target_audiences:
                        logger.info(f"æœ€ç»ˆç›®æ ‡äººç¾¤åˆ†æç»“æœ - {video_file_name} - ç›®æ ‡äººç¾¤: {list(video_target_audiences)}")
                    else:
                        logger.error(f"ä¸¥é‡é”™è¯¯ï¼šå…œåº•æœºåˆ¶å¤±è´¥ï¼Œä»æœªè¯†åˆ«å‡ºç›®æ ‡äººç¾¤: {video_file_name}")
                except Exception as e_llm_srt:
                    logger.error(f"LLMåˆ†æSRTå†…å®¹ä»¥è¯†åˆ«ç›®æ ‡äººç¾¤æ—¶å‘ç”Ÿé”™è¯¯ - {video_file_name}: {str(e_llm_srt)}")
                    # å¼‚å¸¸æƒ…å†µçš„å…œåº•ï¼šåˆ†é…ç»™"æ–°æ‰‹çˆ¸å¦ˆ"
                    video_target_audiences.add("æ–°æ‰‹çˆ¸å¦ˆ")
                    logger.info(f"å¼‚å¸¸æƒ…å†µå…œåº•ï¼Œåˆ†é…ç»™'æ–°æ‰‹çˆ¸å¦ˆ': {video_file_name}")
            else:
                logger.warning(f"æ²¡æœ‰å¯ä¾›åˆ†æçš„SRTå†…å®¹ï¼Œæ— æ³•è¯†åˆ«ç›®æ ‡äººç¾¤: {video_file_name}")
                # æ²¡æœ‰SRTå†…å®¹çš„å…œåº•ï¼šåˆ†é…ç»™"æ–°æ‰‹çˆ¸å¦ˆ"
                video_target_audiences.add("æ–°æ‰‹çˆ¸å¦ˆ")
                logger.info(f"æ— SRTå†…å®¹å…œåº•ï¼Œåˆ†é…ç»™'æ–°æ‰‹çˆ¸å¦ˆ': {video_file_name}")
            
            semantic_segments_for_ui = {k: v for k, v in semantic_segments_for_ui.items() if v}
            
            all_videos_analysis_data.append({
                "video_id": os.path.splitext(video_file_name)[0],
                "video_path": video_path,
                "semantic_segments": semantic_segments_for_ui, 
                "full_transcript_data": full_transcript_data,
                "target_audiences": list(video_target_audiences) if video_target_audiences else [] 
            })
        
        st.session_state.all_videos_analysis_data = all_videos_analysis_data
        
        if not st.session_state.all_videos_analysis_data:
            st.warning("æ‰€æœ‰è§†é¢‘å‡åˆ†æå®Œæˆï¼Œä½†æœªè·å¾—ä»»ä½•æœ‰æ•ˆç»“æœã€‚")
        
        try:
            logger.info("å¼€å§‹è°ƒç”¨ organize_segments_by_type() å‡½æ•°ç»„ç»‡è§†é¢‘ç‰‡æ®µ...")
            success = organize_segments_by_type() # æ­¤å‡½æ•°ç°åœ¨åªè´Ÿè´£å¤åˆ¶ç‰©ç†æ–‡ä»¶
            if success:
                st.success("å·²æŒ‰è¯­ä¹‰ç±»å‹ç»„ç»‡è§†é¢‘ç‰‡æ®µåˆ°data/outputç›®å½•")
                logger.info("è§†é¢‘ç‰‡æ®µå·²æˆåŠŸæŒ‰è¯­ä¹‰ç±»å‹ç»„ç»‡")
            else:
                st.warning("è§†é¢‘ç‰‡æ®µç»„ç»‡è¿‡ç¨‹ä¸­é‡åˆ°é—®é¢˜ï¼Œè¯·æŸ¥çœ‹æ—¥å¿—äº†è§£è¯¦æƒ…")
                logger.warning("è§†é¢‘ç‰‡æ®µç»„ç»‡å¤±è´¥")
        except Exception as e:
            st.error(f"ç»„ç»‡è§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
            logger.error(f"è°ƒç”¨ organize_segments_by_type() å‡½æ•°å‡ºé”™: {str(e)}", exc_info=True)

        # --- ç¡®ä¿åœ¨åˆ†ææµç¨‹çš„æœ«å°¾æ­£ç¡®ä¿å­˜å…ƒæ•°æ®å’Œç”ŸæˆSRT ---
        if analyze_button and st.session_state.video_files: # ç¡®ä¿è¿™äº›æ“ä½œåœ¨åˆ†æå®Œæˆåæ‰§è¡Œ
            if st.session_state.all_videos_analysis_data:
                logger.info("å‡†å¤‡ï¼ˆå†æ¬¡ç¡®è®¤ï¼‰ä¿å­˜æ‰€æœ‰è§†é¢‘ç‰‡æ®µçš„è¯¦ç»†å…ƒæ•°æ®...")
                if save_detailed_segments_metadata(st.session_state.all_videos_analysis_data, ROOT_DIR, logger):
                    logger.info("è¯¦ç»†ç‰‡æ®µå…ƒæ•°æ®ï¼ˆå†æ¬¡ç¡®è®¤ï¼‰ä¿å­˜æˆåŠŸã€‚")
                    
                    # --- æ–°å¢ï¼šç‰‡æ®µåˆ†æåŠŸèƒ½ ---
                    st.subheader("ğŸ” æ™ºèƒ½åˆ†æç‰‡æ®µå†…å®¹")
                    with st.spinner("æ­£åœ¨åˆ†æå„ç‰‡æ®µçš„äº§å“ç±»å‹å’Œæ ¸å¿ƒå–ç‚¹..."):
                        try:
                            # æ”¶é›†æ‰€æœ‰ç‰‡æ®µæ•°æ®
                            all_segments_for_analysis = []
                            for video_data in st.session_state.all_videos_analysis_data:
                                for semantic_type, segments in video_data.get("semantic_segments", {}).items():
                                    for segment in segments:
                                        # å‡†å¤‡ç‰‡æ®µæ•°æ®ç”¨äºåˆ†æ
                                        segment_data = {
                                            'semantic_type': semantic_type,
                                            'start_time': segment.get('start_time_ms', 0.0) / 1000.0,
                                            'end_time': segment.get('end_time_ms', 0.0) / 1000.0,
                                            'time_period': segment.get('time_info', ''),
                                            'text': segment.get('transcript', ''),
                                            'confidence': 1.0,
                                            'analyzed_product_type': segment.get('analyzed_product_type', 'æœªè¯†åˆ«'),
                                            'analyzed_selling_points': segment.get('analyzed_selling_points', []),
                                            'file_path': os.path.join(ROOT_DIR, "data", "output", semantic_type, segment.get('filename', ''))
                                        }
                                        all_segments_for_analysis.append(segment_data)
                            
                            if all_segments_for_analysis:
                                logger.info(f"å¼€å§‹åˆ†æ {len(all_segments_for_analysis)} ä¸ªç‰‡æ®µ...")
                                
                                # ä½¿ç”¨ç¼“å­˜é”®é¿å…é‡å¤åˆ†æ
                                segments_cache_key = f"segments_analysis_{len(all_segments_for_analysis)}_{hash(str(all_segments_for_analysis[:3]))}"
                                
                                # æ‰§è¡Œå¹¶è¡Œåˆ†æ
                                analyzed_segments = analyze_segments_batch(all_segments_for_analysis, max_workers=3)
                                
                                # ç»Ÿè®¡åˆ†æç»“æœ
                                product_types_found = {}
                                selling_points_found = {}
                                
                                for segment in analyzed_segments:
                                    product_type = segment.get("analyzed_product_type", "")
                                    selling_points = segment.get("analyzed_selling_points", [])
                                    
                                    if product_type:
                                        product_types_found[product_type] = product_types_found.get(product_type, 0) + 1
                                    
                                    for sp in selling_points:
                                        selling_points_found[sp] = selling_points_found.get(sp, 0) + 1
                                
                                # æ˜¾ç¤ºåˆ†æç»“æœç»Ÿè®¡
                                col1, col2 = st.columns(2)
                                
                                with col1:
                                    st.write("**è¯†åˆ«åˆ°çš„äº§å“ç±»å‹:**")
                                    if product_types_found:
                                        for pt, count in product_types_found.items():
                                            st.write(f"- {pt}: {count} ä¸ªç‰‡æ®µ")
                                    else:
                                        st.write("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„äº§å“ç±»å‹")
                                
                                with col2:
                                    st.write("**è¯†åˆ«åˆ°çš„æ ¸å¿ƒå–ç‚¹:**")
                                    if selling_points_found:
                                        for sp, count in selling_points_found.items():
                                            st.write(f"- {sp}: {count} ä¸ªç‰‡æ®µ")
                                    else:
                                        st.write("æœªè¯†åˆ«åˆ°æ˜ç¡®çš„æ ¸å¿ƒå–ç‚¹")
                                
                                logger.info(f"ç‰‡æ®µåˆ†æå®Œæˆã€‚äº§å“ç±»å‹: {list(product_types_found.keys())}ï¼Œå–ç‚¹: {list(selling_points_found.keys())}")
                                st.success(f"âœ… å·²å®Œæˆ {len(analyzed_segments)} ä¸ªç‰‡æ®µçš„æ™ºèƒ½åˆ†æ")
                                
                                # å°†åˆ†æç»“æœä¿å­˜åˆ°å…ƒæ•°æ®æ–‡ä»¶
                                try:
                                    logger.info("å¼€å§‹å°†ç‰‡æ®µåˆ†æç»“æœä¿å­˜åˆ°å…ƒæ•°æ®æ–‡ä»¶...")
                                    if update_metadata_with_analysis_results(analyzed_segments, ROOT_DIR, logger):
                                        logger.info("ç‰‡æ®µåˆ†æç»“æœå·²æˆåŠŸä¿å­˜åˆ°å…ƒæ•°æ®æ–‡ä»¶ã€‚")
                                        st.success("ğŸ”– åˆ†æç»“æœå·²ä¿å­˜åˆ°å…ƒæ•°æ®")
                                    else:
                                        logger.warning("ä¿å­˜ç‰‡æ®µåˆ†æç»“æœåˆ°å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥ã€‚")
                                        st.warning("âš ï¸ åˆ†æç»“æœä¿å­˜å¤±è´¥")
                                except Exception as e_save_analysis:
                                    logger.error(f"ä¿å­˜ç‰‡æ®µåˆ†æç»“æœæ—¶å‡ºé”™: {str(e_save_analysis)}")
                                    st.error(f"ä¿å­˜åˆ†æç»“æœå¤±è´¥: {str(e_save_analysis)}")
                                
                                # å°†åˆ†æç»“æœåˆå¹¶å›åŸå§‹æ•°æ®ç»“æ„
                                # TODO: è¿™é‡Œå¯ä»¥æ‰©å±•å°†åˆ†æç»“æœä¿å­˜åˆ°å…ƒæ•°æ®æ–‡ä»¶ä¸­
                                
                            else:
                                st.info("æ²¡æœ‰æ‰¾åˆ°å¯åˆ†æçš„ç‰‡æ®µæ•°æ®")
                                
                        except Exception as e_segment_analysis:
                            logger.error(f"ç‰‡æ®µåˆ†æè¿‡ç¨‹ä¸­å‡ºé”™: {str(e_segment_analysis)}")
                            st.error(f"ç‰‡æ®µåˆ†æå¤±è´¥: {str(e_segment_analysis)}")
                    
                    logger.info("å‡†å¤‡ï¼ˆå†æ¬¡ç¡®è®¤ï¼‰ä¸ºæ‰€æœ‰ç‰‡æ®µç”ŸæˆSRTå­—å¹•æ–‡ä»¶...")
                    create_srt_files_for_segments(ROOT_DIR, logger)
                    logger.info("SRTå­—å¹•æ–‡ä»¶ï¼ˆå†æ¬¡ç¡®è®¤ï¼‰ç”Ÿæˆæµç¨‹è°ƒç”¨å®Œæ¯•ã€‚")
                else:
                    logger.error("è¯¦ç»†ç‰‡æ®µå…ƒæ•°æ®ï¼ˆå†æ¬¡ç¡®è®¤ï¼‰ä¿å­˜å¤±è´¥ã€‚")
            else:
                logger.warning("åˆ†æåæ²¡æœ‰æœ‰æ•ˆçš„åˆ†ææ•°æ®å¯ç”¨äºä¿å­˜å…ƒæ•°æ®ã€‚all_videos_analysis_data ä¸ºç©ºæˆ–ä¸å­˜åœ¨ã€‚")

# ğŸ†• ç‰‡æ®µç¼–è¾‘å™¨ - ä½œä¸ºä¸»è¦åŠŸèƒ½
# æ€»æ˜¯å°è¯•åŠ è½½å®Œæ•´çš„æ•°æ®ï¼ˆåŒ…æ‹¬æ–°åˆ†æå’Œå†å²æ•°æ®ï¼‰
def load_complete_analysis_data():
    """åŠ è½½å®Œæ•´çš„åˆ†ææ•°æ®ï¼ŒåŒ…æ‹¬æ–°åˆ†æå’Œå†å²æ•°æ®"""
    complete_data = {}
    
    # 1. é¦–å…ˆåŠ è½½å†å²æ•°æ®
    try:
        import json
        metadata_file = "data/output/video_segments_metadata.json"
        if os.path.exists(metadata_file):
            with open(metadata_file, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            
            if metadata:
                logger.info(f"ä»å…ƒæ•°æ®æ–‡ä»¶åŠ è½½äº† {len(metadata)} ä¸ªç‰‡æ®µçš„å†å²æ•°æ®")
                
                # è½¬æ¢å…ƒæ•°æ®ä¸ºæ ‡å‡†æ ¼å¼
                for segment in metadata:
                    video_id = segment.get('original_video_id', 'unknown')
                    if video_id not in complete_data:
                        complete_data[video_id] = {
                            'video_id': video_id,
                            'video_path': segment.get('video_path', ''),
                            'semantic_segments': {},
                            'target_audiences': [segment.get('target_audiences', 'æ–°æ‰‹çˆ¸å¦ˆ')]
                        }
                    
                    semantic_type = segment.get('type', 'å…¶ä»–')
                    if semantic_type not in complete_data[video_id]['semantic_segments']:
                        complete_data[video_id]['semantic_segments'][semantic_type] = []
                    
                    segment_data = {
                        'semantic_type': semantic_type,
                        'start_time': segment.get('start_time_ms', 0.0) / 1000.0,
                        'end_time': segment.get('end_time_ms', 0.0) / 1000.0,
                        'time_period': segment.get('time_info', ''),
                        'text': segment.get('transcript', ''),
                        'confidence': 1.0,
                        'analyzed_product_type': segment.get('analyzed_product_type', 'æœªè¯†åˆ«'),
                        'analyzed_selling_points': segment.get('analyzed_selling_points', []),
                        'file_path': os.path.join(ROOT_DIR, "data", "output", semantic_type, segment.get('filename', ''))
                    }
                    
                    complete_data[video_id]['semantic_segments'][semantic_type].append(segment_data)
    except Exception as e:
        logger.error(f"åŠ è½½å†å²æ•°æ®å¤±è´¥: {e}")
    
    # 2. ç„¶ååˆå¹¶æ–°åˆ†æçš„æ•°æ®ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
    if st.session_state.get('all_videos_analysis_data'):
        logger.info(f"åˆå¹¶æ–°åˆ†æçš„ {len(st.session_state.all_videos_analysis_data)} ä¸ªè§†é¢‘æ•°æ®")
        
        for video_data in st.session_state.all_videos_analysis_data:
            video_id = video_data.get("video_id", "unknown")
            
            # å¦‚æœæ˜¯æ–°è§†é¢‘ï¼Œç›´æ¥æ·»åŠ ï¼›å¦‚æœæ˜¯å·²å­˜åœ¨çš„è§†é¢‘ï¼Œæ›´æ–°æ•°æ®
            complete_data[video_id] = video_data
    
    return list(complete_data.values())

# åŠ è½½å®Œæ•´çš„åˆ†ææ•°æ®
complete_analysis_data = load_complete_analysis_data()

if complete_analysis_data:
    st.markdown("### âœï¸ ç‰‡æ®µç¼–è¾‘å™¨")
    st.markdown("åœ¨è¿™é‡Œæ‚¨å¯ä»¥è°ƒæ•´è§†é¢‘ç‰‡æ®µçš„æ—¶é—´ã€è¯­ä¹‰ç±»å‹ç­‰ä¿¡æ¯ï¼Œæ‚¨çš„ä¿®æ”¹å°†ç”¨äºæ”¹è¿›æ¨¡å‹çš„åˆ†æå‡†ç¡®æ€§ã€‚")
    
    # å¯¼å…¥ç‰‡æ®µç¼–è¾‘å™¨
    try:
        from streamlit_app.modules.analysis.segment_editor import SegmentEditor
        
        # åˆ›å»ºç‰‡æ®µç¼–è¾‘å™¨å®ä¾‹
        segment_editor = SegmentEditor()
        
        # ä¸ºæ¯ä¸ªè§†é¢‘æ˜¾ç¤ºç‰‡æ®µç¼–è¾‘å™¨
        for video_data in complete_analysis_data:
            video_id = video_data.get("video_id", "unknown")
            video_path = video_data.get("video_path", "")
            semantic_segments = video_data.get("semantic_segments", {})
            target_audiences = video_data.get("target_audiences", ["æ–°æ‰‹çˆ¸å¦ˆ"])
            
            # å°†è¯­ä¹‰ç‰‡æ®µè½¬æ¢ä¸ºæ‰å¹³åˆ—è¡¨
            all_segments = []
            
            # è®¡ç®—å…¨å±€ç‰‡æ®µç´¢å¼•
            global_segment_index = 0
            
            # ç¡®ä¿semantic_segmentsæ˜¯å­—å…¸æ ¼å¼
            if isinstance(semantic_segments, dict):
                # é¦–å…ˆæ”¶é›†æ‰€æœ‰ç‰‡æ®µä»¥ç¡®å®šæ­£ç¡®çš„ç´¢å¼•
                all_segments_with_types = []
                for semantic_type, segments in semantic_segments.items():
                    if isinstance(segments, list):
                        for segment in segments:
                            all_segments_with_types.append((semantic_type, segment))
                
                # ç°åœ¨å¤„ç†æ¯ä¸ªç‰‡æ®µï¼Œä½¿ç”¨æ­£ç¡®çš„å…¨å±€ç´¢å¼•
                for idx, (semantic_type, segment) in enumerate(all_segments_with_types):
                    # ç¡®ä¿ç‰‡æ®µåŒ…å«å¿…è¦çš„ä¿¡æ¯
                    segment_data = {
                        'semantic_type': semantic_type,
                        'start_time': segment.get('start_time', 0.0),
                        'end_time': segment.get('end_time', 0.0),
                        'time_period': segment.get('time_period', ''),
                        'text': segment.get('text', ''),
                        'confidence': segment.get('confidence', 0.0),
                        'product_type': segment.get('analyzed_product_type', 'æœªè¯†åˆ«'),
                        'target_audience': target_audiences[0] if target_audiences else 'æ–°æ‰‹çˆ¸å¦ˆ',
                        'selling_points': segment.get('analyzed_selling_points', [])
                    }
                    
                    # ç›´æ¥ä½¿ç”¨segmentä¸­å·²æœ‰çš„file_pathï¼Œå¦‚æœæ²¡æœ‰åˆ™æ„å»º
                    if 'file_path' in segment and segment['file_path']:
                        segment_data['file_path'] = segment['file_path']
                    else:
                        # æ„å»ºæ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨å…¨å±€ç´¢å¼•
                        segment_filename = f"{video_id}_semantic_seg_{idx}_{semantic_type}.mp4"
                        segment_data['file_path'] = os.path.join(ROOT_DIR, "data", "output", semantic_type, segment_filename)
                    
                    all_segments.append(segment_data)
            elif isinstance(semantic_segments, list):
                # å¦‚æœsemantic_segmentsæ˜¯åˆ—è¡¨ï¼Œç›´æ¥å¤„ç†
                for i, segment in enumerate(semantic_segments):
                    segment_data = {
                        'semantic_type': segment.get('semantic_type', 'å…¶ä»–'),
                        'start_time': segment.get('start_time', 0.0),
                        'end_time': segment.get('end_time', 0.0),
                        'time_period': segment.get('time_period', ''),
                        'text': segment.get('text', ''),
                        'confidence': segment.get('confidence', 0.0),
                        'product_type': segment.get('analyzed_product_type', 'æœªè¯†åˆ«'),
                        'target_audience': target_audiences[0] if target_audiences else 'æ–°æ‰‹çˆ¸å¦ˆ',
                        'selling_points': segment.get('analyzed_selling_points', [])
                    }
                    
                    # æ„å»ºæ–‡ä»¶è·¯å¾„
                    semantic_type = segment.get('semantic_type', 'å…¶ä»–')
                    segment_filename = f"{video_id}_semantic_seg_{i}_{semantic_type}.mp4"
                    segment_data['file_path'] = os.path.join(ROOT_DIR, "data", "output", semantic_type, segment_filename)
                    
                    all_segments.append(segment_data)
            
            if all_segments:
                st.markdown(f"#### ğŸ¬ è§†é¢‘: {video_id} ({len(all_segments)} ä¸ªç‰‡æ®µ)")
                
                # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ–‡ä»¶è·¯å¾„
                with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯ - æ–‡ä»¶è·¯å¾„", expanded=False):
                    for i, seg in enumerate(all_segments[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                        st.write(f"ç‰‡æ®µ {i+1}:")
                        st.write(f"  è¯­ä¹‰ç±»å‹: {seg.get('semantic_type')}")
                        st.write(f"  æ–‡ä»¶è·¯å¾„: {seg.get('file_path')}")
                        st.write(f"  æ–‡ä»¶å­˜åœ¨: {os.path.exists(seg.get('file_path', ''))}")
                
                # æ¸²æŸ“ç‰‡æ®µç¼–è¾‘å™¨ï¼ˆè¡¨æ ¼å½¢å¼ï¼‰
                updated_segments = segment_editor.render_segment_list(all_segments, video_id)
                
                # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜åé¦ˆæ•°æ®
                if updated_segments:
                    try:
                        from streamlit_app.modules.analysis.feedback_manager import get_feedback_manager
                        feedback_manager = get_feedback_manager()
                        
                        # ä¿å­˜ç”¨æˆ·åé¦ˆ
                        feedback_data = {
                            'video_id': video_id,
                            'original_segments': all_segments,
                            'updated_segments': updated_segments,
                            'timestamp': datetime.now().isoformat()
                        }
                        
                        feedback_manager.save_segment_correction(feedback_data)
                        
                    except Exception as e:
                        st.warning(f"ä¿å­˜åé¦ˆæ•°æ®å¤±è´¥: {e}")
            else:
                st.info(f"è§†é¢‘ {video_id} æš‚æ— ç‰‡æ®µæ•°æ®")
    
    except ImportError as e:
        st.error(f"æ— æ³•åŠ è½½ç‰‡æ®µç¼–è¾‘å™¨: {e}")
    except Exception as e:
        st.error(f"ç‰‡æ®µç¼–è¾‘å™¨å‡ºé”™: {e}")
        st.exception(e)  # æ˜¾ç¤ºè¯¦ç»†é”™è¯¯ä¿¡æ¯
else:
    st.info("æš‚æ— è§†é¢‘åˆ†ææ•°æ®ï¼Œè¯·å…ˆä¸Šä¼ è§†é¢‘å¹¶è¿›è¡Œåˆ†æã€‚")

# é”™è¯¯æ¶ˆæ¯ï¼šä»…å½“ç”¨æˆ·æ˜ç¡®ç‚¹å‡»åˆ†ææŒ‰é’®ä½†æ²¡æœ‰é€‰æ‹©ä»»ä½•è§†é¢‘æ–‡ä»¶æ—¶æ˜¾ç¤ºã€‚
if analyze_button and not st.session_state.video_files:
    st.error("è¯·å…ˆä¸Šä¼ æˆ–æŒ‡å®šä¸€ä¸ªè§†é¢‘æ–‡ä»¶/æ–‡ä»¶å¤¹å†è¿›è¡Œåˆ†æï¼") 