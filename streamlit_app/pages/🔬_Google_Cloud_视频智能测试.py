"""
Google Cloud Video Intelligence API æµ‹è¯•é¡µé¢

ç”¨äºŽæµ‹è¯• Google Cloud Video Intelligence API çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- é•œå¤´åˆ‡åˆ†æ£€æµ‹
- è§†è§‰æ ‡ç­¾æ£€æµ‹
- ðŸ“¦ ç‰©ä½“è·Ÿè¸ª
- âœ‚ï¸ è‡ªåŠ¨åˆ‡åˆ†
- ðŸ“Š æ‰¹é‡åˆ†æž
"""

import streamlit as st
import os
import tempfile
import json
from pathlib import Path
import time
import logging
import shutil

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
root_dir = Path(__file__).parent.parent.parent
if str(root_dir) not in sys.path:
    sys.path.insert(0, str(root_dir))

# æ ‡ç­¾ç¿»è¯‘å­—å…¸
LABEL_TRANSLATIONS = {
    # åŠ¨ç‰©ç±»
    "animal": "åŠ¨ç‰©",
    "cat": "çŒ«",
    "cats": "çŒ«",
    "kitten": "å°çŒ«",
    "kitty": "å°çŒ«",
    "tabby": "è™Žæ–‘çŒ«",
    "persian cat": "æ³¢æ–¯çŒ«",
    "maine coon": "ç¼…å› çŒ«",
    "siamese cat": "æš¹ç½—çŒ«",
    "whiskers": "èƒ¡é¡»",
    "paw": "çˆªå­",
    "tail": "å°¾å·´",
    "fur": "æ¯›å‘",
    "pet": "å® ç‰©",
    "pets": "å® ç‰©",
    "dog": "ç‹—",
    "puppy": "å°ç‹—",
    "bird": "é¸Ÿ",
    "fish": "é±¼",
    "horse": "é©¬",
    "cow": "ç‰›",
    "sheep": "ç¾Š",
    "pig": "çŒª",
    "chicken": "é¸¡",
    "duck": "é¸­",
    "rabbit": "å…”å­",
    "mouse": "è€é¼ ",
    "elephant": "å¤§è±¡",
    "lion": "ç‹®å­",
    "tiger": "è€è™Ž",
    "bear": "ç†Š",
    "monkey": "çŒ´å­",
    "panda": "ç†ŠçŒ«",
    
    # å°ºå¯¸æè¿°
    "small": "å°",
    "medium": "ä¸­ç­‰",
    "large": "å¤§",
    "tiny": "å¾®å°",
    "huge": "å·¨å¤§",
    "sized": "å¤§å°çš„",
    "to": "åˆ°",
    
    # é£Ÿç‰©ç±»
    "food": "é£Ÿç‰©",
    "fruit": "æ°´æžœ",
    "vegetable": "è”¬èœ",
    "meat": "è‚‰ç±»",
    "bread": "é¢åŒ…",
    "cake": "è›‹ç³•",
    "pizza": "æŠ«è¨",
    "hamburger": "æ±‰å ¡",
    "sandwich": "ä¸‰æ˜Žæ²»",
    "noodles": "é¢æ¡",
    "rice": "ç±³é¥­",
    "soup": "æ±¤",
    "salad": "æ²™æ‹‰",
    "coffee": "å’–å•¡",
    "tea": "èŒ¶",
    "milk": "ç‰›å¥¶",
    "formula": "å¥¶ç²‰",
    "baby formula": "å©´å„¿å¥¶ç²‰",
    "infant formula": "å©´å¹¼å„¿å¥¶ç²‰",
    "powder": "ç²‰æœ«",
    "bottle": "å¥¶ç“¶",
    "feeding bottle": "å¥¶ç“¶",
    "baby bottle": "å©´å„¿å¥¶ç“¶",
    "sippy cup": "å­¦é¥®æ¯",
    "pacifier": "å¥¶å˜´",
    "bib": "å›´å˜´",
    "high chair": "é«˜è„šæ¤…",
    "baby food": "å©´å„¿é£Ÿå“",
    "cereal": "ç±³ç²‰",
    "juice": "æžœæ±",
    "water": "æ°´",
    "beer": "å•¤é…’",
    "wine": "é…’",
    
    # äº¤é€šå·¥å…·
    "car": "æ±½è½¦",
    "bus": "å…¬äº¤è½¦",
    "truck": "å¡è½¦",
    "motorcycle": "æ‘©æ‰˜è½¦",
    "bicycle": "è‡ªè¡Œè½¦",
    "train": "ç«è½¦",
    "airplane": "é£žæœº",
    "boat": "èˆ¹",
    "ship": "è½®èˆ¹",
    "taxi": "å‡ºç§Ÿè½¦",
    
    # å»ºç­‘ç‰©å’Œåœºæ‰€
    "house": "æˆ¿å­",
    "home": "å®¶",
    "building": "å»ºç­‘ç‰©",
    "room": "æˆ¿é—´",
    "bedroom": "å§å®¤",
    "living room": "å®¢åŽ…",
    "kitchen": "åŽ¨æˆ¿",
    "bathroom": "æµ´å®¤",
    "nursery": "å©´å„¿æˆ¿",
    "playroom": "æ¸¸æˆå®¤",
    "park": "å…¬å›­",
    "playground": "æ¸¸ä¹åœº",
    "hospital": "åŒ»é™¢",
    "clinic": "è¯Šæ‰€",
    "daycare": "æ‰˜å„¿æ‰€",
    "kindergarten": "å¹¼å„¿å›­",
    "school": "å­¦æ ¡",
    "church": "æ•™å ‚",
    "bridge": "æ¡¥",
    "tower": "å¡”",
    "castle": "åŸŽå ¡",
    "temple": "å¯ºåº™",
    "museum": "åšç‰©é¦†",
    "store": "å•†åº—",
    "supermarket": "è¶…å¸‚",
    "mall": "å•†åœº",
    
    # è‡ªç„¶æ™¯è§‚
    "tree": "æ ‘",
    "flower": "èŠ±",
    "grass": "è‰",
    "mountain": "å±±",
    "river": "æ²³",
    "lake": "æ¹–",
    "sea": "æµ·",
    "beach": "æµ·æ»©",
    "forest": "æ£®æž—",
    "sky": "å¤©ç©º",
    "cloud": "äº‘",
    "sun": "å¤ªé˜³",
    "moon": "æœˆäº®",
    "star": "æ˜Ÿæ˜Ÿ",
    "snow": "é›ª",
    "rain": "é›¨",
    
    # äººç‰©ç›¸å…³
    "person": "äºº",
    "people": "äººä»¬",
    "man": "ç”·äºº",
    "woman": "å¥³äºº",
    "child": "å­©å­",
    "children": "å­©å­ä»¬",
    "baby": "å©´å„¿",
    "babies": "å©´å„¿ä»¬",
    "infant": "å©´å¹¼å„¿",
    "toddler": "å¹¼å„¿",
    "boy": "ç”·å­©",
    "girl": "å¥³å­©",
    "kid": "å°å­©",
    "kids": "å°å­©ä»¬",
    "mother": "å¦ˆå¦ˆ",
    "mom": "å¦ˆå¦ˆ",
    "father": "çˆ¸çˆ¸",
    "dad": "çˆ¸çˆ¸",
    "parent": "çˆ¶æ¯",
    "parents": "çˆ¶æ¯",
    "family": "å®¶åº­",
    "face": "è„¸",
    "hand": "æ‰‹",
    "hands": "æ‰‹",
    "eye": "çœ¼ç›",
    "eyes": "çœ¼ç›",
    "hair": "å¤´å‘",
    "smile": "å¾®ç¬‘",
    "smiling": "å¾®ç¬‘",
    "crying": "å“­æ³£",
    "laughing": "å¤§ç¬‘",
    
    # ç‰©å“
    "book": "ä¹¦",
    "toy": "çŽ©å…·",
    "toys": "çŽ©å…·",
    "doll": "å¨ƒå¨ƒ",
    "teddy bear": "æ³°è¿ªç†Š",
    "stuffed animal": "æ¯›ç»’çŽ©å…·",
    "ball": "çƒ",
    "blocks": "ç§¯æœ¨",
    "puzzle": "æ‹¼å›¾",
    "stroller": "å©´å„¿è½¦",
    "pram": "å©´å„¿è½¦",
    "car seat": "å®‰å…¨åº§æ¤…",
    "crib": "å©´å„¿åºŠ",
    "cradle": "æ‘‡ç¯®",
    "diaper": "å°¿å¸ƒ",
    "nappy": "å°¿å¸ƒ",
    "baby carrier": "å©´å„¿èƒŒå¸¦",
    "baby monitor": "å©´å„¿ç›‘è§†å™¨",
    "phone": "æ‰‹æœº",
    "computer": "ç”µè„‘",
    "television": "ç”µè§†",
    "camera": "ç›¸æœº",
    "clock": "æ—¶é’Ÿ",
    "chair": "æ¤…å­",
    "table": "æ¡Œå­",
    "bed": "åºŠ",
    "door": "é—¨",
    "window": "çª—æˆ·",
    "bag": "åŒ…",
    "diaper bag": "å¦ˆå’ªåŒ…",
    "shoes": "éž‹å­",
    "clothes": "è¡£æœ",
    "baby clothes": "å©´å„¿æœè£…",
    "onesie": "è¿žä½“è¡£",
    "hat": "å¸½å­",
    "glasses": "çœ¼é•œ",
    
    # é¢œè‰²
    "red": "çº¢è‰²",
    "blue": "è“è‰²",
    "green": "ç»¿è‰²",
    "yellow": "é»„è‰²",
    "black": "é»‘è‰²",
    "white": "ç™½è‰²",
    "orange": "æ©™è‰²",
    "purple": "ç´«è‰²",
    "pink": "ç²‰è‰²",
    "brown": "æ£•è‰²",
    "gray": "ç°è‰²",
    
    # æ´»åŠ¨
    "running": "è·‘æ­¥",
    "walking": "èµ°è·¯",
    "jumping": "è·³è·ƒ",
    "swimming": "æ¸¸æ³³",
    "dancing": "è·³èˆž",
    "singing": "å”±æ­Œ",
    "playing": "çŽ©è€",
    "eating": "åƒ",
    "drinking": "å–",
    "feeding": "å–‚é£Ÿ",
    "breastfeeding": "æ¯ä¹³å–‚å…»",
    "bottle feeding": "å¥¶ç“¶å–‚å…»",
    "sleeping": "ç¡è§‰",
    "napping": "å°æ†©",
    "crawling": "çˆ¬è¡Œ",
    "sitting": "åç€",
    "standing": "ç«™ç«‹",
    "walking": "èµ°è·¯",
    "talking": "è¯´è¯",
    "babbling": "å’¿å‘€å­¦è¯­",
    "crying": "å“­æ³£",
    "laughing": "å¤§ç¬‘",
    "giggling": "å’¯å’¯ç¬‘",
    "hugging": "æ‹¥æŠ±",
    "kissing": "äº²å»",
    "cuddling": "æ‹¥æŠ±",
    "bathing": "æ´—æ¾¡",
    "changing": "æ¢å°¿å¸ƒ",
    "reading": "é˜…è¯»",
    "writing": "å†™ä½œ",
    "cooking": "çƒ¹é¥ª",
    "driving": "å¼€è½¦",
    "flying": "é£žè¡Œ",
    
    # å…¶ä»–å¸¸è§è¯æ±‡
    "indoor": "å®¤å†…",
    "outdoor": "æˆ·å¤–",
    "day": "ç™½å¤©",
    "night": "å¤œæ™š",
    "morning": "æ—©æ™¨",
    "evening": "å‚æ™š",
    "summer": "å¤å¤©",
    "winter": "å†¬å¤©",
    "spring": "æ˜¥å¤©",
    "autumn": "ç§‹å¤©",
    "hot": "çƒ­",
    "cold": "å†·",
    "warm": "æ¸©æš–",
    "cool": "å‡‰çˆ½",
    "big": "å¤§",
    "small": "å°",
    "tall": "é«˜",
    "short": "çŸ­",
    "long": "é•¿",
    "wide": "å®½",
    "narrow": "çª„",
    "thick": "åŽš",
    "thin": "è–„",
    "heavy": "é‡",
    "light": "è½»",
    "fast": "å¿«",
    "slow": "æ…¢",
    "new": "æ–°",
    "old": "æ—§",
    "young": "å¹´è½»",
    "beautiful": "ç¾Žä¸½",
    "ugly": "ä¸‘é™‹",
    "good": "å¥½",
    "bad": "å",
    "happy": "å¿«ä¹",
    "sad": "æ‚²ä¼¤",
    "angry": "æ„¤æ€’",
    "surprised": "æƒŠè®¶",
    "excited": "å…´å¥‹",
    "tired": "ç–²å€¦",
    "hungry": "é¥¥é¥¿",
    "thirsty": "å£æ¸´",
    
    # å¹¿å‘Šå’Œå“ç‰Œç›¸å…³
    "advertisement": "å¹¿å‘Š",
    "commercial": "å•†ä¸šå¹¿å‘Š",
    "brand": "å“ç‰Œ",
    "logo": "æ ‡å¿—",
    "product": "äº§å“",
    "package": "åŒ…è£…",
    "packaging": "åŒ…è£…",
    "label": "æ ‡ç­¾",
    "text": "æ–‡å­—",
    "banner": "æ¨ªå¹…",
    "poster": "æµ·æŠ¥",
    "sign": "æ ‡è¯†",
    "nutrition": "è¥å…»",
    "healthy": "å¥åº·",
    "organic": "æœ‰æœº",
    "natural": "å¤©ç„¶",
    "premium": "é«˜ç«¯",
    "quality": "è´¨é‡",
    
    # è§†é¢‘åˆ¶ä½œç›¸å…³
    "video": "è§†é¢‘",
    "vlog": "è§†é¢‘åšå®¢",
    "recording": "å½•åˆ¶",
    "filming": "æ‹æ‘„",
    "camera": "æ‘„åƒæœº",
    "microphone": "éº¦å…‹é£Ž",
    "lighting": "ç¯å…‰",
    "studio": "å·¥ä½œå®¤",
    "background": "èƒŒæ™¯",
    "scene": "åœºæ™¯",
    "shot": "é•œå¤´",
    "close up": "ç‰¹å†™",
    "wide shot": "è¿œæ™¯",
    
    # æƒ…æ„Ÿå’Œè¡¨æƒ…
    "emotion": "æƒ…æ„Ÿ",
    "expression": "è¡¨æƒ…",
    "joy": "å–œæ‚¦",
    "love": "çˆ±",
    "care": "å…³çˆ±",
    "gentle": "æ¸©æŸ”",
    "peaceful": "å¹³é™",
    "comfortable": "èˆ’é€‚",
    "safe": "å®‰å…¨",
    "trust": "ä¿¡ä»»"
}

def translate_label_to_chinese(english_label, use_deepseek=False):
    """å°†è‹±æ–‡æ ‡ç­¾ç¿»è¯‘æˆä¸­æ–‡"""
    # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
    label_lower = english_label.lower().strip()
    
    # ç›´æŽ¥åŒ¹é…æœ¬åœ°å­—å…¸
    if label_lower in LABEL_TRANSLATIONS:
        return LABEL_TRANSLATIONS[label_lower]
    
    # å°è¯•åŒ¹é…å¤åˆè¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”çš„è¯ï¼‰
    words = label_lower.split()
    if len(words) > 1:
        translated_words = []
        all_translated = True
        
        for word in words:
            if word in LABEL_TRANSLATIONS:
                translated_words.append(LABEL_TRANSLATIONS[word])
            else:
                # å¦‚æžœæœ‰è¯æ²¡æœ‰ç¿»è¯‘ï¼Œä¿ç•™åŽŸè¯ä½†æ ‡è®°ä¸ºæœªå®Œå…¨ç¿»è¯‘
                translated_words.append(word)
                all_translated = False
        
        # å¦‚æžœæ‰€æœ‰è¯éƒ½ç¿»è¯‘äº†ï¼Œè¿”å›žç¿»è¯‘ç»“æžœ
        if all_translated:
            return "".join(translated_words)  # ä¸­æ–‡ä¸éœ€è¦ç©ºæ ¼
        
        # å¦‚æžœéƒ¨åˆ†ç¿»è¯‘ä¸”å¯ç”¨DeepSeekï¼Œå°è¯•æ•´ä½“ç¿»è¯‘
        if use_deepseek and not all_translated:
            try:
                deepseek_translation = translate_with_deepseek(english_label)
                if deepseek_translation and deepseek_translation != english_label:
                    return deepseek_translation
            except Exception as e:
                pass
        
        # è¿”å›žéƒ¨åˆ†ç¿»è¯‘ç»“æžœ
        return "".join(translated_words)
    
    # å¦‚æžœæœ¬åœ°å­—å…¸æ²¡æœ‰æ‰¾åˆ°ä¸”å¯ç”¨äº†DeepSeekç¿»è¯‘ï¼Œå°è¯•ä½¿ç”¨DeepSeekç¿»è¯‘
    if use_deepseek:
        try:
            deepseek_translation = translate_with_deepseek(english_label)
            if deepseek_translation and deepseek_translation != english_label:
                return deepseek_translation
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºå¤ªå¤šè­¦å‘Š
            pass
    
    # å¦‚æžœéƒ½æ²¡æœ‰æ‰¾åˆ°ç¿»è¯‘ï¼Œè¿”å›žåŽŸæ–‡
    return english_label

def translate_with_deepseek(english_text):
    """ä½¿ç”¨DeepSeek APIç¿»è¯‘è‹±æ–‡æ ‡ç­¾åˆ°ä¸­æ–‡"""
    try:
        from streamlit_app.modules.ai_analyzers import DeepSeekAnalyzer
        
        # ä½¿ç”¨DeepSeekåˆ†æžå™¨
        analyzer = DeepSeekAnalyzer()
        
        if not analyzer.is_available():
            return None
        
        # ç¿»è¯‘è‹±æ–‡æ ‡ç­¾
        translation = analyzer.translate_text(english_text, "ä¸­æ–‡")
        return translation
        
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œè¿”å›žNoneè®©è°ƒç”¨è€…å¤„ç†
        return None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Google Cloud Video Intelligence API æµ‹è¯•",
    page_icon="ðŸ”¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'current_video_path' not in st.session_state:
    st.session_state.current_video_path = None
if 'current_video_id' not in st.session_state:
    st.session_state.current_video_id = None
if 'analysis_config' not in st.session_state:
    st.session_state.analysis_config = None

def check_credentials():
    """æ£€æŸ¥ Google Cloud å‡­æ®æ˜¯å¦å·²è®¾ç½®"""
    cred_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if cred_path and os.path.exists(cred_path):
        return True, cred_path
    return False, None

def upload_credentials():
    """ä¸Šä¼  Google Cloud æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶"""
    st.subheader("ðŸ“ ä¸Šä¼ æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ‚¨çš„ Google Cloud æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶ (JSONæ ¼å¼)",
        type=['json'],
        help="ä»Ž Google Cloud Console ä¸‹è½½çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶"
    )
    
    if uploaded_file is not None:
        try:
            # éªŒè¯JSONæ ¼å¼
            credentials_data = json.loads(uploaded_file.read())
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['type', 'project_id', 'private_key_id', 'private_key', 'client_email']
            missing_fields = [field for field in required_fields if field not in credentials_data]
            
            if missing_fields:
                st.error(f"å¯†é’¥æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}")
                return False
            
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = Path("temp")
            temp_dir.mkdir(exist_ok=True)
            
            cred_file_path = temp_dir / "google_credentials.json"
            with open(cred_file_path, 'w', encoding='utf-8') as f:
                json.dump(credentials_data, f, indent=2)
            
            # è®¾ç½®çŽ¯å¢ƒå˜é‡
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(cred_file_path)
            
            st.success(f"âœ… å‡­æ®æ–‡ä»¶å·²ä¸Šä¼ å¹¶è®¾ç½®ï¼é¡¹ç›®ID: {credentials_data.get('project_id', 'Unknown')}")
            st.info(f"å‡­æ®æ–‡ä»¶è·¯å¾„: {cred_file_path}")
            
            return True
            
        except json.JSONDecodeError:
            st.error("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æœ‰æ•ˆçš„JSONæ–‡ä»¶")
            return False
        except Exception as e:
            st.error(f"âŒ å¤„ç†å‡­æ®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False
    
    return False

def test_video_intelligence(use_deepseek_translation=False):
    """æµ‹è¯• Video Intelligence API"""
    try:
        from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
        
        st.subheader("ðŸŽ¬ è§†é¢‘åˆ†æžæµ‹è¯•")
        
        # åˆ›å»ºGoogle Cloudåˆ†æžå™¨
        analyzer = GoogleVideoAnalyzer()
        
        # æ£€æŸ¥å‡­æ®
        has_credentials, cred_path = analyzer.check_credentials()
        if not has_credentials:
            st.error("âŒ Google Cloudå‡­æ®æœªè®¾ç½®æˆ–æ— æ•ˆ")
            return
        
        st.success("âœ… Google Cloud Video Intelligence åˆ†æžå™¨å‡†å¤‡å°±ç»ªï¼")
        
        # æ˜¾ç¤ºå­˜å‚¨æ¡¶ä¿¡æ¯
        st.info("ðŸ“¦ **Cloud Storage**: ç³»ç»Ÿå°†ä½¿ç”¨æ‚¨çš„ `ai-video-master` å­˜å‚¨æ¡¶ï¼ˆasia-east2 é¦™æ¸¯ï¼‰è¿›è¡Œæ‰¹é‡å¤„ç†")
        
        # æ–‡ä»¶ä¸Šä¼ 
        st.markdown("### ðŸ“ é€‰æ‹©è§†é¢‘æ–‡ä»¶")
        
        # æ·»åŠ å¿«é€Ÿæµ‹è¯•é€‰é¡¹
        test_option = st.radio(
            "é€‰æ‹©æµ‹è¯•æ–¹å¼ï¼š",
            ["ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶", "ä½¿ç”¨ Google Cloud ç¤ºä¾‹è§†é¢‘ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰"],
            help="ç¤ºä¾‹è§†é¢‘å¯ä»¥å¿«é€ŸéªŒè¯APIæ˜¯å¦æ­£å¸¸å·¥ä½œ"
        )
        
        uploaded_video = None
        use_sample_video = False
        
        if test_option == "ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶":
            uploaded_video = st.file_uploader(
                "é€‰æ‹©è¦åˆ†æžçš„è§†é¢‘æ–‡ä»¶",
                type=['mp4', 'avi', 'mov', 'mkv', 'webm'],
                help="æ”¯æŒå¸¸è§çš„è§†é¢‘æ ¼å¼ï¼Œå»ºè®®æ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MBä»¥èŽ·å¾—æ›´å¿«çš„å¤„ç†é€Ÿåº¦"
            )
        else:
            use_sample_video = True
            st.info("ðŸš€ å°†ä½¿ç”¨ Google Cloud å…¬å¼€ç¤ºä¾‹è§†é¢‘è¿›è¡Œå¿«é€Ÿæµ‹è¯•")
            st.markdown("ç¤ºä¾‹è§†é¢‘: `gs://cloud-samples-data/video/cat.mp4`")
        
        if uploaded_video is not None or use_sample_video:
            if uploaded_video is not None:
                # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                st.write(f"**æ–‡ä»¶å:** {uploaded_video.name}")
                st.write(f"**æ–‡ä»¶å¤§å°:** {uploaded_video.size / (1024*1024):.2f} MB")
            else:
                st.write("**ä½¿ç”¨ç¤ºä¾‹è§†é¢‘:** cat.mp4")
                st.write("**æ–‡ä»¶å¤§å°:** ~1.5 MB")
            
            # é€‰æ‹©åˆ†æžåŠŸèƒ½
            st.subheader("ðŸ”§ é€‰æ‹©åˆ†æžåŠŸèƒ½")
            
            col1, col2 = st.columns(2)
            
            with col1:
                shot_detection = st.checkbox("é•œå¤´åˆ‡åˆ†æ£€æµ‹", value=True, help="æ£€æµ‹è§†é¢‘ä¸­çš„é•œå¤´å˜åŒ–")
                label_detection = st.checkbox("æ ‡ç­¾æ£€æµ‹", value=True, help="è¯†åˆ«è§†é¢‘ä¸­çš„ç‰©ä½“ã€åœºæ™¯ç­‰")
                
            with col2:
                object_tracking = st.checkbox("ç‰©ä½“è·Ÿè¸ª", help="è·Ÿè¸ªè§†é¢‘ä¸­ç§»åŠ¨çš„å¯¹è±¡")
                # æ·»åŠ è‡ªåŠ¨æ¸…ç†é€‰é¡¹
                auto_cleanup = st.checkbox(
                    "åˆ†æžå®ŒæˆåŽåˆ é™¤äº‘ç«¯è§†é¢‘", 
                    value=True, 
                    help="è‡ªåŠ¨åˆ é™¤ä¸Šä¼ åˆ°Cloud Storageçš„ä¸´æ—¶è§†é¢‘æ–‡ä»¶ï¼ŒèŠ‚çœå­˜å‚¨æˆæœ¬"
                )
            
            # å¼€å§‹åˆ†æžæŒ‰é’®
            if st.button("ðŸš€ å¼€å§‹åˆ†æž", type="primary"):
                if not any([shot_detection, label_detection, object_tracking]):
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æžåŠŸèƒ½ï¼")
                    return
                
                try:
                    # å‡†å¤‡åˆ†æžå‚æ•°
                    features = []
                    if shot_detection:
                        features.append("shot_detection")
                    if label_detection:
                        features.append("label_detection")
                    if object_tracking:
                        features.append("object_tracking")
                    
                    # è®¾ç½®è¿›åº¦å›žè°ƒ
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def progress_callback(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    # æ‰§è¡Œåˆ†æž
                    if use_sample_video:
                        # ä½¿ç”¨ç¤ºä¾‹è§†é¢‘URI
                        video_uri = "gs://cloud-samples-data/video/cat.mp4"
                        st.info("ðŸ“¡ ä½¿ç”¨äº‘ç«¯ç¤ºä¾‹è§†é¢‘è¿›è¡Œåˆ†æž")
                        
                        analysis_result = analyzer.analyze_video(
                            video_uri=video_uri,
                            features=features,
                            progress_callback=progress_callback,
                            auto_cleanup_storage=False  # ç¤ºä¾‹è§†é¢‘ä¸éœ€è¦æ¸…ç†
                        )
                        
                        current_video_path = None  # ç¤ºä¾‹è§†é¢‘æ— æ³•ç›´æŽ¥åˆ‡åˆ†
                        current_video_id = "google_sample_cat"
                    else:
                        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶
                        from pathlib import Path
                        temp_dir = Path("data/temp/google_cloud")
                        temp_dir.mkdir(parents=True, exist_ok=True)
                        
                        video_filename = uploaded_video.name
                        video_path = temp_dir / video_filename
                        
                        with open(video_path, "wb") as f:
                            f.write(uploaded_video.read())
                        
                        current_video_path = str(video_path)
                        current_video_id = os.path.splitext(video_filename)[0]
                        
                        st.info(f"ðŸ“Š æ­£åœ¨åˆ†æž {len(features)} ä¸ªåŠŸèƒ½ï¼Œè§†é¢‘å¤§å°: {uploaded_video.size/(1024*1024):.1f}MB")
                        
                        analysis_result = analyzer.analyze_video(
                            video_path=current_video_path,
                            features=features,
                            progress_callback=progress_callback,
                            auto_cleanup_storage=auto_cleanup  # ä½¿ç”¨ç”¨æˆ·é€‰æ‹©çš„æ¸…ç†é€‰é¡¹
                        )
                    
                    if analysis_result.get("success"):
                        result = analysis_result["result"]
                        
                        # æ˜¾ç¤ºæ¸…ç†çŠ¶æ€
                        if analysis_result.get("cleanup_performed"):
                            st.success("âœ… åˆ†æžå®Œæˆï¼äº‘ç«¯ä¸´æ—¶è§†é¢‘æ–‡ä»¶å·²è‡ªåŠ¨åˆ é™¤")
                        elif auto_cleanup and not analysis_result.get("cleanup_performed"):
                            st.info("â„¹ï¸ åˆ†æžå®Œæˆï¼æœªä½¿ç”¨Cloud Storageï¼ˆå°æ–‡ä»¶ç›´æŽ¥ä¼ è¾“ï¼‰")
                        else:
                            st.success("âœ… åˆ†æžå®Œæˆï¼")
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.analysis_result = result
                        st.session_state.current_video_path = current_video_path
                        st.session_state.current_video_id = current_video_id
                        st.session_state.analysis_config = {
                            'shot_detection': shot_detection,
                            'label_detection': label_detection,
                            'object_tracking': object_tracking,
                            'use_deepseek_translation': use_deepseek_translation
                        }
                        
                        # æ˜¾ç¤ºç»“æžœ
                        display_results(result, shot_detection, label_detection, object_tracking, use_deepseek_translation, current_video_path, current_video_id)
                    else:
                        st.error(f"âŒ åˆ†æžå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
                except Exception as e:
                    st.error(f"âŒ è§†é¢‘åˆ†æžå¤±è´¥: {str(e)}")
                    st.info("è¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿žæŽ¥æ˜¯å¦æ­£å¸¸\n2. Google Cloud å‡­æ®æ˜¯å¦æœ‰æ•ˆ\n3. æ˜¯å¦å·²å¯ç”¨ Video Intelligence API\n4. è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸå")
                
                finally:
                    # æ³¨æ„ï¼šä¸è¦ç«‹å³åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œå› ä¸ºåŽç»­çš„åˆ‡åˆ†åŠŸèƒ½éœ€è¦ä½¿ç”¨
                    # ä¸´æ—¶æ–‡ä»¶å°†åœ¨ç”¨æˆ·ç¦»å¼€é¡µé¢æˆ–é‡æ–°ä¸Šä¼ æ—¶è‡ªåŠ¨æ¸…ç†
                    pass
        
    except ImportError as e:
        st.error("âŒ å¯¼å…¥Google Cloud Video Intelligenceæ¨¡å—æ—¶å‡ºé”™")
        st.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        
        # è°ƒè¯•ä¿¡æ¯
        import sys
        st.info("è°ƒè¯•ä¿¡æ¯:")
        st.write(f"- Pythonè·¯å¾„: {sys.executable}")
        st.write(f"- Pythonç‰ˆæœ¬: {sys.version}")
        st.write(f"- GOOGLE_APPLICATION_CREDENTIALS: {os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', 'æœªè®¾ç½®')}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åº“æœªå®‰è£…
        try:
            import google.cloud.videointelligence_v1
            st.success("âœ… google-cloud-videointelligence åº“å·²å®‰è£…")
            st.error("âŒ ä½†æ˜¯GoogleVideoAnalyzeræ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ¨¡å—å†…éƒ¨é”™è¯¯")
        except ImportError:
            st.error("âŒ æœªå®‰è£… google-cloud-videointelligence åº“")
            st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n```bash\npip install google-cloud-videointelligence\n```")

def get_time_seconds(time_offset):
    """å®‰å…¨åœ°èŽ·å–æ—¶é—´åç§»çš„ç§’æ•°"""
    try:
        if hasattr(time_offset, 'total_seconds'):
            return time_offset.total_seconds()
        elif hasattr(time_offset, 'seconds'):
            # å¤„ç† protobuf Duration å¯¹è±¡
            return time_offset.seconds + time_offset.nanos / 1e9
        else:
            # å¦‚æžœæ˜¯æ•°å­—ï¼Œç›´æŽ¥è¿”å›ž
            return float(time_offset)
    except Exception as e:
        st.warning(f"æ—¶é—´è§£æžé”™è¯¯: {e}")
        return 0.0

def analyze_video_segments(segment_files, video_id):
    """
    å¯¹è§†é¢‘åˆ‡ç‰‡è¿›è¡ŒäºŒæ¬¡åˆ†æžï¼ˆä»…æ ‡ç­¾æ£€æµ‹ï¼‰
    
    Args:
        segment_files: åˆ‡ç‰‡æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        video_id: è§†é¢‘ID
    """
    try:
        from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
        
        # åˆ›å»ºåˆ†æžå™¨
        analyzer = GoogleVideoAnalyzer()
        
        # æ£€æŸ¥å‡­æ®æ˜¯å¦æœ‰æ•ˆ
        has_credentials, cred_path = analyzer.check_credentials()
        if not has_credentials:
            st.error("âŒ Google Cloud å‡­æ®æœªè®¾ç½®æˆ–æ— æ•ˆ")
            return
        
        # ä»…ä½¿ç”¨æ ‡ç­¾æ£€æµ‹
        features = ["label_detection"]
        
        st.info(f"ðŸš€ å¼€å§‹åˆ†æž {len(segment_files)} ä¸ªåˆ‡ç‰‡ï¼ŒåŠŸèƒ½: æ ‡ç­¾æ£€æµ‹")
        
        # åˆ›å»ºè¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        results_container = st.container()
        
        segment_results = []
        
        for i, segment_file in enumerate(segment_files):
            try:
                segment_name = segment_file.name
                status_text.text(f"æ­£åœ¨åˆ†æžåˆ‡ç‰‡ {i+1}/{len(segment_files)}: {segment_name}")
                
                # åˆ†æžå•ä¸ªåˆ‡ç‰‡
                def progress_callback(progress, message):
                    overall_progress = (i + progress) / len(segment_files)
                    progress_bar.progress(overall_progress)
                    status_text.text(f"åˆ‡ç‰‡ {i+1}/{len(segment_files)}: {message}")
                
                result = analyzer.analyze_video(
                    video_path=str(segment_file),
                    features=features,
                    progress_callback=progress_callback
                )
                
                if result.get("success"):
                    annotation = result["result"].annotation_results[0]
                    
                    # æå–åˆ†æžç»“æžœï¼ˆä»…æ ‡ç­¾ï¼‰
                    segment_analysis = {
                        'file_name': segment_name,
                        'file_path': str(segment_file),
                        'file_size': segment_file.stat().st_size / (1024*1024),  # MB
                        'labels': []
                    }
                    
                    # æå–æ ‡ç­¾
                    if hasattr(annotation, 'segment_label_annotations'):
                        for label in annotation.segment_label_annotations[:5]:  # å‰5ä¸ªæ ‡ç­¾
                            label_name = label.entity.description
                            label_name_cn = translate_label_to_chinese(label_name, use_deepseek=False)
                            confidence = 0.0
                            
                            if label.segments:
                                confidence = label.segments[0].confidence
                            
                            segment_analysis['labels'].append({
                                'name': label_name_cn,
                                'confidence': confidence
                            })
                    
                    segment_results.append(segment_analysis)
                    
                else:
                    st.warning(f"âš ï¸ åˆ‡ç‰‡ {segment_name} åˆ†æžå¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                
                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(segment_files)
                progress_bar.progress(progress)
                
            except Exception as e:
                st.error(f"âŒ åˆ†æžåˆ‡ç‰‡ {segment_file.name} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        # æ˜¾ç¤ºåˆ†æžç»“æžœ
        progress_bar.progress(1.0)
        status_text.text("âœ… åˆ‡ç‰‡åˆ†æžå®Œæˆï¼")
        
        if segment_results:
            display_segment_analysis_results(segment_results, video_id)
        else:
            st.error("âŒ æ²¡æœ‰æˆåŠŸåˆ†æžçš„åˆ‡ç‰‡")
            
    except Exception as e:
        st.error(f"âŒ åˆ‡ç‰‡åˆ†æžè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        st.code(traceback.format_exc(), language="python")

def display_segment_analysis_results(segment_results, video_id):
    """æ˜¾ç¤ºåˆ‡ç‰‡åˆ†æžç»“æžœï¼ˆç®€åŒ–ç‰ˆï¼‰"""
    st.markdown("### ðŸ“Š åˆ‡ç‰‡åˆ†æžç»“æžœ")
    
    # ç»Ÿè®¡ä¿¡æ¯
    total_segments = len(segment_results)
    total_size = sum(s['file_size'] for s in segment_results)
    total_labels = sum(len(s['labels']) for s in segment_results)
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("åˆ†æžåˆ‡ç‰‡æ•°", total_segments)
    with col2:
        st.metric("æ€»å¤§å°", f"{total_size:.1f} MB")
    with col3:
        st.metric("æ£€æµ‹æ ‡ç­¾æ•°", total_labels)
    with col4:
        avg_labels = total_labels / total_segments if total_segments > 0 else 0
        st.metric("å¹³å‡æ ‡ç­¾æ•°", f"{avg_labels:.1f}")
    
    # è¯¦ç»†ç»“æžœè¡¨æ ¼
    st.markdown("### ðŸ“‹ è¯¦ç»†åˆ†æžç»“æžœ")
    
    for i, result in enumerate(segment_results):
        with st.expander(f"ðŸŽ¬ {result['file_name']} ({result['file_size']:.1f} MB)", expanded=False):
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # æ ‡ç­¾ä¿¡æ¯
                if result['labels']:
                    st.write("**ðŸ·ï¸ æ£€æµ‹åˆ°çš„æ ‡ç­¾:**")
                    for label in result['labels']:
                        confidence_color = "ðŸŸ¢" if label['confidence'] > 0.7 else "ðŸŸ¡" if label['confidence'] > 0.4 else "ðŸ”´"
                        st.write(f"  {confidence_color} {label['name']} (ç½®ä¿¡åº¦: {label['confidence']:.2f})")
                else:
                    st.write("*æœªæ£€æµ‹åˆ°æ ‡ç­¾*")
            
            with col2:
                st.write(f"**æ–‡ä»¶è·¯å¾„:**")
                st.code(result['file_path'], language="text")
                
                if st.button(f"ðŸ“‚ æ‰“å¼€æ–‡ä»¶", key=f"open_segment_{i}"):
                    import subprocess
                    subprocess.run(["open", "-R", result['file_path']], check=False)
    
    # ä¿å­˜åˆ†æžç»“æžœ
    if st.button("ðŸ’¾ ä¿å­˜åˆ†æžç»“æžœ", key="save_segment_analysis"):
        save_segment_analysis_results(segment_results, video_id)

def save_segment_analysis_results(segment_results, video_id):
    """ä¿å­˜åˆ‡ç‰‡åˆ†æžç»“æžœåˆ°JSONæ–‡ä»¶"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        root_dir = Path(__file__).parent.parent.parent
        results_dir = root_dir / "data" / "output" / "google_video" / str(video_id)
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # å‡†å¤‡ç»“æžœæ•°æ®
        analysis_data = {
            'video_id': video_id,
            'analysis_time': datetime.now().isoformat(),
            'total_segments': len(segment_results),
            'segments': segment_results
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        result_file = results_dir / f"segment_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        st.success(f"âœ… åˆ†æžç»“æžœå·²ä¿å­˜åˆ°: {result_file}")
        
        if st.button("ðŸ“‚ æ‰“å¼€ç»“æžœæ–‡ä»¶å¤¹"):
            import subprocess
            try:
                    subprocess.run(["open", str(results_dir)], check=False)
                    st.success("âœ… å·²æ‰“å¼€ç»“æžœæ–‡ä»¶å¤¹")
            except Exception as e:
                    st.error(f"âŒ æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥: {str(e)}")
                    st.info(f"ðŸ“ æ–‡ä»¶å¤¹è·¯å¾„: {results_dir}")
        
    except Exception as e:
        st.error(f"âŒ ä¿å­˜åˆ†æžç»“æžœæ—¶å‡ºé”™: {str(e)}")

def create_video_segments(video_path, segments_data, video_id, is_clustered=False):
    """
    æ ¹æ®åˆ†æžç»“æžœåˆ›å»ºè§†é¢‘ç‰‡æ®µ
    
    Args:
        video_path: åŽŸå§‹è§†é¢‘è·¯å¾„
        segments_data: ç‰‡æ®µæ•°æ®åˆ—è¡¨
        video_id: è§†é¢‘ID
        is_clustered: æ˜¯å¦ä¸ºèšç±»åŽçš„åœºæ™¯åˆ‡åˆ†
    
    Returns:
        æˆåŠŸåˆ›å»ºçš„ç‰‡æ®µåˆ—è¡¨
    """
    try:
        # è°ƒè¯•ä¿¡æ¯
        st.info(f"ðŸ” è°ƒè¯•ä¿¡æ¯:")
        st.write(f"- è§†é¢‘è·¯å¾„: {video_path}")
        st.write(f"- è§†é¢‘ID: {video_id}")
        st.write(f"- ç‰‡æ®µæ•°é‡: {len(segments_data)}")
        st.write(f"- èšç±»åˆ‡åˆ†: {'æ˜¯' if is_clustered else 'å¦'}")
        st.write(f"- è§†é¢‘æ–‡ä»¶å­˜åœ¨: {os.path.exists(video_path) if video_path else 'N/A'}")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        from pathlib import Path
        root_dir = Path(__file__).parent.parent.parent
        
        if is_clustered:
            # èšç±»åŽçš„åœºæ™¯åˆ‡åˆ†ä¿å­˜åˆ° data/results/{video_id}_merge/
            base_output_dir = root_dir / "data" / "results"
            output_dir = base_output_dir / f"{video_id}_merge"
            st.info("ðŸ§  èšç±»åœºæ™¯åˆ‡åˆ†ï¼šä½¿ç”¨ä¸“ç”¨ä¿å­˜è·¯å¾„")
        else:
            # åŽŸå§‹é•œå¤´åˆ‡åˆ†ä¿å­˜åˆ°åŽŸæ¥çš„è·¯å¾„
            base_output_dir = root_dir / "data" / "output" / "google_video"
        output_dir = base_output_dir / str(video_id)
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        st.write(f"- è¾“å‡ºç›®å½•: {output_dir}")
        
        if not video_path:
            st.error("âŒ è§†é¢‘è·¯å¾„ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ‡åˆ†")
            return []
        
        if not os.path.exists(video_path):
            st.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return []
        
        # å¯¼å…¥è§†é¢‘å¤„ç†å™¨
        import sys
        sys.path.append(str(root_dir))
        from src.core.utils.video_processor import VideoProcessor
        
        processor = VideoProcessor()
        created_segments = []
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        cut_type = "èšç±»åœºæ™¯" if is_clustered else "è§†é¢‘ç‰‡æ®µ"
        st.info(f"ðŸŽ¬ æ­£åœ¨åˆ‡åˆ†{cut_type}...")
        progress_bar = st.progress(0)
        
        for i, segment in enumerate(segments_data):
            try:
                start_time = segment['start_time']
                end_time = segment['end_time']
                segment_type = segment['type']
                confidence = segment.get('confidence', 1.0)
                
                # ç¡®ä¿æ—¶é—´æœ‰æ•ˆ
                if start_time >= end_time or end_time - start_time < 0.5:
                    st.warning(f"è·³è¿‡æ— æ•ˆç‰‡æ®µ {i+1}: æ—¶é—´èŒƒå›´ {start_time:.2f}s - {end_time:.2f}s")
                    continue
                
                # ä½¿ç”¨VideoProcessoræå–ç‰‡æ®µ
                extracted_path = processor.extract_segment(
                    video_path=video_path,
                    start_time=start_time,
                    end_time=end_time,
                    segment_index=i,
                    semantic_type=segment_type,
                    video_id=video_id,
                    output_dir=str(output_dir)
                )
                
                if extracted_path and os.path.exists(extracted_path):
                    created_segments.append({
                        'index': i + 1,
                        'type': segment_type,
                        'start_time': start_time,
                        'end_time': end_time,
                        'duration': end_time - start_time,
                        'confidence': confidence,
                        'file_path': extracted_path,
                        'file_size': os.path.getsize(extracted_path) / (1024*1024),  # MB
                        'is_clustered': is_clustered
                    })
                    
                    st.success(f"âœ… ç‰‡æ®µ {i+1}: {segment_type} ({start_time:.1f}s-{end_time:.1f}s)")
                else:
                    st.error(f"âŒ ç‰‡æ®µ {i+1} åˆ›å»ºå¤±è´¥")
                
                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(segments_data)
                progress_bar.progress(progress)
                    
            except Exception as e:
                st.error(f"âŒ å¤„ç†ç‰‡æ®µ {i+1} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        progress_bar.progress(1.0)
        save_location = f"data/results/{video_id}_merge/" if is_clustered else f"data/output/google_video/{video_id}/"
        st.success(f"âœ… {cut_type}åˆ‡åˆ†å®Œæˆï¼šæˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        st.info(f"ðŸ“ ç‰‡æ®µå·²ä¿å­˜åˆ°: {save_location}")
        
        if is_clustered:
            st.success("ðŸ§  èšç±»åœºæ™¯åˆ‡ç‰‡å·²ä¿å­˜åˆ°ä¸“ç”¨æ–‡ä»¶å¤¹ï¼Œä¾¿äºŽåŒºåˆ†å’Œç®¡ç†")
        
        return created_segments
        
    except Exception as e:
        st.error(f"åˆ›å»ºè§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
        return []

def display_results(result, shot_detection, label_detection, object_tracking, use_deepseek_translation=False, video_path=None, video_id=None):
    """æ˜¾ç¤ºåˆ†æžç»“æžœ"""
    st.subheader("ðŸ“Š åˆ†æžç»“æžœ")
    
    if not result.annotation_results:
        st.warning("æ²¡æœ‰èŽ·å¾—åˆ†æžç»“æžœ")
        return
    
    annotation = result.annotation_results[0]
    
    # åˆ›å»ºGoogle Videoåˆ†æžå™¨å®žä¾‹ç”¨äºŽæ•°æ®æå–
    from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
    google_analyzer = GoogleVideoAnalyzer()
    
    # é•œå¤´åˆ‡åˆ†ç»“æžœ
    if shot_detection and annotation.shot_annotations:
        st.subheader("ðŸŽ¬ é•œå¤´åˆ‡åˆ†ç»“æžœ")
        
        # æ˜¾ç¤ºåŽŸå§‹é•œå¤´ç»Ÿè®¡
        total_shots = len(annotation.shot_annotations)
        durations = []
        shot_times = []
        
        for shot in annotation.shot_annotations:
            start_time = get_time_seconds(shot.start_time_offset)
            end_time = get_time_seconds(shot.end_time_offset)
            durations.append(end_time - start_time)
            shot_times.append((start_time, end_time))
        
        avg_duration = sum(durations) / len(durations) if durations else 0
        min_duration = min(durations) if durations else 0
        max_duration = max(durations) if durations else 0
        
        # ä½¿ç”¨åˆ†æžå™¨æå–é•œå¤´ä¿¡æ¯
        mock_result = {"success": True, "result": result}
        shots = google_analyzer.extract_shots(mock_result)
        
        # éªŒè¯é•œå¤´è¿žè´¯æ€§
        continuity = google_analyzer.validate_shot_continuity(shots)
        
        # ä½¿ç”¨åˆ†æžå™¨çš„è¿žè´¯æ€§éªŒè¯ç»“æžœ
        gaps = continuity["gaps"]
        overlaps = continuity["overlaps"]
        total_video_duration = continuity["total_duration"]
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("é•œå¤´æ€»æ•°", total_shots)
        with col2:
            st.metric("å¹³å‡æ—¶é•¿", f"{avg_duration:.1f}s")
        with col3:
            st.metric("æœ€çŸ­æ—¶é•¿", f"{min_duration:.1f}s")
        with col4:
            st.metric("æœ€é•¿æ—¶é•¿", f"{max_duration:.1f}s")
        
        # æ˜¾ç¤ºè¿žè´¯æ€§æ£€æŸ¥ç»“æžœ
        st.markdown("### ðŸ” é•œå¤´è¿žè´¯æ€§æ£€æŸ¥")
        
        if not gaps and not overlaps:
            st.success("âœ… æ‰€æœ‰é•œå¤´æ—¶é—´å®Œå…¨è¿žè´¯ï¼Œæ— ç©ºéš™æˆ–é‡å ")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("è§†é¢‘æ€»æ—¶é•¿", f"{total_video_duration:.2f}s")
            with col2:
                total_cuts_duration = sum(durations)
                st.metric("é•œå¤´æ€»æ—¶é•¿", f"{total_cuts_duration:.2f}s")
                if abs(total_video_duration - total_cuts_duration) < 0.1:
                    st.success("âœ… æ—¶é•¿åŒ¹é…å®Œç¾Ž")
        else:
            if gaps:
                st.warning("âš ï¸ å‘çŽ°æ—¶é—´ç©ºéš™:")
                for gap in gaps:
                    st.write(f"  - {gap}")
            
            if overlaps:
                st.error("âŒ å‘çŽ°æ—¶é—´é‡å :")
                for overlap in overlaps:
                    st.write(f"  - {overlap}")
            
            st.info("ðŸ’¡ æ³¨æ„ï¼šå°‘é‡è¯¯å·®ï¼ˆ<0.1ç§’ï¼‰æ˜¯æ­£å¸¸çš„ï¼Œå¯èƒ½ç”±äºŽæ—¶é—´ç²¾åº¦é€ æˆ")
        
        # æ˜¾ç¤ºåŽŸå§‹é•œå¤´è¡¨æ ¼
        st.markdown("### ðŸ“Š é•œå¤´åˆ‡åˆ†ç»“æžœè¯¦æƒ…")
        
        shots_data = []
        segments_for_cutting = []
        
        for shot in shots:
            shots_data.append({
                "é•œå¤´": f"é•œå¤´ {shot['index']}",
                "å¼€å§‹æ—¶é—´ (ç§’)": f"{shot['start_time']:.2f}",
                "ç»“æŸæ—¶é—´ (ç§’)": f"{shot['end_time']:.2f}",
                "æŒç»­æ—¶é—´ (ç§’)": f"{shot['duration']:.2f}"
            })
            
            segments_for_cutting.append({
                'start_time': shot['start_time'],
                'end_time': shot['end_time'],
                'type': shot['type'],
                'confidence': shot['confidence']
            })
        
        if shots_data:
            import pandas as pd
            df = pd.DataFrame(shots_data)
            st.dataframe(
                df, 
                use_container_width=True,
                hide_index=True,
                column_config={
                    "é•œå¤´": st.column_config.TextColumn("é•œå¤´", width="small"),
                    "å¼€å§‹æ—¶é—´ (ç§’)": st.column_config.NumberColumn("å¼€å§‹æ—¶é—´ (ç§’)", width="medium"),
                    "ç»“æŸæ—¶é—´ (ç§’)": st.column_config.NumberColumn("ç»“æŸæ—¶é—´ (ç§’)", width="medium"),
                    "æŒç»­æ—¶é—´ (ç§’)": st.column_config.NumberColumn("æŒç»­æ—¶é—´ (ç§’)", width="medium")
                }
            )
    
    # æ ‡ç­¾æ£€æµ‹ç»“æžœ
    if label_detection and annotation.segment_label_annotations:
        st.subheader("ðŸ·ï¸ æ ‡ç­¾æ£€æµ‹ç»“æžœ")
        
        try:
            # ä½¿ç”¨åˆ†æžå™¨æå–æ ‡ç­¾ä¿¡æ¯
            mock_result = {"success": True, "result": result}
            labels = google_analyzer.extract_labels(mock_result)
            
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            label_data = []
            
            # ç¿»è¯‘çŠ¶æ€ç»Ÿè®¡
            local_translated = 0
            deepseek_translated = 0
            
            for label in labels[:20]:  # æ˜¾ç¤ºå‰20ä¸ªæ ‡ç­¾
                label_name = label['label']
                
                # å…ˆå°è¯•æœ¬åœ°ç¿»è¯‘
                local_translation = translate_label_to_chinese(label_name, use_deepseek=False)
                if local_translation != label_name:
                    label_name_cn = local_translation
                    local_translated += 1
                elif use_deepseek_translation:
                    # ä½¿ç”¨DeepSeekç¿»è¯‘
                    deepseek_translation = translate_with_deepseek(label_name)
                    if deepseek_translation and deepseek_translation != label_name:
                        label_name_cn = deepseek_translation
                        deepseek_translated += 1
                    else:
                        label_name_cn = label_name
                else:
                    label_name_cn = label_name
                
                # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                start_time = label['start_time']
                end_time = label['end_time']
                confidence = label['confidence']
                
                start_min = int(start_time // 60)
                start_sec = int(start_time % 60)
                end_min = int(end_time // 60)
                end_sec = int(end_time % 60)
                
                time_range = f"{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}"
                
                label_data.append({
                    "æ ‡ç­¾": label_name_cn,
                    "æ—¶é—´æ®µ": time_range,
                    "ç½®ä¿¡åº¦": f"{confidence:.2f}"
                })
            
            if label_data:
                # æ˜¾ç¤ºä¸ºè¡¨æ ¼
                import pandas as pd
                df = pd.DataFrame(label_data)
                
                # è®¾ç½®è¡¨æ ¼æ ·å¼
                st.dataframe(
                    df, 
                    use_container_width=True, 
                    hide_index=True,
                    column_config={
                        "æ ‡ç­¾": st.column_config.TextColumn(
                            "æ ‡ç­¾",
                            help="æ£€æµ‹åˆ°çš„ç‰©ä½“æˆ–åœºæ™¯æ ‡ç­¾",
                            width="medium"
                        ),
                        "æ—¶é—´æ®µ": st.column_config.TextColumn(
                            "æ—¶é—´æ®µ",
                            help="æ ‡ç­¾å‡ºçŽ°çš„æ—¶é—´èŒƒå›´",
                            width="medium"
                        ),
                        "ç½®ä¿¡åº¦": st.column_config.NumberColumn(
                            "ç½®ä¿¡åº¦",
                            help="AIè¯†åˆ«çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰",
                            width="small",
                            format="%.2f"
                        )
                    }
                )
                
                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ£€æµ‹åˆ°çš„æ ‡ç­¾ç±»åž‹", len(annotation.segment_label_annotations))
                with col2:
                    st.metric("æ ‡ç­¾å®žä¾‹æ€»æ•°", len(label_data))
                with col3:
                    avg_confidence = sum(float(item["ç½®ä¿¡åº¦"]) for item in label_data) / len(label_data)
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
                with col4:
                    if use_deepseek_translation:
                        st.metric("AIç¿»è¯‘æ ‡ç­¾", deepseek_translated)
                    else:
                        st.metric("æœ¬åœ°ç¿»è¯‘", local_translated)
                
                # ç¿»è¯‘è¯¦æƒ…
                if use_deepseek_translation and (local_translated > 0 or deepseek_translated > 0):
                    st.info(f"ðŸ“Š ç¿»è¯‘ç»Ÿè®¡: æœ¬åœ°å­—å…¸ç¿»è¯‘ {local_translated} ä¸ªï¼ŒDeepSeek AIç¿»è¯‘ {deepseek_translated} ä¸ª")
                
                # æ·»åŠ æ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†åŠŸèƒ½
                if video_path and video_id:
                    st.markdown("### ðŸ·ï¸ æ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†")
                    
                    # å¯è°ƒèŠ‚çš„å‚æ•°è®¾ç½®
                    with st.expander("âš™ï¸ æ ‡ç­¾ç‰‡æ®µå‚æ•°è®¾ç½®", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            min_duration = st.slider(
                                "æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰",
                                min_value=0.5,
                                max_value=5.0,
                                value=1.0,
                                step=0.5,
                                help="çŸ­äºŽæ­¤æ—¶é•¿çš„æ ‡ç­¾ç‰‡æ®µå°†è¢«è¿‡æ»¤"
                            )
                        with col2:
                            min_confidence = st.slider(
                                "æœ€å°ç½®ä¿¡åº¦",
                                min_value=0.1,
                                max_value=1.0,
                                value=0.5,
                                step=0.1,
                                help="ä½ŽäºŽæ­¤ç½®ä¿¡åº¦çš„æ ‡ç­¾ç‰‡æ®µå°†è¢«è¿‡æ»¤"
                            )
                        with col3:
                            max_labels = st.slider(
                                "æœ€å¤§æ ‡ç­¾æ•°é‡",
                                min_value=5,
                                max_value=50,
                                value=10,
                                step=5,
                                help="å¤„ç†çš„æ ‡ç­¾æ•°é‡ä¸Šé™"
                            )
                    
                    # ç»Ÿè®¡åŽŸå§‹æ ‡ç­¾ä¿¡æ¯
                    total_labels = len(annotation.segment_label_annotations)
                    all_segments_count = 0
                    filtered_segments_count = 0
                    
                    # å‡†å¤‡æ ‡ç­¾ç‰‡æ®µæ•°æ®
                    label_segments = []
                    label_debug_info = []
                    
                    for i, label in enumerate(annotation.segment_label_annotations[:max_labels]):
                        label_name = label.entity.description
                        label_name_cn = translate_label_to_chinese(label_name, use_deepseek=use_deepseek_translation)
                        
                        for segment in label.segments:
                            try:
                                start_time = get_time_seconds(segment.segment.start_time_offset)
                                end_time = get_time_seconds(segment.segment.end_time_offset)
                                confidence = segment.confidence
                                duration = end_time - start_time
                                
                                all_segments_count += 1
                                
                                # è®°å½•è°ƒè¯•ä¿¡æ¯
                                label_debug_info.append({
                                    'label': label_name_cn,
                                    'duration': duration,
                                    'confidence': confidence,
                                    'start_time': start_time,
                                    'end_time': end_time,
                                    'passed_duration': duration >= min_duration,
                                    'passed_confidence': confidence >= min_confidence
                                })
                                
                                if duration >= min_duration and confidence >= min_confidence:
                                    filtered_segments_count += 1
                                    label_segments.append({
                                        'start_time': start_time,
                                        'end_time': end_time,
                                        'type': f"æ ‡ç­¾_{label_name_cn}",
                                        'confidence': confidence
                                    })
                            except Exception as e:
                                continue
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ£€æµ‹åˆ°çš„æ ‡ç­¾", total_labels)
                    with col2:
                        st.metric("åŽŸå§‹ç‰‡æ®µæ•°", all_segments_count)
                    with col3:
                        st.metric("è¿‡æ»¤åŽç‰‡æ®µ", filtered_segments_count)
                    with col4:
                        filter_rate = (filtered_segments_count / all_segments_count * 100) if all_segments_count > 0 else 0
                        st.metric("é€šè¿‡çŽ‡", f"{filter_rate:.1f}%")
                    
                    # æ˜¾ç¤ºè¯¦ç»†çš„è¿‡æ»¤ä¿¡æ¯
                    if st.checkbox("æ˜¾ç¤ºæ ‡ç­¾è¿‡æ»¤è¯¦æƒ…", key="show_label_filter_details"):
                        st.markdown("#### ðŸ“Š æ ‡ç­¾ç‰‡æ®µè¿‡æ»¤è¯¦æƒ…")
                        
                        if label_debug_info:
                            import pandas as pd
                            df_debug = pd.DataFrame(label_debug_info)
                            
                            # æ·»åŠ çŠ¶æ€åˆ—
                            df_debug['çŠ¶æ€'] = df_debug.apply(
                                lambda row: 'âœ… é€šè¿‡' if row['passed_duration'] and row['passed_confidence'] 
                                else f"âŒ {'æ—¶é•¿ä¸è¶³' if not row['passed_duration'] else ''}{'ç½®ä¿¡åº¦ä½Ž' if not row['passed_confidence'] else ''}", 
                                axis=1
                            )
                            
                            # æ ¼å¼åŒ–æ˜¾ç¤º
                            df_display = df_debug[['label', 'duration', 'confidence', 'çŠ¶æ€']].copy()
                            df_display['duration'] = df_display['duration'].apply(lambda x: f"{x:.2f}s")
                            df_display['confidence'] = df_display['confidence'].apply(lambda x: f"{x:.2f}")
                            df_display.columns = ['æ ‡ç­¾', 'æ—¶é•¿', 'ç½®ä¿¡åº¦', 'çŠ¶æ€']
                            
                            st.dataframe(df_display, use_container_width=True, hide_index=True)
                            
                            # åˆ†æžè¿‡æ»¤åŽŸå› 
                            duration_filtered = len([x for x in label_debug_info if not x['passed_duration']])
                            confidence_filtered = len([x for x in label_debug_info if not x['passed_confidence']])
                            
                            st.info(f"ðŸ“ˆ è¿‡æ»¤ç»Ÿè®¡: {duration_filtered} ä¸ªå› æ—¶é•¿ä¸è¶³è¢«è¿‡æ»¤ï¼Œ{confidence_filtered} ä¸ªå› ç½®ä¿¡åº¦è¿‡ä½Žè¢«è¿‡æ»¤")
                        else:
                            st.warning("æ²¡æœ‰æ ‡ç­¾ç‰‡æ®µæ•°æ®")
                    
                    if label_segments:
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.info(f"å°†æ ¹æ® {len(label_segments)} ä¸ªæ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†è§†é¢‘")
                        with col2:
                            if st.button("ðŸ”ª å¼€å§‹åˆ‡åˆ†æ ‡ç­¾", type="secondary"):
                                with st.spinner("æ­£åœ¨åˆ‡åˆ†æ ‡ç­¾ç‰‡æ®µ..."):
                                    created_segments = create_video_segments(video_path, label_segments, video_id, is_clustered=False)
                                    
                                    if created_segments:
                                        st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªæ ‡ç­¾ç‰‡æ®µ")
                                        
                                        # æ˜¾ç¤ºåˆ›å»ºçš„ç‰‡æ®µä¿¡æ¯
                                        with st.expander("ðŸ“ æŸ¥çœ‹åˆ›å»ºçš„æ ‡ç­¾ç‰‡æ®µ", expanded=True):
                                            for segment in created_segments:
                                                col1, col2, col3 = st.columns([2, 1, 1])
                                                with col1:
                                                    st.write(f"**{segment['type']}** ({segment['duration']:.1f}ç§’)")
                                                with col2:
                                                    st.write(f"{segment['file_size']:.1f} MB")
                                                with col3:
                                                    if st.button(f"ðŸ“ æ‰“å¼€", key=f"open_label_{segment['index']}"):
                                                        import subprocess
                                                        subprocess.run(["open", "-R", segment['file_path']], check=False)
                                    else:
                                        st.error("âŒ æ ‡ç­¾ç‰‡æ®µåˆ›å»ºå¤±è´¥")
                    else:
                        st.info("æ²¡æœ‰æ‰¾åˆ°é€‚åˆåˆ‡åˆ†çš„æ ‡ç­¾ç‰‡æ®µï¼ˆéœ€è¦è‡³å°‘1ç§’é•¿åº¦ï¼‰")
                    
            else:
                st.warning("æ²¡æœ‰æˆåŠŸè§£æžçš„æ ‡ç­¾æ•°æ®")
                
        except Exception as e:
            st.error(f"æ ‡ç­¾æ£€æµ‹ç»“æžœæ˜¾ç¤ºé”™è¯¯: {e}")
            # æ˜¾ç¤ºåŽŸå§‹æ•°æ®ç”¨äºŽè°ƒè¯•
            st.write("åŽŸå§‹æ ‡ç­¾æ•°æ®:")
            st.json(str(annotation.segment_label_annotations[0]) if annotation.segment_label_annotations else "æ— æ•°æ®")
    
    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    with st.expander("ðŸ” è°ƒè¯•ä¿¡æ¯"):
        st.write("**åˆ†æžç»“æžœè¯¦æƒ…:**")
        
        # æ£€æŸ¥å„ç§åˆ†æžç»“æžœ
        results_summary = []
        
        # é•œå¤´åˆ‡åˆ†
        if hasattr(annotation, 'shot_annotations'):
            if annotation.shot_annotations:
                results_summary.append(f"âœ… é•œå¤´åˆ‡åˆ†: {len(annotation.shot_annotations)} ä¸ªé•œå¤´")
            else:
                results_summary.append("âŒ é•œå¤´åˆ‡åˆ†: æ— ç»“æžœ")
        else:
            results_summary.append("âŒ é•œå¤´åˆ‡åˆ†: æœªæ£€æµ‹")
            
        # æ ‡ç­¾æ£€æµ‹
        if hasattr(annotation, 'segment_label_annotations'):
            if annotation.segment_label_annotations:
                results_summary.append(f"âœ… æ ‡ç­¾æ£€æµ‹: {len(annotation.segment_label_annotations)} ä¸ªæ ‡ç­¾")
            else:
                results_summary.append("âŒ æ ‡ç­¾æ£€æµ‹: æ— ç»“æžœ")
        else:
            results_summary.append("âŒ æ ‡ç­¾æ£€æµ‹: æœªæ£€æµ‹")
            
        # ç‰©ä½“è·Ÿè¸ª
        if hasattr(annotation, 'object_annotations'):
            if annotation.object_annotations:
                results_summary.append(f"âœ… ç‰©ä½“è·Ÿè¸ª: {len(annotation.object_annotations)} ä¸ªç‰©ä½“")
            else:
                results_summary.append("âŒ ç‰©ä½“è·Ÿè¸ª: æ— ç»“æžœ")
        else:
            results_summary.append("âŒ ç‰©ä½“è·Ÿè¸ª: æœªæ£€æµ‹")
        
        for result in results_summary:
            st.write(f"- {result}")
            
        # æ˜¾ç¤ºåŽŸå§‹annotationç»“æž„ï¼ˆç”¨äºŽé«˜çº§è°ƒè¯•ï¼‰
        if st.checkbox("æ˜¾ç¤ºåŽŸå§‹APIå“åº”ç»“æž„"):
            st.write("**åŽŸå§‹annotationå¯¹è±¡å±žæ€§:**")
            attrs = [attr for attr in dir(annotation) if not attr.startswith('_')]
            st.write(attrs)
            
            st.write("**annotationå¯¹è±¡è¯¦æƒ…:**")
            st.json({
                "has_shot_annotations": hasattr(annotation, 'shot_annotations'),
                "has_segment_label_annotations": hasattr(annotation, 'segment_label_annotations'),
                "has_object_annotations": hasattr(annotation, 'object_annotations'),
            })
    
    # æ·»åŠ è§†é¢‘åˆ‡åˆ†åŠŸèƒ½
    if video_path and video_id and segments_for_cutting:
        st.markdown(f"### ðŸŽ¬ è§†é¢‘é•œå¤´åˆ‡åˆ†")
        
        col1, col2 = st.columns([3, 1])
        with col1:
            st.info(f"å°†æ ¹æ® {len(segments_for_cutting)} ä¸ªé•œå¤´åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ")
            st.write(f"ðŸ“ ä¿å­˜è·¯å¾„: `data/output/google_video/{video_id}/`")
        with col2:
            if st.button("ðŸ”ª å¼€å§‹åˆ‡åˆ†", type="primary", key="cut_original_shots"):
                with st.spinner("æ­£åœ¨åˆ‡åˆ†è§†é¢‘é•œå¤´..."):
                    created_segments = create_video_segments(
                        video_path, segments_for_cutting, video_id, is_clustered=False
                    )
                    
                    if created_segments:
                        st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªé•œå¤´ç‰‡æ®µ")
                        
                        # æ˜¾ç¤ºåˆ›å»ºçš„ç‰‡æ®µä¿¡æ¯
                        with st.expander("ðŸ“ æŸ¥çœ‹åˆ›å»ºçš„ç‰‡æ®µ", expanded=True):
                            for segment in created_segments:
                                col1, col2, col3 = st.columns([2, 1, 1])
                                
                                with col1:
                                    st.write(f"**ç‰‡æ®µ {segment['index']}**: {segment['type']}")
                                    st.write(f"æ—¶é—´: {segment['start_time']:.1f}s - {segment['end_time']:.1f}s")
                                
                                with col2:
                                    st.write(f"ðŸ“ {segment['file_size']:.1f}MB")
                                
                                with col3:
                                    if st.button(f"ðŸ“‚ æ‰“å¼€", key=f"open_shot_{segment['index']}"):
                                        import subprocess
                                        try:
                                            subprocess.run(["open", "-R", segment['file_path']], check=False)
                                        except Exception as e:
                                            st.error(f"æ— æ³•æ‰“å¼€æ–‡ä»¶å¤¹: {e}")
                    else:
                        st.error("âŒ è§†é¢‘ç‰‡æ®µåˆ›å»ºå¤±è´¥")

def main():
    """ä¸»å‡½æ•°"""
    st.title("ðŸ”¬ Google Cloud Video Intelligence API æµ‹è¯•")
    
    # ðŸ”¥ ç«‹å³æ˜¾ç¤ºå‡­æ®çŠ¶æ€æ£€æŸ¥
    st.markdown("### ðŸ“Š ç³»ç»ŸçŠ¶æ€æ£€æŸ¥")
    
    # æ£€æŸ¥Google Cloudå‡­æ®çŠ¶æ€
    has_credentials, cred_path = check_credentials()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        if has_credentials:
            try:
                with open(cred_path, 'r', encoding='utf-8') as f:
                    cred_data = json.load(f)
                    project_id = cred_data.get('project_id', 'Unknown')
                st.success(f"âœ… **Google Cloudå‡­æ®**: å·²é…ç½® (é¡¹ç›®: {project_id})")
                st.info(f"ðŸ“ å‡­æ®æ–‡ä»¶: {cred_path}")
            except Exception:
                st.success("âœ… **Google Cloudå‡­æ®**: å·²é…ç½®")
        else:
            st.error("âŒ **Google Cloudå‡­æ®**: æœªè®¾ç½®")
            st.warning("âš ï¸ **æ— æ³•ä½¿ç”¨Google Cloud Video IntelligenceåŠŸèƒ½**")
            
            with st.expander("ðŸ”§ å¦‚ä½•è®¾ç½®Google Cloudå‡­æ®", expanded=True):
                st.markdown("""
                **å¿«é€Ÿè®¾ç½®æ­¥éª¤:**
                
                1. **åœ¨æœ¬é¡µé¢è®¾ç½®æ ‡ç­¾é¡µä¸Šä¼ **
                   - ç‚¹å‡»ä¸‹æ–¹ "âš™ï¸ è®¾ç½®" æ ‡ç­¾é¡µ
                   - ä¸Šä¼ Google CloudæœåŠ¡è´¦æˆ·JSONæ–‡ä»¶
                
                2. **èŽ·å–å‡­æ®æ–‡ä»¶æ­¥éª¤:**
                   - è®¿é—® [Google Cloud Console](https://console.cloud.google.com)
                   - åˆ›å»ºé¡¹ç›® â†’ å¯ç”¨Video Intelligence API
                   - åˆ›å»ºæœåŠ¡è´¦æˆ· â†’ ä¸‹è½½JSONå¯†é’¥æ–‡ä»¶
                   - ä¸Šä¼ åˆ°æœ¬é¡µé¢è®¾ç½®åŒºåŸŸ
                
                3. **ç¡®ä¿APIæƒé™:**
                   - Cloud Video Intelligence API
                   - Cloud Storage API (ç”¨äºŽæ–‡ä»¶ä¸Šä¼ )
                """)
    
    with col2:
        if has_credentials:
            # æ˜¾ç¤ºæœåŠ¡çŠ¶æ€
            st.metric("Google Cloud", "å·²è¿žæŽ¥", "âœ…")
        # åˆ é™¤æœªé…ç½®çš„é”™è¯¯æç¤ºå’ŒæŒ‰é’®æ¨¡å—
    
    st.markdown("---")
    
    # å¦‚æžœæœªé…ç½®å‡­æ®ï¼Œæ˜¾ç¤ºä¸»è¦è¯´æ˜Žä½†ç¦ç”¨åŠŸèƒ½
    if not has_credentials:
        st.warning("ðŸš« **è¯·å…ˆé…ç½®Google Cloudå‡­æ®æ‰èƒ½ä½¿ç”¨æ­¤é¡µé¢åŠŸèƒ½**")
        st.markdown("""
        ### ðŸ“‹ åŠŸèƒ½ä»‹ç»ï¼ˆéœ€è¦å‡­æ®é…ç½®åŽä½¿ç”¨ï¼‰:
        - ðŸŽ¬ **é•œå¤´åˆ‡åˆ†æ£€æµ‹**ï¼šæ™ºèƒ½æ£€æµ‹è§†é¢‘åœºæ™¯å˜åŒ–
        - ðŸ·ï¸ **æ ‡ç­¾æ£€æµ‹**ï¼šè¯†åˆ«è§†é¢‘ä¸­çš„ç‰©ä½“ã€åœºæ™¯ã€åŠ¨ä½œ
        - ðŸ“¦ **ç‰©ä½“è·Ÿè¸ª**ï¼šè·Ÿè¸ªè§†é¢‘ä¸­ç§»åŠ¨çš„å¯¹è±¡
        - âœ‚ï¸ **è‡ªåŠ¨åˆ‡åˆ†**ï¼šæ ¹æ®æ£€æµ‹ç»“æžœè‡ªåŠ¨ç”Ÿæˆè§†é¢‘ç‰‡æ®µ
        - ðŸ“Š **æ‰¹é‡åˆ†æž**ï¼šæ”¯æŒå¤šç‰‡æ®µå¹¶è¡Œå¤„ç†
        """)
        
        # æ˜¾ç¤ºè®¾ç½®æ ‡ç­¾é¡µï¼Œä½†ç¦ç”¨å…¶ä»–åŠŸèƒ½
        tab_settings = st.tabs(["âš™ï¸ è®¾ç½®"])[0]
        with tab_settings:
            st.markdown("### ðŸ“‹ Google Cloud å‡­æ®è®¾ç½®")
            st.markdown("""
            **é¦–æ¬¡ä½¿ç”¨éœ€è¦é…ç½®Google Cloudå‡­æ®æ–‡ä»¶ï¼š**
            """)
            
            if upload_credentials():
                st.rerun()
        
        return
    
    # æœ‰å‡­æ®æ—¶æ˜¾ç¤ºå®Œæ•´åŠŸèƒ½
    st.markdown("""
    è¿™ä¸ªæµ‹è¯•é¡µé¢å¯ä»¥å¸®æ‚¨éªŒè¯ Google Cloud Video Intelligence API çš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - ðŸŽ¬ é•œå¤´åˆ‡åˆ†æ£€æµ‹
    - ðŸ·ï¸ æ ‡ç­¾æ£€æµ‹
    - ðŸ“¦ ç‰©ä½“è·Ÿè¸ª
    
    **ðŸš€ æ ¸å¿ƒåŠŸèƒ½**:
    - âœ‚ï¸ **æ™ºèƒ½è§†é¢‘åˆ‡åˆ†**: æ ¹æ®é•œå¤´æ£€æµ‹ç»“æžœè‡ªåŠ¨åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ
    - ðŸ“ ç‰‡æ®µè‡ªåŠ¨ä¿å­˜åˆ° `data/output/google_video/` ç›®å½•
    - ðŸ“Š æä¾›è¯¦ç»†çš„åˆ†æžç»Ÿè®¡å’Œå¯è§†åŒ–å±•ç¤º
    
    **ä½¿ç”¨æµç¨‹**: ä¸Šä¼ è§†é¢‘ â†’ Google Cloud AIåˆ†æž â†’ è§†é¢‘åˆ‡åˆ† â†’ åœ¨'ðŸ·ï¸ ç‰‡æ®µæ ‡ç­¾åˆ†æž'æ¨¡å—è¿›è¡ŒAIæ ‡æ³¨
    """)
    st.markdown("---")
    
    # åŠŸèƒ½é€‰æ‹©æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4 = st.tabs(["ðŸŽ¬ è§†é¢‘åˆ†æžä¸Žåˆ‡åˆ†", "ðŸ›ï¸ åœºæ™¯èšåˆ", "ðŸ·ï¸ ç‰‡æ®µæ ‡ç­¾åˆ†æž", "âš™ï¸ è®¾ç½®"])
    
    with tab1:
            # ä¿ç•™å…¼å®¹æ€§
            use_deepseek_translation = False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„åˆ†æžç»“æžœ
            if st.session_state.analysis_result and st.session_state.analysis_config:
                st.success("âœ… å‘çŽ°ä¹‹å‰çš„åˆ†æžç»“æžœ")
                
                # æ˜¾ç¤ºä¹‹å‰çš„åˆ†æžç»“æžœ
                config = st.session_state.analysis_config
                display_results(
                    st.session_state.analysis_result,
                    config['shot_detection'],
                    config['label_detection'], 
                    config['object_tracking'],
                    config['use_deepseek_translation'],
                    st.session_state.current_video_path,
                    st.session_state.current_video_id
                )
                
                # æ·»åŠ æ¸…é™¤ç»“æžœæŒ‰é’®
                if st.button("ðŸ”„ é‡æ–°åˆ†æž", type="secondary"):
                    st.session_state.analysis_result = None
                    st.session_state.current_video_path = None
                    st.session_state.current_video_id = None
                    st.session_state.analysis_config = None
                    st.rerun()
            else:
                # å¼€å§‹æµ‹è¯•
                test_video_intelligence(use_deepseek_translation)
    
    with tab2:
        st.subheader("ðŸ›ï¸ åœºæ™¯èšåˆ")
        st.markdown("""
        å¯¹å·²åˆ‡åˆ†çš„è§†é¢‘ç‰‡æ®µè¿›è¡Œæ™ºèƒ½èšåˆï¼Œç”Ÿæˆæ›´æœ‰æ„ä¹‰çš„åœºæ™¯ï¼š
        - ðŸ§  **è§†è§‰ç‰¹å¾èšç±»**: åŸºäºŽé¢œè‰²ã€çº¹ç†ã€è¾¹ç¼˜ç­‰135ç»´ç‰¹å¾è¿›è¡Œèšåˆ
        - ðŸ“Š **è‡ªé€‚åº”èšç±»**: è‡ªåŠ¨ç¡®å®šæœ€ä½³èšç±»æ•°é‡
        - â±ï¸ **æ—¶é—´è¿žç»­æ€§ä¿è¯**: ç¡®ä¿èšåˆåŽçš„åœºæ™¯åœ¨æ—¶é—´ä¸Šè¿žç»­
        """)
        
        # åœºæ™¯èšåˆåŠŸèƒ½
        scene_clustering_interface()
    
    with tab3:
        st.subheader("ðŸ·ï¸ è§†é¢‘ç‰‡æ®µæ ‡ç­¾åˆ†æž")
        st.markdown("""
        é’ˆå¯¹å·²åˆ‡åˆ†çš„è§†é¢‘ç‰‡æ®µè¿›è¡ŒAIæ ‡ç­¾åˆ†æžï¼Œæ”¯æŒå¤šç§åˆ†æžæ¨¡åž‹ï¼š
        - ðŸŒ **Google Cloud Video Intelligence**: é«˜ç²¾åº¦æ ‡ç­¾æ£€æµ‹
        - ðŸ§  **Qwenæ¨¡åž‹**: æœ¬åœ°åŒ–è§†è§‰ç†è§£åˆ†æž
        """)
        
        # è§†é¢‘ç‰‡æ®µæ ‡ç­¾åˆ†æžåŠŸèƒ½
        analyze_existing_segments()
    
    with tab4:
        st.subheader("âš™ï¸ ç³»ç»Ÿè®¾ç½®")
        
        # Google Cloudå‡­æ®è®¾ç½®
        st.markdown("### ðŸ“‹ Google Cloud å‡­æ®è®¾ç½®")
        
        if has_credentials:
            st.success(f"âœ… Google Cloud å‡­æ®å·²è®¾ç½®: {cred_path}")
            
            # æ˜¾ç¤ºå½“å‰é¡¹ç›®ä¿¡æ¯
            try:
                with open(cred_path, 'r', encoding='utf-8') as f:
                    cred_data = json.load(f)
                    st.info(f"å½“å‰é¡¹ç›®ID: {cred_data.get('project_id', 'Unknown')}")
            except:
                pass
            
            # æä¾›é‡æ–°ä¸Šä¼ é€‰é¡¹
            if st.button("ðŸ”„ é‡æ–°ä¸Šä¼ å‡­æ®æ–‡ä»¶"):
                if upload_credentials():
                    st.rerun()
        else:
            st.markdown("""
            ### ðŸ“‹ è®¾ç½®æ­¥éª¤ï¼š
            
            1. **åˆ›å»º Google Cloud é¡¹ç›®**
               - è®¿é—® [Google Cloud Console](https://console.cloud.google.com)
               - åˆ›å»ºæ–°é¡¹ç›®æˆ–é€‰æ‹©çŽ°æœ‰é¡¹ç›®
            
            2. **å¯ç”¨ Video Intelligence API**
               - åœ¨å¯¼èˆªèœå•ä¸­é€‰æ‹© "API å’ŒæœåŠ¡" > "åº“"
               - æœç´¢å¹¶å¯ç”¨ "Cloud Video Intelligence API"
            
            3. **åˆ›å»ºæœåŠ¡è´¦å·**
               - åœ¨å¯¼èˆªèœå•ä¸­é€‰æ‹© "API å’ŒæœåŠ¡" > "å‡­æ®"
               - ç‚¹å‡» "åˆ›å»ºå‡­æ®" > "æœåŠ¡è´¦å·"
               - å¡«å†™æœåŠ¡è´¦å·ä¿¡æ¯å¹¶å®Œæˆåˆ›å»º
            
            4. **ä¸‹è½½å¯†é’¥æ–‡ä»¶**
               - åœ¨æœåŠ¡è´¦å·åˆ—è¡¨ä¸­ï¼Œç‚¹å‡»åˆšåˆ›å»ºçš„è´¦å·
               - é€‰æ‹© "å¯†é’¥" æ ‡ç­¾é¡µ
               - ç‚¹å‡» "æ·»åŠ å¯†é’¥" > "åˆ›å»ºæ–°å¯†é’¥"ï¼Œé€‰æ‹© JSON æ ¼å¼
            
            5. **ä¸Šä¼ å¯†é’¥æ–‡ä»¶**
               - ä½¿ç”¨ä¸‹é¢çš„æ–‡ä»¶ä¸Šä¼ å™¨ä¸Šä¼ åˆšä¸‹è½½çš„ JSON å¯†é’¥æ–‡ä»¶
            """)
            
            # ä¸Šä¼ å‡­æ®
            if upload_credentials():
                st.rerun()

    # åœ¨mainå‡½æ•°æœ€åŽæ·»åŠ æ•°æ®å­˜å‚¨è¯´æ˜Ž
    st.markdown("---")
    st.markdown("### ðŸ“ æ•°æ®å­˜å‚¨è¯´æ˜Ž")
    
    with st.expander("ðŸ“‚ åˆ†æžç»“æžœå­˜æ”¾ä½ç½®", expanded=False):
        st.markdown("""
        **ðŸŽ¯ åˆ†æžç»“æžœè‡ªåŠ¨ä¿å­˜ä½ç½®ï¼š**
        
        **ðŸ“Š JSONæ ¼å¼åŽŸå§‹æ•°æ®ï¼š**
        - **Google Cloudåˆ†æž**: `data/output/google_video/{video_id}/google_cloud_analysis_{timestamp}.json`
        - **Qwenæ¨¡åž‹åˆ†æž**: `data/output/google_video/{video_id}/qwen_analysis_{timestamp}.json`
        
        **ðŸ“‹ è¡¨æ ¼å¯¼å‡ºæ•°æ®ï¼š**
        - **CSVè¡¨æ ¼**: `data/results/{filename}.csv` (UTF-8æ ¼å¼ï¼ŒExcelå¯ç›´æŽ¥æ‰“å¼€)
        - **JSONè¡¨æ ¼**: `data/results/{filename}.json` (ç»“æž„åŒ–æ•°æ®)
        - **Excelè¡¨æ ¼**: `data/results/{filename}.xlsx` (å¦‚æžœå®‰è£…äº†openpyxl)
        
        **ðŸŽ¬ è§†é¢‘ç‰‡æ®µæ–‡ä»¶ï¼š**
        - **åˆ†å‰²ç‰‡æ®µ**: `data/output/google_video/{video_id}/segments/`
        - **åŽŸå§‹è§†é¢‘**: `data/input/` (ç”¨æˆ·ä¸Šä¼ çš„è§†é¢‘)
        
        **ðŸ’¡ å¿«é€Ÿè®¿é—®ï¼š**
        - ç‚¹å‡»åˆ†æžç»“æžœé¡µé¢çš„"ðŸ“‚ æ‰“å¼€ç‰‡æ®µæ–‡ä»¶å¤¹"æŒ‰é’®å¯ç›´æŽ¥æ‰“å¼€å¯¹åº”ç›®å½•
        - ç‚¹å‡»"ðŸ’¾ å¯¼å‡ºè¡¨æ ¼æ•°æ®"æŒ‰é’®å¯ç”Ÿæˆå¤šæ ¼å¼è¡¨æ ¼æ–‡ä»¶
        - æ‰€æœ‰åˆ†æžéƒ½ä¼šè‡ªåŠ¨ä¿å­˜ï¼Œæ— éœ€æ‰‹åŠ¨æ“ä½œ
        
        **ðŸ“‹ è¡¨æ ¼æ ¼å¼è¯´æ˜Žï¼š**
        ```
        video_id | start_time | end_time | visual_label | confidence
        1.mp4    | 00:00:00   | 00:00:04 | baby,chair    | ðŸŸ¢ 0.915
        1.mp4    | 00:00:04   | 00:00:08 | garden,plant  | ðŸŸ¡ 0.650
        ```
        
        **ðŸŽ¨ ç½®ä¿¡åº¦é¢œè‰²å«ä¹‰ï¼š**
        - ðŸŸ¢ **é«˜ç½®ä¿¡åº¦ (0.8-1.0)**: ç»“æžœéžå¸¸å¯é ï¼Œå¯ç›´æŽ¥ä½¿ç”¨
        - ðŸŸ¡ **ä¸­ç­‰ç½®ä¿¡åº¦ (0.5-0.8)**: ç»“æžœè¾ƒå¯é ï¼Œå»ºè®®äººå·¥æ ¸æŸ¥  
        - ðŸ”´ **ä½Žç½®ä¿¡åº¦ (0.0-0.5)**: ç»“æžœä¸å¤ªå¯é ï¼Œéœ€è¦éªŒè¯
        """)

def analyze_existing_segments():
    """åˆ†æžå·²å­˜åœ¨çš„è§†é¢‘ç‰‡æ®µ"""
    st.markdown("### ðŸ“ é€‰æ‹©è§†é¢‘ç‰‡æ®µç›®å½•")
    
    # æ‰«æå¯ç”¨çš„è§†é¢‘IDç›®å½•
    from pathlib import Path
    root_dir = Path(__file__).parent.parent.parent
    base_output_dir = root_dir / "data" / "output" / "google_video"
    
    if not base_output_dir.exists():
        st.warning("âŒ æœªæ‰¾åˆ°è§†é¢‘ç‰‡æ®µç›®å½•")
        st.info("è¯·å…ˆåœ¨ 'ðŸŽ¬ è§†é¢‘åˆ†æžä¸Žåˆ‡åˆ†' æ ‡ç­¾é¡µä¸­å®Œæˆè§†é¢‘åˆ‡åˆ†")
        return
    
    # èŽ·å–æ‰€æœ‰è§†é¢‘IDç›®å½•
    video_dirs = [d for d in base_output_dir.iterdir() if d.is_dir()]
    
    if not video_dirs:
        st.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ç‰‡æ®µ")
        st.info("è¯·å…ˆåœ¨ 'ðŸŽ¬ è§†é¢‘åˆ†æžä¸Žåˆ‡åˆ†' æ ‡ç­¾é¡µä¸­å®Œæˆè§†é¢‘åˆ‡åˆ†")
        return
    
    # é€‰æ‹©è§†é¢‘ID
    video_ids = [d.name for d in video_dirs]
    selected_video_id = st.selectbox(
        "é€‰æ‹©è¦åˆ†æžçš„è§†é¢‘IDï¼š",
        video_ids,
        help="è¿™äº›æ˜¯å·²ç»åˆ‡åˆ†è¿‡çš„è§†é¢‘é¡¹ç›®"
    )
    
    if selected_video_id:
        segments_dir = base_output_dir / selected_video_id
        
        # èŽ·å–ç‰‡æ®µæ–‡ä»¶
        segment_files = list(segments_dir.glob("*.mp4"))
        segment_files.sort()
        
        if not segment_files:
            st.warning(f"âŒ åœ¨ç›®å½• {segments_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘ç‰‡æ®µ")
            return
        
        st.success(f"âœ… æ‰¾åˆ° {len(segment_files)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
        with st.expander("ðŸ“‹ ç‰‡æ®µåˆ—è¡¨", expanded=False):
            for i, segment_file in enumerate(segment_files[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                file_size = segment_file.stat().st_size / (1024*1024)
                st.write(f"{i+1}. {segment_file.name} ({file_size:.1f} MB)")
            
            if len(segment_files) > 10:
                st.write(f"... è¿˜æœ‰ {len(segment_files) - 10} ä¸ªç‰‡æ®µ")
        
        # é€‰æ‹©åˆ†æžæ¨¡åž‹
        st.markdown("### ðŸ¤– é€‰æ‹©åˆ†æžæ¨¡åž‹")
        
        analysis_model = "Qwenè§†è§‰æ¨¡åž‹"
        st.info("ðŸ§  ä½¿ç”¨Qwenè§†è§‰æ¨¡åž‹è¿›è¡Œè§†é¢‘ç‰‡æ®µæ ‡ç­¾åˆ†æž")
        
        # åˆ é™¤Google Cloudç›¸å…³çš„æ‰¹å¤„ç†é€‰é¡¹
        use_batch_api = False
        cleanup_files = True
        
        # åˆ†æžå‚æ•°è®¾ç½®
        with st.expander("âš™ï¸ åˆ†æžå‚æ•°", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                max_segments = st.slider(
                    "åˆ†æžç‰‡æ®µæ•°é‡",
                    min_value=1,
                    max_value=min(len(segment_files), 50),
                    value=min(len(segment_files), 50),
                    help="ä¸ºäº†èŠ‚çœæ—¶é—´å’Œèµ„æºï¼Œå¯ä»¥é™åˆ¶åˆ†æžçš„ç‰‡æ®µæ•°é‡"
                )
            
            with col2:
                batch_size = st.slider(
                    "æ‰¹å¤„ç†å¤§å°",
                    min_value=1,
                    max_value=5,
                    value=2,
                    help="åŒæ—¶å¤„ç†çš„ç‰‡æ®µæ•°é‡ï¼Œå½±å“åˆ†æžé€Ÿåº¦"
                )
        
        # å¼€å§‹åˆ†æžæŒ‰é’®
        if st.button("ðŸš€ å¼€å§‹ç‰‡æ®µæ ‡ç­¾åˆ†æž", type="primary"):
            if analysis_model == "Qwenè§†è§‰æ¨¡åž‹":
                analyze_segments_with_qwen(segment_files[:max_segments], selected_video_id, batch_size)
            else:
                st.warning("ðŸš« å½“å‰é€‰æ‹©çš„åˆ†æžæ¨¡åž‹ä¸æ”¯æŒ")

def analyze_segments_with_qwen(segment_files, video_id, batch_size=2):
    """ä½¿ç”¨Qwenæ¨¡åž‹åˆ†æžè§†é¢‘ç‰‡æ®µï¼ˆä¼˜åŒ–ç‰ˆæ‰¹å¤„ç†ï¼‰"""
    st.markdown("### ðŸ§  Qwenæ¨¡åž‹ç‰‡æ®µåˆ†æž")
    
    try:
        # æ£€æŸ¥Qwenåˆ†æžå™¨æ˜¯å¦å¯ç”¨
        from streamlit_app.modules.ai_analyzers import QwenVideoAnalyzer
        
        analyzer = QwenVideoAnalyzer()
        if not analyzer.is_available():
            st.error("âŒ Qwenåˆ†æžå™¨ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥DASHSCOPE_API_KEYé…ç½®")
            return
        
        st.info(f"ðŸš€ å¼€å§‹ä½¿ç”¨Qwenæ¨¡åž‹åˆ†æž {len(segment_files)} ä¸ªç‰‡æ®µï¼ˆæ‰¹å¤„ç†å¤§å°: {batch_size}ï¼‰")
        
        # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
        progress_bar = st.progress(0)
        status_text = st.empty()
        metrics_cols = st.columns(4)
        
        with metrics_cols[0]:
            total_metric = st.metric("æ€»ç‰‡æ®µ", len(segment_files))
        with metrics_cols[1]:
            processed_metric = st.metric("å·²å¤„ç†", 0)
        with metrics_cols[2]:
            success_metric = st.metric("æˆåŠŸ", 0)
        with metrics_cols[3]:
            error_metric = st.metric("å¤±è´¥", 0)
        
        segment_results = []
        processed_count = 0
        success_count = 0
        error_count = 0
        
        # ä¼˜åŒ–çš„æ‰¹å¤„ç†åˆ†æž - æ·»åŠ å»¶æ—¶å’Œé‡è¯•æœºåˆ¶
        for i in range(0, len(segment_files), batch_size):
            batch_files = segment_files[i:i+batch_size]
            batch_num = i // batch_size + 1
            total_batches = (len(segment_files) + batch_size - 1) // batch_size
            
            status_text.text(f"ðŸ“¦ å¤„ç†æ‰¹æ¬¡ {batch_num}/{total_batches}ï¼ŒåŒ…å« {len(batch_files)} ä¸ªç‰‡æ®µ")
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªæ–‡ä»¶
            for j, segment_file in enumerate(batch_files):
                current_index = i + j + 1
                
                try:
                    segment_name = segment_file.name
                    status_text.text(f"ðŸ” æ­£åœ¨åˆ†æžç‰‡æ®µ {current_index}/{len(segment_files)}: {segment_name}")
                    
                    # é‡è¯•æœºåˆ¶
                    max_retries = 2
                    analysis_result = None
                    
                    for retry in range(max_retries + 1):
                        try:
                            # ä½¿ç”¨Qwenåˆ†æžè§†é¢‘å†…å®¹
                            analysis_result = analyzer.analyze_video_segment(
                                video_path=str(segment_file),
                                tag_language="ä¸­æ–‡",
                                frame_rate=2.0
                            )
                            
                            if analysis_result.get("success"):
                                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªçŽ¯
                            else:
                                if retry < max_retries:
                                    status_text.text(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry + 1}/{max_retries})...")
                                    time.sleep(1)  # é‡è¯•å‰ç­‰å¾…1ç§’
                                    
                        except Exception as e:
                            if retry < max_retries:
                                status_text.text(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¼‚å¸¸ï¼Œæ­£åœ¨é‡è¯• ({retry + 1}/{max_retries}): {str(e)}")
                                time.sleep(1)
                            else:
                                raise e
                    
                    processed_count += 1
                    
                    if analysis_result and analysis_result.get("success"):
                        success_count += 1
                        
                        # ç›´æŽ¥ä½¿ç”¨è§£æžåŽçš„å­—æ®µï¼Œä¸å†éœ€è¦é‡æ–°æž„é€  labels åˆ—è¡¨
                        # analysis_result å·²ç»åŒ…å«äº† object, sence, emotion, brand_elements, confidence ç­‰å­—æ®µ
                        
                        segment_analysis = {
                            'file_name': segment_name,
                            'file_path': str(segment_file),
                            'file_size': segment_file.stat().st_size / (1024*1024),  # MB
                            'model': 'Qwen2.5', # æˆ–è€…ä»Ž analysis_result èŽ·å–ï¼ˆå¦‚æžœæ¨¡åž‹æœ‰è¿”å›žï¼‰
                            'quality_score': 0.9,  # é»˜è®¤æˆ–ä»Ž analysis_result èŽ·å–
                            # ç›´æŽ¥åˆå¹¶ analysis_result ä¸­çš„å­—æ®µ
                            **analysis_result # è¿™ä¼šæŠŠ object, sence, etc. æ·»åŠ è¿›æ¥
                        }
                        
                        # ç§»é™¤æ—§çš„summaryå’Œemotionså­—æ®µï¼Œå› ä¸ºæ–°æ ¼å¼ä¸­å·²ç»åŒ…å«
                        # segment_analysis.pop('summary', None)
                        # segment_analysis.pop('emotions', None)
                        # segment_analysis.pop('labels', None) # ç§»é™¤æ—§çš„labelsåˆ—è¡¨

                        # ç¡®ä¿CSVå’ŒJSONéœ€è¦çš„å­—æ®µéƒ½åœ¨
                        # å¦‚æžœQwenVideoAnalyzerè¿”å›žçš„analysis_resulté”®åä¸ŽCSVåˆ—åå®Œå…¨ä¸€è‡´ï¼ˆé™¤äº†å¤§å°å†™å’Œsenceæ‹¼å†™ï¼‰
                        # å°±ä¸éœ€è¦ä¸‹é¢çš„æ˜¾å¼èµ‹å€¼ï¼Œ**analysis_resultå·²ç»å¤„ç†äº†
                        # ä½†ä¸ºäº†æ˜Žç¡®ï¼Œå¯ä»¥ä¿ç•™ï¼Œæˆ–è€…ç¡®ä¿QwenVideoAnalyzerè¿”å›žçš„é”®åå°±æ˜¯è¿™äº›
                        segment_analysis['object'] = analysis_result.get('object', 'æ— ')
                        segment_analysis['sence'] = analysis_result.get('sence', 'æ— ') # ç¡®ä¿ä½¿ç”¨CSVçš„senceæ‹¼å†™
                        segment_analysis['emotion'] = analysis_result.get('emotion', 'æ— ')
                        segment_analysis['brand_elements'] = analysis_result.get('brand_elements', 'æ— ')
                        segment_analysis['confidence'] = analysis_result.get('confidence', 0.0)
                        
                        segment_results.append(segment_analysis)
                        
                    else:
                        error_count += 1
                        error_msg = analysis_result.get('error', 'æœªçŸ¥é”™è¯¯') if analysis_result else 'åˆ†æžå¤±è´¥'
                        st.warning(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¤±è´¥: {error_msg}")
                    
                except Exception as e:
                    error_count += 1
                    processed_count += 1
                    st.error(f"âŒ åˆ†æžç‰‡æ®µ {segment_file.name} æ—¶å‡ºé”™: {str(e)}")
                    continue
                
                # æ›´æ–°è¿›åº¦å’ŒæŒ‡æ ‡
                progress = current_index / len(segment_files)
                progress_bar.progress(progress)
                
                # æ›´æ–°æŒ‡æ ‡æ˜¾ç¤º
                with metrics_cols[1]:
                    processed_metric.metric("å·²å¤„ç†", processed_count)
                with metrics_cols[2]:
                    success_metric.metric("æˆåŠŸ", success_count)
                with metrics_cols[3]:
                    error_metric.metric("å¤±è´¥", error_count)
                
                # APIé™æµæŽ§åˆ¶ - åœ¨æ¯ä¸ªç‰‡æ®µåˆ†æžåŽæ·»åŠ å»¶æ—¶
                if current_index < len(segment_files):  # ä¸æ˜¯æœ€åŽä¸€ä¸ªç‰‡æ®µ
                    delay_time = 0.5 if batch_size <= 2 else 1.0  # æ ¹æ®æ‰¹å¤„ç†å¤§å°è°ƒæ•´å»¶æ—¶
                    status_text.text(f"â³ APIé™æµæŽ§åˆ¶ï¼Œç­‰å¾… {delay_time} ç§’...")
                    time.sleep(delay_time)
            
            # æ‰¹æ¬¡é—´å»¶æ—¶ - åœ¨æ¯ä¸ªæ‰¹æ¬¡åŽæ·»åŠ ç¨é•¿çš„å»¶æ—¶
            if i + batch_size < len(segment_files):  # ä¸æ˜¯æœ€åŽä¸€ä¸ªæ‰¹æ¬¡
                batch_delay = 1.0 if batch_size <= 2 else 2.0
                status_text.text(f"ðŸ“¦ æ‰¹æ¬¡ {batch_num} å®Œæˆï¼Œç­‰å¾… {batch_delay} ç§’åŽå¤„ç†ä¸‹ä¸€æ‰¹...")
                time.sleep(batch_delay)
        
        # æ˜¾ç¤ºåˆ†æžç»“æžœ
        progress_bar.progress(1.0)
        status_text.text(f"âœ… Qwenæ¨¡åž‹åˆ†æžå®Œæˆï¼æˆåŠŸåˆ†æž {success_count}/{len(segment_files)} ä¸ªç‰‡æ®µ")
        
        if segment_results:
            display_qwen_analysis_results(segment_results, video_id)
        else:
            st.error("âŒ æ²¡æœ‰æˆåŠŸåˆ†æžçš„ç‰‡æ®µ")
            
    except ImportError:
        st.error("âŒ æ— æ³•å¯¼å…¥Qwenåˆ†æžå™¨ï¼Œè¯·æ£€æŸ¥æ¨¡å—æ˜¯å¦æ­£ç¡®å®‰è£…")
        st.info("è¯·ç¡®ä¿å·²å®‰è£…DashScopeç›¸å…³ä¾èµ–")
    except Exception as e:
        st.error(f"âŒ Qwenåˆ†æžè¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
        import traceback
        st.code(traceback.format_exc(), language="python")

def analyze_segments_with_google_cloud(segment_files, video_id, use_batch_api=False, cleanup_files=True):
    """ä½¿ç”¨Google Cloud Video Intelligenceåˆ†æžè§†é¢‘ç‰‡æ®µï¼ˆä¼˜åŒ–ç‰ˆæ‰¹å¤„ç†ï¼‰"""
    st.markdown("### â˜ï¸ Google Cloud Video Intelligence ç‰‡æ®µåˆ†æž")
    
    try:
        from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
        
        # åˆ›å»ºåˆ†æžå™¨
        analyzer = GoogleVideoAnalyzer()
        
        # æ£€æŸ¥å‡­æ®æ˜¯å¦æœ‰æ•ˆ
        has_credentials, cred_path = analyzer.check_credentials()
        if not has_credentials:
            st.error("âŒ Google Cloud å‡­æ®æœªè®¾ç½®æˆ–æ— æ•ˆ")
            st.info("è¯·åœ¨è®¾ç½®é¡µé¢é…ç½®Google Cloudå‡­æ®")
            return
        
        if use_batch_api:
            # ä½¿ç”¨åŽŸç”Ÿæ‰¹å¤„ç†API
            st.info(f"ðŸš€ ä½¿ç”¨åŽŸç”Ÿæ‰¹å¤„ç†APIåˆ†æž {len(segment_files)} ä¸ªç‰‡æ®µ")
            st.success(f"ðŸ“¦ è§†é¢‘å°†ä¸Šä¼ åˆ° `ai-video-master` å­˜å‚¨æ¡¶çš„ `video-analysis/` æ–‡ä»¶å¤¹ä¸­")
            
            # è½¬æ¢ä¸ºè·¯å¾„åˆ—è¡¨
            video_paths = [str(segment_file) for segment_file in segment_files]
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # æ‰¹å¤„ç†åˆ†æž
            def progress_callback(progress, message):
                progress_bar.progress(progress / 100.0)
                status_text.text(message)
            
            batch_result = analyzer.analyze_videos_batch(
                video_paths=video_paths,
                features=["label_detection"],
                progress_callback=progress_callback,
                cleanup_cloud_files=cleanup_files
            )
            
            if batch_result.get("success"):
                st.success(f"âœ… æ‰¹å¤„ç†åˆ†æžå®Œæˆï¼æˆåŠŸåˆ†æž {batch_result['total_videos']} ä¸ªè§†é¢‘")
                
                # æ˜¾ç¤ºæ‰¹å¤„ç†ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ€»ç‰‡æ®µ", batch_result['total_videos'])
                with col2:
                    st.metric("æˆåŠŸä¸Šä¼ ", batch_result['successful_uploads'])
                with col3:
                    st.metric("æ‰¹å¤„ç†ID", batch_result.get('batch_operation_name', 'N/A')[:8] + "...")
                with col4:
                    st.metric("å­˜å‚¨æ¡¶", batch_result.get('bucket_name', 'N/A')[:15] + "...")
                
                # æ˜¾ç¤ºä¸ªåˆ«ç»“æžœ
                individual_results = batch_result.get('individual_results', [])
                display_google_cloud_batch_results(individual_results, video_id)
                
                # ä¿å­˜ç»“æžœ
                if st.button("ðŸ’¾ ä¿å­˜æ‰¹å¤„ç†åˆ†æžç»“æžœ"):
                    save_google_cloud_batch_results(batch_result, video_id)
                    st.success("âœ… æ‰¹å¤„ç†ç»“æžœå·²ä¿å­˜")
            else:
                st.error(f"âŒ æ‰¹å¤„ç†åˆ†æžå¤±è´¥: {batch_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        else:
            # ä½¿ç”¨åŽŸæœ‰çš„é¡ºåºå¤„ç†æ–¹å¼
            st.info(f"ðŸ”„ ä½¿ç”¨é¡ºåºå¤„ç†æ–¹å¼åˆ†æž {len(segment_files)} ä¸ªç‰‡æ®µ")
            
            # ä½¿ç”¨æ ‡ç­¾æ£€æµ‹
            features = ["label_detection"]
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            metrics_cols = st.columns(4)
            
            with metrics_cols[0]:
                total_metric = st.metric("æ€»ç‰‡æ®µ", len(segment_files))
            with metrics_cols[1]:
                processed_metric = st.metric("å·²å¤„ç†", 0)
            with metrics_cols[2]:
                success_metric = st.metric("æˆåŠŸ", 0)
            with metrics_cols[3]:
                error_metric = st.metric("å¤±è´¥", 0)
            
            segment_results = []
            processed_count = 0
            success_count = 0
            error_count = 0
            
            # ä¼˜åŒ–çš„é¡ºåºå¤„ç† - Google Cloud APIé€šå¸¸æœ‰è¾ƒå¥½çš„å†…ç½®ä¼˜åŒ–
            for i, segment_file in enumerate(segment_files):
                try:
                    segment_name = segment_file.name
                    status_text.text(f"ðŸ” æ­£åœ¨åˆ†æžç‰‡æ®µ {i+1}/{len(segment_files)}: {segment_name}")
                    
                    # Google Cloudåˆ†æžé€šå¸¸æ¯”è¾ƒç¨³å®šï¼Œé‡è¯•æ¬¡æ•°å¯ä»¥å°‘ä¸€äº›
                    max_retries = 2  # å¢žåŠ é‡è¯•æ¬¡æ•°ä»Ž1åˆ°2
                    analysis_result = None
                    last_error = None
                    
                    for retry in range(max_retries + 1):
                        try:
                            # åˆ†æžå•ä¸ªåˆ‡ç‰‡
                            def progress_callback(progress, message):
                                overall_progress = (i + progress/100) / len(segment_files)
                                progress_bar.progress(overall_progress)
                                status_text.text(f"ç‰‡æ®µ {i+1}/{len(segment_files)}: {message}")
                            
                            result = analyzer.analyze_video(
                                video_path=str(segment_file),
                                features=features,
                                progress_callback=progress_callback
                            )
                            
                            if result.get("success"):
                                analysis_result = result
                                break  # æˆåŠŸåˆ™é€€å‡ºé‡è¯•å¾ªçŽ¯
                            else:
                                last_error = result.get('error', 'æœªçŸ¥é”™è¯¯')
                                if retry < max_retries:
                                    status_text.text(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry + 1}/{max_retries})...")
                                    time.sleep(3)  # å¢žåŠ é‡è¯•ç­‰å¾…æ—¶é—´åˆ°3ç§’
                                    
                        except Exception as e:
                            last_error = str(e)
                            if retry < max_retries:
                                status_text.text(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¼‚å¸¸ï¼Œæ­£åœ¨é‡è¯• ({retry + 1}/{max_retries}): {str(e)}")
                                time.sleep(3)  # å¢žåŠ é‡è¯•ç­‰å¾…æ—¶é—´åˆ°3ç§’
                            else:
                                break  # æœ€åŽä¸€æ¬¡é‡è¯•å¤±è´¥å°±é€€å‡º
                    
                    processed_count += 1
                    
                    if analysis_result and analysis_result.get("success"):
                        success_count += 1
                        annotation = analysis_result["result"].annotation_results[0]
                        
                        # æå–åˆ†æžç»“æžœï¼ˆä»…æ ‡ç­¾ï¼‰
                        segment_analysis = {
                            'file_name': segment_name,
                            'file_path': str(segment_file),
                            'file_size': segment_file.stat().st_size / (1024*1024),  # MB
                            'model': 'Google Cloud Video Intelligence',
                            'labels': [],
                            'summary': '',
                            'quality_score': 0.95  # Google Cloud é»˜è®¤è´¨é‡åˆ†
                        }
                        
                        # æå–æ ‡ç­¾
                        labels = []
                        if hasattr(annotation, 'segment_label_annotations') and annotation.segment_label_annotations:
                            for label in annotation.segment_label_annotations[:10]:  # å‰10ä¸ªæ ‡ç­¾
                                label_name = label.entity.description
                                confidence = 0.0
                                
                                if label.segments:
                                    confidence = label.segments[0].confidence
                                
                                labels.append({
                                    'name': label_name,
                                    'confidence': confidence
                                })
                        
                        segment_analysis['labels'] = labels
                        
                        # ç”Ÿæˆç®€å•æ‘˜è¦
                        if labels:
                            top_labels = [label['name'] for label in labels[:3]]
                            segment_analysis['summary'] = f"ä¸»è¦å†…å®¹: {', '.join(top_labels)}"
                        else:
                            segment_analysis['summary'] = "æœªæ£€æµ‹åˆ°æ˜Žæ˜¾å†…å®¹"
                        
                        segment_results.append(segment_analysis)
                        
                        # å®žæ—¶æ˜¾ç¤ºç»“æžœ
                        with st.expander(f"ðŸ“„ {segment_name} - åˆ†æžå®Œæˆ", expanded=False):
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write(f"**æ–‡ä»¶å¤§å°**: {segment_analysis['file_size']:.1f} MB")
                                st.write(f"**è´¨é‡åˆ†**: {segment_analysis['quality_score']:.2f}")
                            with col2:
                                st.write(f"**æ£€æµ‹æ ‡ç­¾**: {len(labels)} ä¸ª")
                                if labels:
                                    st.write(f"**ä¸»è¦æ ‡ç­¾**: {labels[0]['name']} ({labels[0]['confidence']:.2f})")
                            
                            if labels:
                                st.write("**æ‰€æœ‰æ ‡ç­¾**:")
                                for label in labels[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                                    confidence_color = "ðŸŸ¢" if label['confidence'] > 0.8 else "ðŸŸ¡" if label['confidence'] > 0.5 else "ðŸ”´"
                                    st.write(f"  {confidence_color} {label['name']}: {label['confidence']:.2f}")
                    
                    else:
                        error_count += 1
                        # æ˜¾ç¤ºæ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                        if last_error:
                            st.warning(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¤±è´¥: {last_error}")
                        else:
                            st.warning(f"âš ï¸ ç‰‡æ®µ {segment_name} åˆ†æžå¤±è´¥: æœªçŸ¥é”™è¯¯")
                    
                    # æ›´æ–°æŒ‡æ ‡
                    processed_metric.metric("å·²å¤„ç†", processed_count)
                    success_metric.metric("æˆåŠŸ", success_count)
                    error_metric.metric("å¤±è´¥", error_count)
                    
                    # é€‚å½“å»¶è¿Ÿï¼Œé¿å…APIé™æµ
                    time.sleep(1)  # å¢žåŠ å»¶è¿Ÿåˆ°1ç§’
                    
                except Exception as e:
                    error_count += 1
                    processed_count += 1
                    st.error(f"âŒ å¤„ç†ç‰‡æ®µ {segment_file.name} æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                    continue
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æžœ
            if segment_results:
                st.success(f"âœ… é¡ºåºåˆ†æžå®Œæˆï¼æˆåŠŸåˆ†æž {len(segment_results)} ä¸ªç‰‡æ®µ")
                display_google_cloud_analysis_results(segment_results, video_id)
                
                # ä¿å­˜ç»“æžœ
                if st.button("ðŸ’¾ ä¿å­˜åˆ†æžç»“æžœ"):
                    save_google_cloud_analysis_results(segment_results, video_id)
                    st.success("âœ… åˆ†æžç»“æžœå·²ä¿å­˜")
            else:
                st.warning("âš ï¸ æ²¡æœ‰æˆåŠŸåˆ†æžä»»ä½•ç‰‡æ®µ")
    
    except Exception as e:
        st.error(f"âŒ Google Cloud ç‰‡æ®µåˆ†æžå¤±è´¥: {str(e)}")
        logger.error(f"Google Cloud ç‰‡æ®µåˆ†æžå¤±è´¥: {str(e)}")

def display_google_cloud_batch_results(individual_results, video_id):
    """æ˜¾ç¤ºåˆ†æžç»“æžœ"""
    if not individual_results:
        st.warning("æ²¡æœ‰åˆ†æžç»“æžœå¯æ˜¾ç¤º")
        return
    st.markdown("### åˆ†æžç»“æžœ")
    st.info("åŠŸèƒ½æ­£åœ¨ç»´æŠ¤ä¸­")

def save_google_cloud_batch_results(batch_result, video_id):
    """ä¿å­˜Google Cloudæ‰¹å¤„ç†åˆ†æžç»“æžœåˆ°JSONæ–‡ä»¶"""
    try:
        from datetime import datetime
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        root_dir = Path(__file__).parent.parent.parent
        results_dir = root_dir / "data" / "output" / "google_video" / str(video_id)
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # å‡†å¤‡ç»“æžœæ•°æ®
        analysis_data = {
            'video_id': video_id,
            'analysis_type': 'Google Cloud Video Intelligence (Batch)',
            'analysis_time': datetime.now().isoformat(),
            'batch_info': {
                'total_videos': batch_result.get('total_videos', 0),
                'successful_uploads': batch_result.get('successful_uploads', 0),
                'batch_operation_name': batch_result.get('batch_operation_name'),
                'bucket_name': batch_result.get('bucket_name'),
                'features': batch_result.get('features', [])
            },
            'individual_results': batch_result.get('individual_results', []),
            'upload_info': batch_result.get('upload_info', [])
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = results_dir / f"google_cloud_batch_analysis_{timestamp}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        st.info(f"ðŸ“ æ‰¹å¤„ç†ç»“æžœå·²ä¿å­˜åˆ°: {result_file}")
        
    except Exception as e:
        st.error(f"ä¿å­˜æ‰¹å¤„ç†ç»“æžœå¤±è´¥: {str(e)}")
        logger.error(f"ä¿å­˜æ‰¹å¤„ç†ç»“æžœå¤±è´¥: {str(e)}")

def analyze_segments_comparison(segment_files, video_id, batch_size=2):
    """å¯¹æ¯”åˆ†æžï¼šåŒæ—¶ä½¿ç”¨Google Cloudå’ŒQwenæ¨¡åž‹"""
    st.markdown("### ðŸ†š å¯¹æ¯”åˆ†æž")
    st.info("å°†åŒæ—¶ä½¿ç”¨Google Cloudå’ŒQwenæ¨¡åž‹åˆ†æžç›¸åŒçš„è§†é¢‘ç‰‡æ®µï¼Œä»¥ä¾¿å¯¹æ¯”ä¸¤ç§æ¨¡åž‹çš„åˆ†æžç»“æžœ")
    
    # å…ˆè¿è¡ŒGoogle Cloudåˆ†æž
    st.markdown("#### ç¬¬ä¸€æ­¥ï¼šGoogle Cloud Video Intelligence åˆ†æž")
    analyze_segments_with_google_cloud(segment_files, video_id)
    
    st.markdown("---")
    
    # å†è¿è¡ŒQwenåˆ†æž
    st.markdown("#### ç¬¬äºŒæ­¥ï¼šQwenè§†è§‰æ¨¡åž‹åˆ†æž")
    analyze_segments_with_qwen(segment_files, video_id, batch_size)
    
    st.markdown("---")
    st.success("ðŸŽ‰ å¯¹æ¯”åˆ†æžå®Œæˆï¼æ‚¨å¯ä»¥æŸ¥çœ‹ä¸Šæ–¹ä¸¤ä¸ªæ¨¡åž‹çš„åˆ†æžç»“æžœè¿›è¡Œå¯¹æ¯”ã€‚")

def display_qwen_analysis_results(segment_results, video_id):
    """æ˜¾ç¤ºQwenåˆ†æžç»“æžœ - ç®€åŒ–ç‰ˆï¼šåªè‡ªåŠ¨ä¿å­˜æ–‡ä»¶"""
    if not segment_results:
        st.warning("æ²¡æœ‰åˆ†æžç»“æžœå¯æ˜¾ç¤º")
        return
    
    st.markdown("### âœ… Qwenæ¨¡åž‹åˆ†æžå®Œæˆ")
    
    # ðŸ” æ·»åŠ è°ƒè¯•ä¿¡æ¯
    st.markdown("#### ðŸ” è°ƒè¯•ä¿¡æ¯")
    with st.expander("æŸ¥çœ‹åŽŸå§‹åˆ†æžæ•°æ®", expanded=True):
        st.write(f"**æ€»ç»“æžœæ•°é‡**: {len(segment_results)}")
        
        # æ˜¾ç¤ºå‰3ä¸ªç»“æžœçš„è¯¦ç»†ä¿¡æ¯
        for i, result in enumerate(segment_results[:3]):
            st.write(f"**ç»“æžœ {i+1}:**")
            st.json({
                'file_name': result.get('file_name', 'N/A'),
                'object': result.get('object', 'N/A'),
                'sence': result.get('sence', 'N/A'), 
                'emotion': result.get('emotion', 'N/A'),
                'brand_elements': result.get('brand_elements', 'N/A'),
                'confidence': result.get('confidence', 'N/A')
            })
    
    # ç»Ÿè®¡æ ‡ç­¾æ•°é‡
    total_segments = len(segment_results)
    total_tags = 0
    debug_info = []
    for s in segment_results:
        object_count = len(s.get('object', '').split(',')) if s.get('object') and s.get('object') != 'æ— ' else 0
        sence_count = len(s.get('sence', '').split(',')) if s.get('sence') and s.get('sence') != 'æ— ' else 0
        emotion_count = len(s.get('emotion', '').split(',')) if s.get('emotion') and s.get('emotion') != 'æ— ' else 0
        brand_count = len(s.get('brand_elements', '').split(',')) if s.get('brand_elements') and s.get('brand_elements') != 'æ— ' else 0
        tag_count = object_count + sence_count + emotion_count + brand_count
        total_tags += tag_count
        debug_info.append({
            'file_name': s.get('file_name', ''),
            'object': s.get('object', ''),
            'sence': s.get('sence', ''),
            'emotion': s.get('emotion', ''),
            'brand_elements': s.get('brand_elements', ''),
            'object_count': object_count,
            'sence_count': sence_count,
            'emotion_count': emotion_count,
            'brand_count': brand_count,
            'total_tags': tag_count
        })
    
    st.success(f"ðŸŽ‰ æˆåŠŸåˆ†æž {total_segments} ä¸ªè§†é¢‘ç‰‡æ®µï¼Œè¯†åˆ«å‡º {total_tags} ä¸ªæ ‡ç­¾")
    
    # æ˜¾ç¤ºè¯¦ç»†çš„æ ‡ç­¾ç»Ÿè®¡è°ƒè¯•ä¿¡æ¯
    with st.expander("ðŸ“Š æ ‡ç­¾ç»Ÿè®¡è¯¦æƒ…", expanded=True):
        total_objects = sum(d['object_count'] for d in debug_info)
        total_sences = sum(d['sence_count'] for d in debug_info)
        total_emotions = sum(d['emotion_count'] for d in debug_info)
        total_brands = sum(d['brand_count'] for d in debug_info)
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç‰©ä½“æ ‡ç­¾", total_objects)
        with col2:
            st.metric("åœºæ™¯æ ‡ç­¾", total_sences)
        with col3:
            st.metric("æƒ…ç»ªæ ‡ç­¾", total_emotions)
        with col4:
            st.metric("å“ç‰Œæ ‡ç­¾", total_brands)
        
        # æ˜¾ç¤ºæ¯ä¸ªç‰‡æ®µçš„æ ‡ç­¾è¯¦æƒ…
        st.markdown("**å„ç‰‡æ®µæ ‡ç­¾è¯¦æƒ…:**")
        for debug in debug_info[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
            st.write(f"ðŸ“ {debug['file_name']}: ç‰©ä½“({debug['object_count']}) + åœºæ™¯({debug['sence_count']}) + æƒ…ç»ª({debug['emotion_count']}) + å“ç‰Œ({debug['brand_count']}) = {debug['total_tags']} ä¸ªæ ‡ç­¾")
            if debug['total_tags'] == 0:
                st.write(f"   ðŸ” åŽŸå§‹æ•°æ®: object='{debug['object']}', sence='{debug['sence']}', emotion='{debug['emotion']}', brand_elements='{debug['brand_elements']}'")
    
    # è‡ªåŠ¨ä¿å­˜JSONæ–‡ä»¶
    json_file = save_qwen_analysis_results(segment_results, video_id)
    
    # è‡ªåŠ¨ä¿å­˜CSVæ–‡ä»¶
    csv_file = export_qwen_results_to_csv(segment_results, video_id)
    
    # æ˜¾ç¤ºä¿å­˜è·¯å¾„
    st.markdown("#### ðŸ’¾ æ–‡ä»¶å·²è‡ªåŠ¨ä¿å­˜")
    if json_file:
        st.info(f"ðŸ“„ **JSONè¯¦ç»†æ•°æ®**: `{json_file}`")
    if csv_file:
        st.info(f"ðŸ“Š **CSVè¡¨æ ¼æ•°æ®**: `{csv_file}`")
    # ç§»é™¤"ðŸ“‚ æ‰“å¼€ä¿å­˜æ–‡ä»¶å¤¹"æŒ‰é’®

def export_qwen_results_to_csv(segment_results, video_id):
    """å¯¼å‡ºQwenåˆ†æžç»“æžœä¸ºCSVæ–‡ä»¶ - è¿”å›žæ–‡ä»¶è·¯å¾„ï¼Œé€‚é…æ–°çš„demo.csvæ ¼å¼"""
    try:
        import pandas as pd
        from datetime import datetime
        from pathlib import Path
        
        csv_data = []
        for result in segment_results: # segment_resultsçŽ°åœ¨ç›´æŽ¥åŒ…å«è§£æžåŽçš„å­—æ®µ
            # æ¯ä¸ªresultä»£è¡¨ä¸€è¡ŒCSV
            csv_data.append({
                'video_id': video_id,
                'segment_file': result.get('file_name', 'N/A'),
                'file_size_mb': result.get('file_size', 0.0),
                'object': result.get('object', 'æ— '), # ç›´æŽ¥ä»Žè§£æžç»“æžœèŽ·å–
                'sence': result.get('sence', 'æ— '),   # ç›´æŽ¥ä»Žè§£æžç»“æžœèŽ·å– (æ³¨æ„æ‹¼å†™)
                'emotion': result.get('emotion', 'æ— '), # ç›´æŽ¥ä»Žè§£æžç»“æžœèŽ·å–
                'brand_elements': result.get('brand_elements', 'æ— '), # ç›´æŽ¥ä»Žè§£æžç»“æžœèŽ·å–
                'confidence': result.get('confidence', 0.0),
                'model': result.get('model', 'Qwen2.5'), # modelå¯èƒ½å·²åœ¨segment_resultä¸­
                'quality_score': result.get('quality_score', 0.9), # quality_scoreå¯èƒ½å·²åœ¨segment_resultä¸­
                'analysis_time': datetime.now().isoformat()
            })
        
        if csv_data:
            df = pd.DataFrame(csv_data)
            # ç¡®ä¿åˆ—é¡ºåºä¸Ž demo.csv ä¸€è‡´
            column_order = ['video_id', 'segment_file', 'file_size_mb', 'object', 'sence', 'emotion', 'brand_elements', 'confidence', 'model', 'quality_score', 'analysis_time']
            df = df[column_order]
            
            root_dir = Path(__file__).parent.parent.parent
            results_dir = root_dir / "data" / "results"
            results_dir.mkdir(parents=True, exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            # ä½¿ç”¨ä¸Ždemo.csvä¸€è‡´çš„æ–‡ä»¶åï¼Œæˆ–è€…ä¿æŒåŽŸæœ‰å‘½åè§„åˆ™
            csv_file = results_dir / f"qwen_analysis_export_{video_id}_{timestamp}.csv"
            
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            return str(csv_file)
        
        return None
        
    except Exception as e:
        st.error(f"âŒ å¯¼å‡ºCSVå¤±è´¥: {str(e)}")
        return None

def save_qwen_analysis_results(segment_results, video_id):
    """ä¿å­˜Qwenåˆ†æžç»“æžœåˆ°JSONæ–‡ä»¶ - è¿”å›žæ–‡ä»¶è·¯å¾„ï¼Œé€‚é…æ–°æ ¼å¼"""
    try:
        import json
        from pathlib import Path
        from datetime import datetime
        
        root_dir = Path(__file__).parent.parent.parent
        results_dir = root_dir / "data" / "output" / "google_video" / str(video_id)
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # segment_resultsä¸­çš„æ¯ä¸ªå…ƒç´ çŽ°åœ¨åº”è¯¥ç›´æŽ¥åŒ…å«è§£æžåŽçš„å­—æ®µ
        # ä¾‹å¦‚: object, sence, emotion, brand_elements, confidence
        # ä»¥åŠ file_name, file_path, file_size, model, quality_score ç­‰å…ƒæ•°æ®
        # JSONç»“æž„å¯ä»¥ä¿æŒä¸Žä¹‹å‰ç±»ä¼¼ï¼Œä½†segmentsåˆ—è¡¨ä¸­çš„æ¯ä¸ªå­—å…¸ä¼šåŒ…å«æ–°çš„å­—æ®µ
        analysis_data = {
            'video_id': video_id,
            'analysis_time': datetime.now().isoformat(),
            'model': 'Qwen', # æˆ–è€…ä»Žç¬¬ä¸€ä¸ªresultåŠ¨æ€èŽ·å–
            'total_segments': len(segment_results),
            'segments': segment_results # segment_results çŽ°åœ¨æ˜¯å·²è½¬æ¢æ ¼å¼çš„åˆ—è¡¨
        }
        
        result_file = results_dir / f"qwen_analysis_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        return str(result_file)
        
    except Exception as e:
        st.error(f"âŒ ä¿å­˜Qwenåˆ†æžç»“æžœæ—¶å‡ºé”™: {str(e)}")
        return None

def display_google_cloud_analysis_results(segment_results, video_id):
    """æ˜¾ç¤ºåˆ†æžç»“æžœ"""
    if not individual_results:
        st.warning("æ²¡æœ‰åˆ†æžç»“æžœå¯æ˜¾ç¤º")
        return
    st.markdown("### åˆ†æžç»“æžœ")
    st.info("åŠŸèƒ½æ­£åœ¨ç»´æŠ¤ä¸­")

def save_google_cloud_analysis_results(segment_results, video_id):
    """ä¿å­˜Google Cloudåˆ†æžç»“æžœåˆ°JSONæ–‡ä»¶"""
    try:
        from datetime import datetime
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        root_dir = Path(__file__).parent.parent.parent
        results_dir = root_dir / "data" / "output" / "google_video" / str(video_id)
        results_dir.mkdir(parents=True, exist_ok=True)
        
        # å‡†å¤‡ç»“æžœæ•°æ®
        analysis_data = {
            'video_id': video_id,
            'analysis_type': 'Google Cloud Video Intelligence',
            'analysis_time': datetime.now().isoformat(),
            'total_segments': len(segment_results),
            'segments': segment_results
        }
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        result_file = results_dir / f"google_cloud_analysis_{timestamp}.json"
        
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(analysis_data, f, ensure_ascii=False, indent=2)
        
        st.success(f"âœ… Google Cloudåˆ†æžç»“æžœå·²ä¿å­˜åˆ°: {result_file}")
        
    except Exception as e:
        st.error(f"âŒ ä¿å­˜Google Cloudåˆ†æžç»“æžœæ—¶å‡ºé”™: {str(e)}")

def scene_clustering_interface():
    """åœºæ™¯èšåˆç•Œé¢ï¼Œç”¨äºŽå¯¹å·²åˆ‡åˆ†çš„è§†é¢‘ç‰‡æ®µè¿›è¡Œèšåˆ"""
    st.markdown("### ðŸ“ é€‰æ‹©è§†é¢‘ç‰‡æ®µç›®å½•")
    
    # æ‰«æå¯ç”¨çš„è§†é¢‘IDç›®å½•
    from pathlib import Path
    root_dir = Path(__file__).parent.parent.parent
    base_output_dir = root_dir / "data" / "output" / "google_video"
    
    if not base_output_dir.exists():
        st.warning("âŒ æœªæ‰¾åˆ°è§†é¢‘ç‰‡æ®µç›®å½•")
        st.info("è¯·å…ˆåœ¨ 'ðŸŽ¬ è§†é¢‘åˆ†æžä¸Žåˆ‡åˆ†' æ ‡ç­¾é¡µä¸­å®Œæˆè§†é¢‘åˆ‡åˆ†")
        return
    
    # èŽ·å–æ‰€æœ‰è§†é¢‘IDç›®å½•
    video_dirs = [d for d in base_output_dir.iterdir() if d.is_dir()]
    
    if not video_dirs:
        st.warning("âŒ æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘ç‰‡æ®µ")
        st.info("è¯·å…ˆåœ¨ 'ðŸŽ¬ è§†é¢‘åˆ†æžä¸Žåˆ‡åˆ†' æ ‡ç­¾é¡µä¸­å®Œæˆè§†é¢‘åˆ‡åˆ†")
        return
    
    # é€‰æ‹©è§†é¢‘ID
    video_ids = [d.name for d in video_dirs]
    selected_video_id = st.selectbox(
        "é€‰æ‹©è¦èšåˆçš„è§†é¢‘IDï¼š",
        video_ids,
        help="è¿™äº›æ˜¯å·²ç»åˆ‡åˆ†è¿‡çš„è§†é¢‘é¡¹ç›®",
        key="scene_clustering_video_id"
    )
    
    if selected_video_id:
        segments_dir = base_output_dir / selected_video_id
        
        # èŽ·å–ç‰‡æ®µæ–‡ä»¶
        segment_files = list(segments_dir.glob("*.mp4"))
        segment_files.sort()
        
        if not segment_files:
            st.warning(f"âŒ åœ¨ç›®å½• {segments_dir} ä¸­æœªæ‰¾åˆ°è§†é¢‘ç‰‡æ®µ")
            return
        
        st.success(f"âœ… æ‰¾åˆ° {len(segment_files)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        # æ˜¾ç¤ºç‰‡æ®µä¿¡æ¯
        with st.expander("ðŸ“‹ ç‰‡æ®µåˆ—è¡¨", expanded=False):
            for i, segment_file in enumerate(segment_files[:10]):  # åªæ˜¾ç¤ºå‰10ä¸ª
                file_size = segment_file.stat().st_size / (1024*1024)
                st.write(f"{i+1}. {segment_file.name} ({file_size:.1f} MB)")
            
            if len(segment_files) > 10:
                st.write(f"... è¿˜æœ‰ {len(segment_files) - 10} ä¸ªç‰‡æ®µ")
        
        # åˆ†æžç‰‡æ®µç‰¹å¾ï¼Œç»™å‡ºèšåˆå»ºè®®
        analyze_segment_fragmentation(segment_files, selected_video_id)
        
        # èšåˆå‚æ•°è®¾ç½®
        st.markdown("### âš™ï¸ èšåˆå‚æ•°è®¾ç½®")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            similarity_threshold = st.slider(
                "ç›¸ä¼¼åº¦é˜ˆå€¼",
                min_value=0.5,
                max_value=0.9,
                value=0.75,
                step=0.05,
                help="è¶Šé«˜è¶Šä¸¥æ ¼ï¼Œåªåˆå¹¶éžå¸¸ç›¸ä¼¼çš„ç‰‡æ®µ",
                key="scene_clustering_similarity"
            )
        
        with col2:
            min_scene_duration = st.slider(
                "æœ€å°åœºæ™¯æ—¶é•¿ï¼ˆç§’ï¼‰",
                min_value=2.0,
                max_value=10.0,
                value=3.0,
                step=0.5,
                help="èšåˆåŽæ¯ä¸ªåœºæ™¯çš„æœ€å°æŒç»­æ—¶é—´",
                key="scene_clustering_min_duration"
            )
        
        with col3:
            max_scenes = st.selectbox(
                "æœ€å¤§åœºæ™¯æ•°",
                options=[None, 3, 5, 8, 10, 15],
                index=0,
                help="é™åˆ¶æœ€å¤šç”Ÿæˆå¤šå°‘ä¸ªåœºæ™¯ï¼ˆNoneä¸ºè‡ªåŠ¨ï¼‰",
                key="scene_clustering_max_scenes"
            )
        
        # å¼€å§‹èšåˆæŒ‰é’®
        if st.button("ðŸ§  å¼€å§‹åœºæ™¯èšåˆ", type="primary", key="start_scene_clustering"):
            perform_scene_clustering(segment_files, selected_video_id, similarity_threshold, min_scene_duration, max_scenes)

def analyze_segment_fragmentation(segment_files, video_id):
    """åˆ†æžç‰‡æ®µç¢Žç‰‡åŒ–ç¨‹åº¦ï¼Œç»™å‡ºèšåˆå»ºè®®"""
    st.markdown("### ðŸ“Š ç‰‡æ®µç¢Žç‰‡åŒ–åˆ†æž")
    
    try:
        # èŽ·å–ç‰‡æ®µæ—¶é•¿ä¿¡æ¯
        durations = []
        total_size = 0
        
        for segment_file in segment_files:
            try:
                # ç®€å•ä¼°ç®—ï¼šæ–‡ä»¶å¤§å°(MB) / 2 â‰ˆ æ—¶é•¿(ç§’)
                file_size_mb = segment_file.stat().st_size / (1024*1024)
                estimated_duration = file_size_mb / 2  # ç²—ç•¥ä¼°ç®—
                durations.append(estimated_duration)
                total_size += file_size_mb
            except:
                durations.append(2.0)  # é»˜è®¤å€¼
        
        if durations:
            avg_duration = sum(durations) / len(durations)
            short_segments = len([d for d in durations if d < 3.0])
            fragmentation_ratio = short_segments / len(durations) * 100
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("ç‰‡æ®µæ€»æ•°", len(segment_files))
            with col2:
                st.metric("å¹³å‡æ—¶é•¿", f"{avg_duration:.1f}s")
            with col3:
                st.metric("çŸ­ç‰‡æ®µæ•°", f"{short_segments}")
            with col4:
                st.metric("ç¢Žç‰‡åŒ–çŽ‡", f"{fragmentation_ratio:.1f}%")
            
            # ç»™å‡ºèšåˆå»ºè®®
            if fragmentation_ratio > 50:
                st.warning(f"âš ï¸ ç¢Žç‰‡åŒ–ç¨‹åº¦é«˜ ({fragmentation_ratio:.1f}%)")
                st.info(f"ðŸ’¡ å¼ºçƒˆå»ºè®®è¿›è¡Œåœºæ™¯èšåˆï¼Œå¯ä»¥å°† {len(segment_files)} ä¸ªç‰‡æ®µåˆå¹¶ä¸ºæ›´å°‘çš„æœ‰æ„ä¹‰åœºæ™¯")
            elif fragmentation_ratio > 30:
                st.info(f"ðŸ“Š ä¸­ç­‰ç¢Žç‰‡åŒ–ç¨‹åº¦ ({fragmentation_ratio:.1f}%)")
                st.info("ðŸ’¡ å¯ä»¥è€ƒè™‘è¿›è¡Œåœºæ™¯èšåˆæ¥ä¼˜åŒ–ç‰‡æ®µç»“æž„")
            else:
                st.success(f"âœ… ç‰‡æ®µé•¿åº¦åˆ†å¸ƒè‰¯å¥½ ({fragmentation_ratio:.1f}%)")
                st.info("ðŸ’¡ å¯ä»¥é€‰æ‹©æ€§è¿›è¡Œèšåˆï¼Œæˆ–ä¿æŒå½“å‰ç‰‡æ®µç»“æž„")
            
            # é¢„ä¼°èšåˆæ•ˆæžœ
            estimated_scenes = max(3, int(len(segment_files) * 0.3))  # ä¼°ç®—èšåˆåŽåœºæ™¯æ•°
            st.info(f"ðŸŽ¯ é¢„ä¼°èšåˆæ•ˆæžœ: {len(segment_files)} ä¸ªç‰‡æ®µ â†’ çº¦ {estimated_scenes} ä¸ªåœºæ™¯")
            
    except Exception as e:
        st.error(f"âŒ åˆ†æžç‰‡æ®µä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")

def perform_scene_clustering(segment_files, video_id, similarity_threshold, min_scene_duration, max_scenes):
    """æ‰§è¡Œåœºæ™¯èšåˆ"""
    try:
        st.markdown("### ðŸ§  æ‰§è¡Œåœºæ™¯èšåˆ")
        
        # å¯¼å…¥èšç±»æ¨¡å—
        from streamlit_app.modules.video_clustering import cluster_video_segments
        
        with st.spinner("ðŸ” æ­£åœ¨åˆ†æžè§†é¢‘ç‰‡æ®µå¹¶æ‰§è¡Œèšåˆ..."):
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            def progress_callback(progress, message):
                progress_bar.progress(progress / 100.0)
                status_text.text(message)
            
            # æ‰§è¡Œèšåˆ
            clustered_scenes = cluster_video_segments(
                segment_files=segment_files,
                video_id=video_id,
                similarity_threshold=similarity_threshold,
                min_scene_duration=min_scene_duration,
                max_scenes=max_scenes,
                progress_callback=progress_callback
            )
            
            progress_bar.progress(1.0)
            status_text.text("âœ… åœºæ™¯èšåˆå®Œæˆï¼")
            
            if clustered_scenes:
                st.success(f"âœ… èšåˆå®Œæˆï¼{len(segment_files)} ä¸ªç‰‡æ®µ â†’ {len(clustered_scenes)} ä¸ªåœºæ™¯")
                
                # æ˜¾ç¤ºèšåˆç»“æžœ
                display_clustering_results(clustered_scenes, video_id, len(segment_files))
                
                # è‡ªåŠ¨ç”Ÿæˆèšåˆåœºæ™¯è§†é¢‘
                auto_generate_clustered_scene_videos(clustered_scenes, video_id, segment_files)
            else:
                st.error("âŒ åœºæ™¯èšåˆå¤±è´¥")
                
    except ImportError as e:
        st.error("âŒ åœºæ™¯èšåˆåŠŸèƒ½ä¸å¯ç”¨ï¼Œç¼ºå°‘å¿…è¦ä¾èµ–")
        st.info("è¯·å®‰è£…ï¼špip install scikit-learn opencv-python")
    except Exception as e:
        st.error(f"âŒ åœºæ™¯èšåˆå¤±è´¥: {str(e)}")
        import traceback
        st.code(traceback.format_exc(), language="python")

def display_clustering_results(clustered_scenes, video_id, original_segment_count):
    """æ˜¾ç¤ºèšåˆç»“æžœ"""
    st.markdown("#### ðŸ“Š èšåˆç»“æžœè¯¦æƒ…")
    
    # ç»Ÿè®¡ä¿¡æ¯
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        reduction_ratio = (original_segment_count - len(clustered_scenes)) / original_segment_count * 100
        st.metric("ç‰‡æ®µå‡å°‘", f"{reduction_ratio:.1f}%")
    with col2:
        avg_scene_duration = sum(s['duration'] for s in clustered_scenes) / len(clustered_scenes)
        st.metric("å¹³å‡åœºæ™¯æ—¶é•¿", f"{avg_scene_duration:.1f}s")
    with col3:
        total_segments_in_scenes = sum(s['segment_count'] for s in clustered_scenes)
        st.metric("åŒ…å«ç‰‡æ®µæ•°", total_segments_in_scenes)
    with col4:
        longest_scene = max(s['duration'] for s in clustered_scenes)
        st.metric("æœ€é•¿åœºæ™¯", f"{longest_scene:.1f}s")
    
    # è¯¦ç»†åœºæ™¯åˆ—è¡¨
    st.markdown("#### ðŸŽ­ èšåˆåŽçš„åœºæ™¯åˆ—è¡¨")
    
    scenes_data = []
    for scene in clustered_scenes:
        scenes_data.append({
            "åœºæ™¯": f"åœºæ™¯ {scene['index']}",
            "æ—¶é•¿": f"{scene['duration']:.1f}s",
            "åŒ…å«ç‰‡æ®µ": scene['segment_count'],
            "ç‰‡æ®µåˆ—è¡¨": ', '.join([f"ç‰‡æ®µ{i+1}" for i in range(scene['segment_count'])]),
            "è´¨é‡è¯„åˆ†": f"{scene.get('quality_score', 0.8):.2f}"
        })
    
    if scenes_data:
        import pandas as pd
        df_scenes = pd.DataFrame(scenes_data)
        st.dataframe(
            df_scenes,
            use_container_width=True,
            hide_index=True,
            column_config={
                "åœºæ™¯": st.column_config.TextColumn("åœºæ™¯", width="small"),
                "æ—¶é•¿": st.column_config.TextColumn("æ—¶é•¿", width="small"),
                "åŒ…å«ç‰‡æ®µ": st.column_config.NumberColumn("åŒ…å«ç‰‡æ®µ", width="small"),
                "ç‰‡æ®µåˆ—è¡¨": st.column_config.TextColumn("ç‰‡æ®µåˆ—è¡¨", width="large"),
                "è´¨é‡è¯„åˆ†": st.column_config.TextColumn("è´¨é‡è¯„åˆ†", width="small")
            }
        )

def auto_generate_clustered_scene_videos(clustered_scenes, video_id, segment_files):
    """è‡ªåŠ¨ç”Ÿæˆèšåˆåœºæ™¯è§†é¢‘å¹¶æ›¿æ¢åŽŸå§‹åˆ‡ç‰‡"""
    st.markdown("#### ðŸŽ¬ è‡ªåŠ¨ç”Ÿæˆèšåˆåœºæ™¯è§†é¢‘")
    
    try:
        # å‡†å¤‡è¾“å‡ºç›®å½•
        from pathlib import Path
        import shutil
        import os
        
        root_dir = Path(__file__).parent.parent.parent
        
        # ä¸´æ—¶èšç±»è¾“å‡ºç›®å½•
        temp_output_dir = root_dir / "data" / "results" / f"{video_id}_clustered_scenes"
        temp_output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŽŸå§‹åˆ‡åˆ†ç›®å½•
        original_dir = root_dir / "data" / "output" / "google_video" / str(video_id)
        
        created_videos = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # åˆ›å»ºç‰‡æ®µæ–‡ä»¶æ˜ å°„ï¼ˆæŒ‰æ–‡ä»¶åç´¢å¼•ï¼‰
        segment_file_map = {f.stem: f for f in segment_files}
        
        status_text.text("ðŸ”„ ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆèšç±»åœºæ™¯è§†é¢‘...")
        
        for i, scene in enumerate(clustered_scenes):
            try:
                status_text.text(f"æ­£åœ¨ç”Ÿæˆåœºæ™¯ {scene['index']}: {len(scene['segments'])} ä¸ªç‰‡æ®µ...")
                
                # æ”¶é›†åœºæ™¯ä¸­çš„æ‰€æœ‰ç‰‡æ®µæ–‡ä»¶
                scene_segment_files = []
                for segment in scene['segments']:
                    # ä»Žsegmentä¸­èŽ·å–æ–‡ä»¶è·¯å¾„
                    if 'file_path' in segment:
                        segment_file = Path(segment['file_path'])
                        if segment_file.exists():
                            scene_segment_files.append(segment_file)
                    elif 'file_name' in segment:
                        # å°è¯•ä»Žæ–‡ä»¶ååŒ¹é…
                        file_stem = Path(segment['file_name']).stem
                        if file_stem in segment_file_map:
                            scene_segment_files.append(segment_file_map[file_stem])
                
                if not scene_segment_files:
                    st.warning(f"âš ï¸ åœºæ™¯ {scene['index']} æ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„ç‰‡æ®µæ–‡ä»¶")
                    continue
                
                # ç”Ÿæˆåœºæ™¯è§†é¢‘æ–‡ä»¶å
                scene_filename = f"scene_{scene['index']:02d}_{len(scene_segment_files)}segments.mp4"
                scene_output_path = temp_output_dir / scene_filename
                
                # æ‰§è¡Œè§†é¢‘åˆå¹¶
                if len(scene_segment_files) == 1:
                    # å•ä¸ªç‰‡æ®µï¼Œç›´æŽ¥å¤åˆ¶
                    shutil.copy2(scene_segment_files[0], scene_output_path)
                    st.info(f"ðŸ“‹ åœºæ™¯ {scene['index']}: å•ç‰‡æ®µç›´æŽ¥å¤åˆ¶")
                else:
                    # å¤šä¸ªç‰‡æ®µï¼Œä½¿ç”¨FFmpegåˆå¹¶
                    success = merge_video_segments(scene_segment_files, scene_output_path)
                    if not success:
                        st.warning(f"âš ï¸ åœºæ™¯ {scene['index']} è§†é¢‘åˆå¹¶å¤±è´¥")
                        continue
                    st.info(f"ðŸ”— åœºæ™¯ {scene['index']}: {len(scene_segment_files)} ä¸ªç‰‡æ®µå·²åˆå¹¶")
                
                # è®°å½•åˆ›å»ºçš„è§†é¢‘ä¿¡æ¯
                scene_info = {
                    'scene_index': scene['index'],
                    'duration': scene['duration'],
                    'segment_count': len(scene_segment_files),
                    'output_path': str(scene_output_path),
                    'filename': scene_filename,
                    'file_size_mb': scene_output_path.stat().st_size / (1024*1024) if scene_output_path.exists() else 0
                }
                created_videos.append(scene_info)
                
                progress = (i + 1) / len(clustered_scenes) * 0.7  # 70%è¿›åº¦ç”¨äºŽç”Ÿæˆè§†é¢‘
                progress_bar.progress(progress)
                
            except Exception as e:
                st.warning(f"âš ï¸ åœºæ™¯ {scene['index']} è§†é¢‘ç”Ÿæˆå¤±è´¥: {str(e)}")
                continue
        
        if not created_videos:
            st.error("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•åœºæ™¯è§†é¢‘")
            return
        
        # ç¬¬äºŒæ­¥ï¼šæ›¿æ¢åŽŸå§‹æ–‡ä»¶
        status_text.text("ðŸ”„ ç¬¬äºŒæ­¥ï¼šå¤‡ä»½å¹¶æ›¿æ¢åŽŸå§‹åˆ‡ç‰‡æ–‡ä»¶...")
        progress_bar.progress(0.7)
        
        try:
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            backup_dir = original_dir.parent / f"{video_id}_backup_{int(time.time())}"
            backup_dir.mkdir(exist_ok=True)
            
            # å¤‡ä»½åŽŸå§‹æ–‡ä»¶
            original_files = list(original_dir.glob("*.mp4"))
            st.info(f"ðŸ“¦ å¤‡ä»½ {len(original_files)} ä¸ªåŽŸå§‹æ–‡ä»¶åˆ°: {backup_dir.name}")
            
            for file in original_files:
                shutil.copy2(file, backup_dir / file.name)
            
            progress_bar.progress(0.8)
            
            # åˆ é™¤åŽŸå§‹ç›®å½•ä¸­çš„mp4æ–‡ä»¶
            status_text.text("ðŸ—‘ï¸ æ¸…ç†åŽŸå§‹æ–‡ä»¶...")
            for file in original_files:
                file.unlink()
            
            progress_bar.progress(0.85)
            
            # ç§»åŠ¨èšç±»åŽçš„æ–‡ä»¶åˆ°åŽŸå§‹ç›®å½•
            status_text.text("ðŸ“ ç§»åŠ¨èšç±»æ–‡ä»¶åˆ°åŽŸå§‹ç›®å½•...")
            moved_count = 0
            
            for video_info in created_videos:
                source_file = Path(video_info['output_path'])
                target_file = original_dir / video_info['filename']
                
                if source_file.exists():
                    shutil.move(str(source_file), str(target_file))
                    moved_count += 1
            
            progress_bar.progress(0.95)
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            status_text.text("ðŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            if temp_output_dir.exists():
                shutil.rmtree(temp_output_dir)
            
            progress_bar.progress(1.0)
            status_text.text("âœ… åœºæ™¯èšåˆå’Œæ–‡ä»¶æ›¿æ¢å®Œæˆï¼")
            
            # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
            st.success(f"ðŸŽ‰ åœºæ™¯èšåˆå®Œæˆï¼åŽŸå§‹ {len(original_files)} ä¸ªç‰‡æ®µå·²è¢« {moved_count} ä¸ªèšç±»åœºæ™¯æ›¿æ¢")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                reduction_ratio = (len(original_files) - moved_count) / len(original_files) * 100
                st.metric("ç‰‡æ®µå‡å°‘", f"{reduction_ratio:.1f}%")
            with col2:
                total_size = sum(v['file_size_mb'] for v in created_videos)
                st.metric("æ–°ç‰‡æ®µæ€»å¤§å°", f"{total_size:.1f} MB")
            with col3:
                avg_duration = sum(v['duration'] for v in created_videos) / len(created_videos)
                st.metric("å¹³å‡åœºæ™¯æ—¶é•¿", f"{avg_duration:.1f}s")
            with col4:
                st.metric("å¤‡ä»½æ–‡ä»¶å¤¹", backup_dir.name[:15] + "...")
            
            # æ˜¾ç¤ºæ–‡ä»¶å˜åŒ–è¯¦æƒ…
            with st.expander("ðŸ“‹ æ–‡ä»¶æ›¿æ¢è¯¦æƒ…", expanded=True):
                st.write(f"**ðŸ“ ç›®æ ‡ç›®å½•**: `{original_dir}`")
                st.write(f"**ðŸ—‚ï¸ å¤‡ä»½ç›®å½•**: `{backup_dir}`")
                st.write(f"**ðŸ“¦ åŽŸå§‹æ–‡ä»¶**: {len(original_files)} ä¸ª")
                st.write(f"**ðŸŽ¬ æ–°åœºæ™¯æ–‡ä»¶**: {moved_count} ä¸ª")
                
                st.markdown("**ðŸŽ­ æ–°çš„åœºæ™¯æ–‡ä»¶åˆ—è¡¨:**")
                for video_info in created_videos:
                    st.write(f"- `{video_info['filename']}` ({video_info['file_size_mb']:.1f} MB, {video_info['duration']:.1f}s)")
            
            # å¿«é€Ÿè®¿é—®æŒ‰é’®
            if st.button("ðŸ“‚ æ‰“å¼€æ›´æ–°åŽçš„æ–‡ä»¶å¤¹", type="secondary", key="open_updated_folder"):
                import subprocess
                try:
                    subprocess.run(["open", str(original_dir)], check=False)
                    st.success("âœ… å·²æ‰“å¼€æ›´æ–°åŽçš„æ–‡ä»¶å¤¹")
                except Exception as e:
                    st.error(f"âŒ æ‰“å¼€æ–‡ä»¶å¤¹å¤±è´¥: {e}")
                    st.info(f"ðŸ“ æ–‡ä»¶å¤¹è·¯å¾„: {original_dir}")
            
        except Exception as e:
            st.error(f"âŒ æ–‡ä»¶æ›¿æ¢è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            st.warning("âš ï¸ èšç±»è§†é¢‘å·²ç”Ÿæˆï¼Œä½†æ–‡ä»¶æ›¿æ¢å¤±è´¥ã€‚è¯·æ‰‹åŠ¨å¤„ç†ã€‚")
            st.info(f"ðŸ“ èšç±»æ–‡ä»¶ä½ç½®: {temp_output_dir}")
            
    except Exception as e:
        st.error(f"âŒ ç”Ÿæˆèšåˆåœºæ™¯è§†é¢‘æ—¶å‡ºé”™: {str(e)}")
        import traceback
        st.code(traceback.format_exc(), language="python")

def merge_video_segments(segment_files, output_path):
    """ä½¿ç”¨FFmpegåˆå¹¶å¤šä¸ªè§†é¢‘ç‰‡æ®µ"""
    try:
        import subprocess
        import tempfile
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶åˆ—è¡¨
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for segment_file in segment_files:
                f.write(f"file '{segment_file.absolute()}'\n")
            temp_list_file = f.name
        
        # ä½¿ç”¨FFmpegåˆå¹¶
        ffmpeg_cmd = [
            'ffmpeg',
            '-f', 'concat',
            '-safe', '0',
            '-i', temp_list_file,
            '-c', 'copy',
            '-y',  # è¦†ç›–è¾“å‡ºæ–‡ä»¶
            str(output_path)
        ]
        
        result = subprocess.run(
            ffmpeg_cmd,
            capture_output=True,
            text=True,
            timeout=60  # 60ç§’è¶…æ—¶
        )
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        import os
        os.unlink(temp_list_file)
        
        if result.returncode == 0:
            return True
        else:
            logger.error(f"FFmpegåˆå¹¶å¤±è´¥: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        st.warning("âš ï¸ è§†é¢‘åˆå¹¶è¶…æ—¶")
        return False
    except FileNotFoundError:
        st.warning("âš ï¸ æœªæ‰¾åˆ°FFmpegï¼Œè¯·å®‰è£…FFmpeg")
        return False
    except Exception as e:
        logger.error(f"è§†é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    main() 