"""
Google Cloud Video Intelligence API æµ‹è¯•é¡µé¢

ç”¨äºæµ‹è¯• Google Cloud Video Intelligence API çš„åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- é•œå¤´åˆ‡åˆ†æ£€æµ‹
- è§†è§‰æ ‡ç­¾æ£€æµ‹
- æ–‡æœ¬æ£€æµ‹
- äººè„¸æ£€æµ‹ç­‰
"""

import streamlit as st
import os
import tempfile
import json
from pathlib import Path
import time

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
import sys
root_dir = Path(__file__).parent.parent.parent
if str(root_dir) not in sys.path:
    sys.path.insert(0, str(root_dir))

# æ ‡ç­¾ç¿»è¯‘å­—å…¸
LABEL_TRANSLATIONS = {
    # åŠ¨ç‰©ç±»
    "animal": "åŠ¨ç‰©",
    "cat": "çŒ«",
    "cats": "çŒ«",
    "kitten": "å°çŒ«",
    "kitty": "å°çŒ«",
    "tabby": "è™æ–‘çŒ«",
    "persian cat": "æ³¢æ–¯çŒ«",
    "maine coon": "ç¼…å› çŒ«",
    "siamese cat": "æš¹ç½—çŒ«",
    "whiskers": "èƒ¡é¡»",
    "paw": "çˆªå­",
    "tail": "å°¾å·´",
    "fur": "æ¯›å‘",
    "pet": "å® ç‰©",
    "pets": "å® ç‰©",
    "dog": "ç‹—",
    "puppy": "å°ç‹—",
    "bird": "é¸Ÿ",
    "fish": "é±¼",
    "horse": "é©¬",
    "cow": "ç‰›",
    "sheep": "ç¾Š",
    "pig": "çŒª",
    "chicken": "é¸¡",
    "duck": "é¸­",
    "rabbit": "å…”å­",
    "mouse": "è€é¼ ",
    "elephant": "å¤§è±¡",
    "lion": "ç‹®å­",
    "tiger": "è€è™",
    "bear": "ç†Š",
    "monkey": "çŒ´å­",
    "panda": "ç†ŠçŒ«",
    
    # å°ºå¯¸æè¿°
    "small": "å°",
    "medium": "ä¸­ç­‰",
    "large": "å¤§",
    "tiny": "å¾®å°",
    "huge": "å·¨å¤§",
    "sized": "å¤§å°çš„",
    "to": "åˆ°",
    
    # é£Ÿç‰©ç±»
    "food": "é£Ÿç‰©",
    "fruit": "æ°´æœ",
    "vegetable": "è”¬èœ",
    "meat": "è‚‰ç±»",
    "bread": "é¢åŒ…",
    "cake": "è›‹ç³•",
    "pizza": "æŠ«è¨",
    "hamburger": "æ±‰å ¡",
    "sandwich": "ä¸‰æ˜æ²»",
    "noodles": "é¢æ¡",
    "rice": "ç±³é¥­",
    "soup": "æ±¤",
    "salad": "æ²™æ‹‰",
    "coffee": "å’–å•¡",
    "tea": "èŒ¶",
    "milk": "ç‰›å¥¶",
    "formula": "å¥¶ç²‰",
    "baby formula": "å©´å„¿å¥¶ç²‰",
    "infant formula": "å©´å¹¼å„¿å¥¶ç²‰",
    "powder": "ç²‰æœ«",
    "bottle": "å¥¶ç“¶",
    "feeding bottle": "å¥¶ç“¶",
    "baby bottle": "å©´å„¿å¥¶ç“¶",
    "sippy cup": "å­¦é¥®æ¯",
    "pacifier": "å¥¶å˜´",
    "bib": "å›´å˜´",
    "high chair": "é«˜è„šæ¤…",
    "baby food": "å©´å„¿é£Ÿå“",
    "cereal": "ç±³ç²‰",
    "juice": "æœæ±",
    "water": "æ°´",
    "beer": "å•¤é…’",
    "wine": "é…’",
    
    # äº¤é€šå·¥å…·
    "car": "æ±½è½¦",
    "bus": "å…¬äº¤è½¦",
    "truck": "å¡è½¦",
    "motorcycle": "æ‘©æ‰˜è½¦",
    "bicycle": "è‡ªè¡Œè½¦",
    "train": "ç«è½¦",
    "airplane": "é£æœº",
    "boat": "èˆ¹",
    "ship": "è½®èˆ¹",
    "taxi": "å‡ºç§Ÿè½¦",
    
    # å»ºç­‘ç‰©å’Œåœºæ‰€
    "house": "æˆ¿å­",
    "home": "å®¶",
    "building": "å»ºç­‘ç‰©",
    "room": "æˆ¿é—´",
    "bedroom": "å§å®¤",
    "living room": "å®¢å…",
    "kitchen": "å¨æˆ¿",
    "bathroom": "æµ´å®¤",
    "nursery": "å©´å„¿æˆ¿",
    "playroom": "æ¸¸æˆå®¤",
    "park": "å…¬å›­",
    "playground": "æ¸¸ä¹åœº",
    "hospital": "åŒ»é™¢",
    "clinic": "è¯Šæ‰€",
    "daycare": "æ‰˜å„¿æ‰€",
    "kindergarten": "å¹¼å„¿å›­",
    "school": "å­¦æ ¡",
    "church": "æ•™å ‚",
    "bridge": "æ¡¥",
    "tower": "å¡”",
    "castle": "åŸå ¡",
    "temple": "å¯ºåº™",
    "museum": "åšç‰©é¦†",
    "store": "å•†åº—",
    "supermarket": "è¶…å¸‚",
    "mall": "å•†åœº",
    
    # è‡ªç„¶æ™¯è§‚
    "tree": "æ ‘",
    "flower": "èŠ±",
    "grass": "è‰",
    "mountain": "å±±",
    "river": "æ²³",
    "lake": "æ¹–",
    "sea": "æµ·",
    "beach": "æµ·æ»©",
    "forest": "æ£®æ—",
    "sky": "å¤©ç©º",
    "cloud": "äº‘",
    "sun": "å¤ªé˜³",
    "moon": "æœˆäº®",
    "star": "æ˜Ÿæ˜Ÿ",
    "snow": "é›ª",
    "rain": "é›¨",
    
    # äººç‰©ç›¸å…³
    "person": "äºº",
    "people": "äººä»¬",
    "man": "ç”·äºº",
    "woman": "å¥³äºº",
    "child": "å­©å­",
    "children": "å­©å­ä»¬",
    "baby": "å©´å„¿",
    "babies": "å©´å„¿ä»¬",
    "infant": "å©´å¹¼å„¿",
    "toddler": "å¹¼å„¿",
    "boy": "ç”·å­©",
    "girl": "å¥³å­©",
    "kid": "å°å­©",
    "kids": "å°å­©ä»¬",
    "mother": "å¦ˆå¦ˆ",
    "mom": "å¦ˆå¦ˆ",
    "father": "çˆ¸çˆ¸",
    "dad": "çˆ¸çˆ¸",
    "parent": "çˆ¶æ¯",
    "parents": "çˆ¶æ¯",
    "family": "å®¶åº­",
    "face": "è„¸",
    "hand": "æ‰‹",
    "hands": "æ‰‹",
    "eye": "çœ¼ç›",
    "eyes": "çœ¼ç›",
    "hair": "å¤´å‘",
    "smile": "å¾®ç¬‘",
    "smiling": "å¾®ç¬‘",
    "crying": "å“­æ³£",
    "laughing": "å¤§ç¬‘",
    
    # ç‰©å“
    "book": "ä¹¦",
    "toy": "ç©å…·",
    "toys": "ç©å…·",
    "doll": "å¨ƒå¨ƒ",
    "teddy bear": "æ³°è¿ªç†Š",
    "stuffed animal": "æ¯›ç»’ç©å…·",
    "ball": "çƒ",
    "blocks": "ç§¯æœ¨",
    "puzzle": "æ‹¼å›¾",
    "stroller": "å©´å„¿è½¦",
    "pram": "å©´å„¿è½¦",
    "car seat": "å®‰å…¨åº§æ¤…",
    "crib": "å©´å„¿åºŠ",
    "cradle": "æ‘‡ç¯®",
    "diaper": "å°¿å¸ƒ",
    "nappy": "å°¿å¸ƒ",
    "baby carrier": "å©´å„¿èƒŒå¸¦",
    "baby monitor": "å©´å„¿ç›‘è§†å™¨",
    "phone": "æ‰‹æœº",
    "computer": "ç”µè„‘",
    "television": "ç”µè§†",
    "camera": "ç›¸æœº",
    "clock": "æ—¶é’Ÿ",
    "chair": "æ¤…å­",
    "table": "æ¡Œå­",
    "bed": "åºŠ",
    "door": "é—¨",
    "window": "çª—æˆ·",
    "bag": "åŒ…",
    "diaper bag": "å¦ˆå’ªåŒ…",
    "shoes": "é‹å­",
    "clothes": "è¡£æœ",
    "baby clothes": "å©´å„¿æœè£…",
    "onesie": "è¿ä½“è¡£",
    "hat": "å¸½å­",
    "glasses": "çœ¼é•œ",
    
    # é¢œè‰²
    "red": "çº¢è‰²",
    "blue": "è“è‰²",
    "green": "ç»¿è‰²",
    "yellow": "é»„è‰²",
    "black": "é»‘è‰²",
    "white": "ç™½è‰²",
    "orange": "æ©™è‰²",
    "purple": "ç´«è‰²",
    "pink": "ç²‰è‰²",
    "brown": "æ£•è‰²",
    "gray": "ç°è‰²",
    
    # æ´»åŠ¨
    "running": "è·‘æ­¥",
    "walking": "èµ°è·¯",
    "jumping": "è·³è·ƒ",
    "swimming": "æ¸¸æ³³",
    "dancing": "è·³èˆ",
    "singing": "å”±æ­Œ",
    "playing": "ç©è€",
    "eating": "åƒ",
    "drinking": "å–",
    "feeding": "å–‚é£Ÿ",
    "breastfeeding": "æ¯ä¹³å–‚å…»",
    "bottle feeding": "å¥¶ç“¶å–‚å…»",
    "sleeping": "ç¡è§‰",
    "napping": "å°æ†©",
    "crawling": "çˆ¬è¡Œ",
    "sitting": "åç€",
    "standing": "ç«™ç«‹",
    "walking": "èµ°è·¯",
    "talking": "è¯´è¯",
    "babbling": "å’¿å‘€å­¦è¯­",
    "crying": "å“­æ³£",
    "laughing": "å¤§ç¬‘",
    "giggling": "å’¯å’¯ç¬‘",
    "hugging": "æ‹¥æŠ±",
    "kissing": "äº²å»",
    "cuddling": "æ‹¥æŠ±",
    "bathing": "æ´—æ¾¡",
    "changing": "æ¢å°¿å¸ƒ",
    "reading": "é˜…è¯»",
    "writing": "å†™ä½œ",
    "cooking": "çƒ¹é¥ª",
    "driving": "å¼€è½¦",
    "flying": "é£è¡Œ",
    
    # å…¶ä»–å¸¸è§è¯æ±‡
    "indoor": "å®¤å†…",
    "outdoor": "æˆ·å¤–",
    "day": "ç™½å¤©",
    "night": "å¤œæ™š",
    "morning": "æ—©æ™¨",
    "evening": "å‚æ™š",
    "summer": "å¤å¤©",
    "winter": "å†¬å¤©",
    "spring": "æ˜¥å¤©",
    "autumn": "ç§‹å¤©",
    "hot": "çƒ­",
    "cold": "å†·",
    "warm": "æ¸©æš–",
    "cool": "å‡‰çˆ½",
    "big": "å¤§",
    "small": "å°",
    "tall": "é«˜",
    "short": "çŸ­",
    "long": "é•¿",
    "wide": "å®½",
    "narrow": "çª„",
    "thick": "åš",
    "thin": "è–„",
    "heavy": "é‡",
    "light": "è½»",
    "fast": "å¿«",
    "slow": "æ…¢",
    "new": "æ–°",
    "old": "æ—§",
    "young": "å¹´è½»",
    "beautiful": "ç¾ä¸½",
    "ugly": "ä¸‘é™‹",
    "good": "å¥½",
    "bad": "å",
    "happy": "å¿«ä¹",
    "sad": "æ‚²ä¼¤",
    "angry": "æ„¤æ€’",
    "surprised": "æƒŠè®¶",
    "excited": "å…´å¥‹",
    "tired": "ç–²å€¦",
    "hungry": "é¥¥é¥¿",
    "thirsty": "å£æ¸´",
    
    # å¹¿å‘Šå’Œå“ç‰Œç›¸å…³
    "advertisement": "å¹¿å‘Š",
    "commercial": "å•†ä¸šå¹¿å‘Š",
    "brand": "å“ç‰Œ",
    "logo": "æ ‡å¿—",
    "product": "äº§å“",
    "package": "åŒ…è£…",
    "packaging": "åŒ…è£…",
    "label": "æ ‡ç­¾",
    "text": "æ–‡å­—",
    "banner": "æ¨ªå¹…",
    "poster": "æµ·æŠ¥",
    "sign": "æ ‡è¯†",
    "nutrition": "è¥å…»",
    "healthy": "å¥åº·",
    "organic": "æœ‰æœº",
    "natural": "å¤©ç„¶",
    "premium": "é«˜ç«¯",
    "quality": "è´¨é‡",
    
    # è§†é¢‘åˆ¶ä½œç›¸å…³
    "video": "è§†é¢‘",
    "vlog": "è§†é¢‘åšå®¢",
    "recording": "å½•åˆ¶",
    "filming": "æ‹æ‘„",
    "camera": "æ‘„åƒæœº",
    "microphone": "éº¦å…‹é£",
    "lighting": "ç¯å…‰",
    "studio": "å·¥ä½œå®¤",
    "background": "èƒŒæ™¯",
    "scene": "åœºæ™¯",
    "shot": "é•œå¤´",
    "close up": "ç‰¹å†™",
    "wide shot": "è¿œæ™¯",
    
    # æƒ…æ„Ÿå’Œè¡¨æƒ…
    "emotion": "æƒ…æ„Ÿ",
    "expression": "è¡¨æƒ…",
    "joy": "å–œæ‚¦",
    "love": "çˆ±",
    "care": "å…³çˆ±",
    "gentle": "æ¸©æŸ”",
    "peaceful": "å¹³é™",
    "comfortable": "èˆ’é€‚",
    "safe": "å®‰å…¨",
    "trust": "ä¿¡ä»»"
}

def translate_label_to_chinese(english_label, use_deepseek=False):
    """å°†è‹±æ–‡æ ‡ç­¾ç¿»è¯‘æˆä¸­æ–‡"""
    # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
    label_lower = english_label.lower().strip()
    
    # ç›´æ¥åŒ¹é…æœ¬åœ°å­—å…¸
    if label_lower in LABEL_TRANSLATIONS:
        return LABEL_TRANSLATIONS[label_lower]
    
    # å°è¯•åŒ¹é…å¤åˆè¯ï¼ˆç”¨ç©ºæ ¼åˆ†éš”çš„è¯ï¼‰
    words = label_lower.split()
    if len(words) > 1:
        translated_words = []
        all_translated = True
        
        for word in words:
            if word in LABEL_TRANSLATIONS:
                translated_words.append(LABEL_TRANSLATIONS[word])
            else:
                # å¦‚æœæœ‰è¯æ²¡æœ‰ç¿»è¯‘ï¼Œä¿ç•™åŸè¯ä½†æ ‡è®°ä¸ºæœªå®Œå…¨ç¿»è¯‘
                translated_words.append(word)
                all_translated = False
        
        # å¦‚æœæ‰€æœ‰è¯éƒ½ç¿»è¯‘äº†ï¼Œè¿”å›ç¿»è¯‘ç»“æœ
        if all_translated:
            return "".join(translated_words)  # ä¸­æ–‡ä¸éœ€è¦ç©ºæ ¼
        
        # å¦‚æœéƒ¨åˆ†ç¿»è¯‘ä¸”å¯ç”¨DeepSeekï¼Œå°è¯•æ•´ä½“ç¿»è¯‘
        if use_deepseek and not all_translated:
            try:
                deepseek_translation = translate_with_deepseek(english_label)
                if deepseek_translation and deepseek_translation != english_label:
                    return deepseek_translation
            except Exception as e:
                pass
        
        # è¿”å›éƒ¨åˆ†ç¿»è¯‘ç»“æœ
        return "".join(translated_words)
    
    # å¦‚æœæœ¬åœ°å­—å…¸æ²¡æœ‰æ‰¾åˆ°ä¸”å¯ç”¨äº†DeepSeekç¿»è¯‘ï¼Œå°è¯•ä½¿ç”¨DeepSeekç¿»è¯‘
    if use_deepseek:
        try:
            deepseek_translation = translate_with_deepseek(english_label)
            if deepseek_translation and deepseek_translation != english_label:
                return deepseek_translation
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…åœ¨ç•Œé¢ä¸Šæ˜¾ç¤ºå¤ªå¤šè­¦å‘Š
            pass
    
    # å¦‚æœéƒ½æ²¡æœ‰æ‰¾åˆ°ç¿»è¯‘ï¼Œè¿”å›åŸæ–‡
    return english_label

def translate_with_deepseek(english_text):
    """ä½¿ç”¨DeepSeek APIç¿»è¯‘è‹±æ–‡æ ‡ç­¾åˆ°ä¸­æ–‡"""
    try:
        from streamlit_app.modules.ai_analyzers import DeepSeekAnalyzer
        
        # ä½¿ç”¨DeepSeekåˆ†æå™¨
        analyzer = DeepSeekAnalyzer()
        
        if not analyzer.is_available():
            return None
        
        # ç¿»è¯‘è‹±æ–‡æ ‡ç­¾
        translation = analyzer.translate_text(english_text, "ä¸­æ–‡")
        return translation
        
    except Exception as e:
        # é™é»˜å¤±è´¥ï¼Œè¿”å›Noneè®©è°ƒç”¨è€…å¤„ç†
        return None

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="Google Cloud è§†é¢‘æ™ºèƒ½æµ‹è¯•",
    page_icon="ğŸ”¬",
    layout="wide"
)

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'current_video_path' not in st.session_state:
    st.session_state.current_video_path = None
if 'current_video_id' not in st.session_state:
    st.session_state.current_video_id = None
if 'analysis_config' not in st.session_state:
    st.session_state.analysis_config = None

def check_credentials():
    """æ£€æŸ¥ Google Cloud å‡­æ®æ˜¯å¦å·²è®¾ç½®"""
    cred_path = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")
    if cred_path and os.path.exists(cred_path):
        return True, cred_path
    return False, None

def upload_credentials():
    """ä¸Šä¼  Google Cloud æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶"""
    st.subheader("ğŸ“ ä¸Šä¼ æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶")
    
    uploaded_file = st.file_uploader(
        "é€‰æ‹©æ‚¨çš„ Google Cloud æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶ (JSONæ ¼å¼)",
        type=['json'],
        help="ä» Google Cloud Console ä¸‹è½½çš„æœåŠ¡è´¦å·å¯†é’¥æ–‡ä»¶"
    )
    
    if uploaded_file is not None:
        try:
            # éªŒè¯JSONæ ¼å¼
            credentials_data = json.loads(uploaded_file.read())
            
            # æ£€æŸ¥å¿…è¦å­—æ®µ
            required_fields = ['type', 'project_id', 'private_key_id', 'private_key', 'client_email']
            missing_fields = [field for field in required_fields if field not in credentials_data]
            
            if missing_fields:
                st.error(f"å¯†é’¥æ–‡ä»¶ç¼ºå°‘å¿…è¦å­—æ®µ: {', '.join(missing_fields)}")
                return False
            
            # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = Path("temp")
            temp_dir.mkdir(exist_ok=True)
            
            cred_file_path = temp_dir / "google_credentials.json"
            with open(cred_file_path, 'w', encoding='utf-8') as f:
                json.dump(credentials_data, f, indent=2)
            
            # è®¾ç½®ç¯å¢ƒå˜é‡
            os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = str(cred_file_path)
            
            st.success(f"âœ… å‡­æ®æ–‡ä»¶å·²ä¸Šä¼ å¹¶è®¾ç½®ï¼é¡¹ç›®ID: {credentials_data.get('project_id', 'Unknown')}")
            st.info(f"å‡­æ®æ–‡ä»¶è·¯å¾„: {cred_file_path}")
            
            return True
            
        except json.JSONDecodeError:
            st.error("âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œè¯·ç¡®ä¿ä¸Šä¼ çš„æ˜¯æœ‰æ•ˆçš„JSONæ–‡ä»¶")
            return False
        except Exception as e:
            st.error(f"âŒ å¤„ç†å‡­æ®æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
            return False
    
    return False

def test_video_intelligence(use_deepseek_translation=False):
    """æµ‹è¯• Video Intelligence API"""
    try:
        from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
        
        st.subheader("ğŸ¬ è§†é¢‘åˆ†ææµ‹è¯•")
        
        # åˆ›å»ºGoogle Cloudåˆ†æå™¨
        analyzer = GoogleVideoAnalyzer()
        
        # æ£€æŸ¥å‡­æ®
        has_credentials, cred_path = analyzer.check_credentials()
        if not has_credentials:
            st.error("âŒ Google Cloudå‡­æ®æœªè®¾ç½®æˆ–æ— æ•ˆ")
            return
        
        st.success("âœ… Google Cloud Video Intelligence åˆ†æå™¨å‡†å¤‡å°±ç»ªï¼")
        
        # æ–‡ä»¶ä¸Šä¼ 
        st.markdown("### ğŸ“ é€‰æ‹©è§†é¢‘æ–‡ä»¶")
        
        # æ·»åŠ å¿«é€Ÿæµ‹è¯•é€‰é¡¹
        test_option = st.radio(
            "é€‰æ‹©æµ‹è¯•æ–¹å¼ï¼š",
            ["ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶", "ä½¿ç”¨ Google Cloud ç¤ºä¾‹è§†é¢‘ï¼ˆå¿«é€Ÿæµ‹è¯•ï¼‰"],
            help="ç¤ºä¾‹è§†é¢‘å¯ä»¥å¿«é€ŸéªŒè¯APIæ˜¯å¦æ­£å¸¸å·¥ä½œ"
        )
        
        uploaded_video = None
        use_sample_video = False
        
        if test_option == "ä¸Šä¼ æœ¬åœ°è§†é¢‘æ–‡ä»¶":
            uploaded_video = st.file_uploader(
                "é€‰æ‹©è¦åˆ†æçš„è§†é¢‘æ–‡ä»¶",
                type=['mp4', 'avi', 'mov', 'mkv', 'webm'],
                help="æ”¯æŒå¸¸è§çš„è§†é¢‘æ ¼å¼ï¼Œå»ºè®®æ–‡ä»¶å¤§å°ä¸è¶…è¿‡50MBä»¥è·å¾—æ›´å¿«çš„å¤„ç†é€Ÿåº¦"
            )
        else:
            use_sample_video = True
            st.info("ğŸš€ å°†ä½¿ç”¨ Google Cloud å…¬å¼€ç¤ºä¾‹è§†é¢‘è¿›è¡Œå¿«é€Ÿæµ‹è¯•")
            st.markdown("ç¤ºä¾‹è§†é¢‘: `gs://cloud-samples-data/video/cat.mp4`")
        
        if uploaded_video is not None or use_sample_video:
            if uploaded_video is not None:
                # æ˜¾ç¤ºè§†é¢‘ä¿¡æ¯
                st.write(f"**æ–‡ä»¶å:** {uploaded_video.name}")
                st.write(f"**æ–‡ä»¶å¤§å°:** {uploaded_video.size / (1024*1024):.2f} MB")
            else:
                st.write("**ä½¿ç”¨ç¤ºä¾‹è§†é¢‘:** cat.mp4")
                st.write("**æ–‡ä»¶å¤§å°:** ~1.5 MB")
            
            # é€‰æ‹©åˆ†æåŠŸèƒ½
            st.subheader("ğŸ”§ é€‰æ‹©åˆ†æåŠŸèƒ½")
            
            col1, col2 = st.columns(2)
            
            with col1:
                shot_detection = st.checkbox("é•œå¤´åˆ‡åˆ†æ£€æµ‹", value=True, help="æ£€æµ‹è§†é¢‘ä¸­çš„é•œå¤´å˜åŒ–")
                label_detection = st.checkbox("æ ‡ç­¾æ£€æµ‹", value=True, help="è¯†åˆ«è§†é¢‘ä¸­çš„ç‰©ä½“ã€åœºæ™¯ç­‰")
                text_detection = st.checkbox("æ–‡æœ¬æ£€æµ‹", help="æ£€æµ‹è§†é¢‘ä¸­çš„æ–‡å­—å†…å®¹")
                
            with col2:
                face_detection = st.checkbox("äººè„¸æ£€æµ‹", help="æ£€æµ‹è§†é¢‘ä¸­çš„äººè„¸")
                object_tracking = st.checkbox("ç‰©ä½“è·Ÿè¸ª", help="è·Ÿè¸ªè§†é¢‘ä¸­çš„ç‰¹å®šç‰©ä½“")
            
            # å¼€å§‹åˆ†ææŒ‰é’®
            if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
                if not any([shot_detection, label_detection, text_detection, face_detection, object_tracking]):
                    st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æåŠŸèƒ½ï¼")
                    return
                
                try:
                    # å‡†å¤‡åˆ†æå‚æ•°
                    features = []
                    if shot_detection:
                        features.append("shot_detection")
                    if label_detection:
                        features.append("label_detection")
                    if text_detection:
                        features.append("text_detection")
                    if face_detection:
                        features.append("face_detection")
                    if object_tracking:
                        features.append("object_tracking")
                    
                    # è®¾ç½®è¿›åº¦å›è°ƒ
                    progress_bar = st.progress(0)
                    status_text = st.empty()
                    
                    def progress_callback(progress, message):
                        progress_bar.progress(progress)
                        status_text.text(message)
                    
                    # æ‰§è¡Œåˆ†æ
                    if use_sample_video:
                        # ä½¿ç”¨ç¤ºä¾‹è§†é¢‘URI
                        video_uri = "gs://cloud-samples-data/video/cat.mp4"
                        st.info("ğŸ“¡ ä½¿ç”¨äº‘ç«¯ç¤ºä¾‹è§†é¢‘è¿›è¡Œåˆ†æ")
                        
                        analysis_result = analyzer.analyze_video(
                            video_uri=video_uri,
                            features=features,
                            progress_callback=progress_callback
                        )
                        
                        current_video_path = None  # ç¤ºä¾‹è§†é¢‘æ— æ³•ç›´æ¥åˆ‡åˆ†
                        current_video_id = "google_sample_cat"
                    else:
                        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶
                        from pathlib import Path
                        temp_dir = Path("data/temp/google_cloud")
                        temp_dir.mkdir(parents=True, exist_ok=True)
                        
                        video_filename = uploaded_video.name
                        video_path = temp_dir / video_filename
                        
                        with open(video_path, "wb") as f:
                            f.write(uploaded_video.read())
                        
                        current_video_path = str(video_path)
                        current_video_id = os.path.splitext(video_filename)[0]
                        
                        st.info(f"ğŸ“Š æ­£åœ¨åˆ†æ {len(features)} ä¸ªåŠŸèƒ½ï¼Œè§†é¢‘å¤§å°: {uploaded_video.size/(1024*1024):.1f}MB")
                        
                        analysis_result = analyzer.analyze_video(
                            video_path=current_video_path,
                            features=features,
                            progress_callback=progress_callback
                        )
                    
                    if analysis_result.get("success"):
                        result = analysis_result["result"]
                        
                        # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                        st.session_state.analysis_result = result
                        st.session_state.current_video_path = current_video_path
                        st.session_state.current_video_id = current_video_id
                        st.session_state.analysis_config = {
                            'shot_detection': shot_detection,
                            'label_detection': label_detection,
                            'text_detection': text_detection,
                            'face_detection': face_detection,
                            'object_tracking': object_tracking,
                            'use_deepseek_translation': use_deepseek_translation
                        }
                        
                        # æ˜¾ç¤ºç»“æœ
                        display_results(result, shot_detection, label_detection, text_detection, face_detection, object_tracking, use_deepseek_translation, current_video_path, current_video_id)
                    else:
                        st.error(f"âŒ åˆ†æå¤±è´¥: {analysis_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    
                except Exception as e:
                    st.error(f"âŒ è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
                    st.info("è¯·æ£€æŸ¥ï¼š\n1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\n2. Google Cloud å‡­æ®æ˜¯å¦æœ‰æ•ˆ\n3. æ˜¯å¦å·²å¯ç”¨ Video Intelligence API\n4. è§†é¢‘æ–‡ä»¶æ˜¯å¦æŸå")
                
                finally:
                    # æ³¨æ„ï¼šä¸è¦ç«‹å³åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œå› ä¸ºåç»­çš„åˆ‡åˆ†åŠŸèƒ½éœ€è¦ä½¿ç”¨
                    # ä¸´æ—¶æ–‡ä»¶å°†åœ¨ç”¨æˆ·ç¦»å¼€é¡µé¢æˆ–é‡æ–°ä¸Šä¼ æ—¶è‡ªåŠ¨æ¸…ç†
                    pass
        
    except ImportError as e:
        st.error("âŒ å¯¼å…¥Google Cloud Video Intelligenceæ¨¡å—æ—¶å‡ºé”™")
        st.error(f"é”™è¯¯è¯¦æƒ…: {str(e)}")
        
        # è°ƒè¯•ä¿¡æ¯
        import sys
        st.info("è°ƒè¯•ä¿¡æ¯:")
        st.write(f"- Pythonè·¯å¾„: {sys.executable}")
        st.write(f"- Pythonç‰ˆæœ¬: {sys.version}")
        st.write(f"- GOOGLE_APPLICATION_CREDENTIALS: {os.environ.get('GOOGLE_APPLICATION_CREDENTIALS', 'æœªè®¾ç½®')}")
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯åº“æœªå®‰è£…
        try:
            import google.cloud.videointelligence_v1
            st.success("âœ… google-cloud-videointelligence åº“å·²å®‰è£…")
            st.error("âŒ ä½†æ˜¯GoogleVideoAnalyzeræ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œå¯èƒ½æ˜¯æ¨¡å—å†…éƒ¨é”™è¯¯")
        except ImportError:
            st.error("âŒ æœªå®‰è£… google-cloud-videointelligence åº“")
            st.info("è¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤å®‰è£…ï¼š\n```bash\npip install google-cloud-videointelligence\n```")

def get_time_seconds(time_offset):
    """å®‰å…¨åœ°è·å–æ—¶é—´åç§»çš„ç§’æ•°"""
    try:
        if hasattr(time_offset, 'total_seconds'):
            return time_offset.total_seconds()
        elif hasattr(time_offset, 'seconds'):
            # å¤„ç† protobuf Duration å¯¹è±¡
            return time_offset.seconds + time_offset.nanos / 1e9
        else:
            # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥è¿”å›
            return float(time_offset)
    except Exception as e:
        st.warning(f"æ—¶é—´è§£æé”™è¯¯: {e}")
        return 0.0





def create_video_segments(video_path, segments_data, video_id):
    """
    æ ¹æ®åˆ†æç»“æœåˆ›å»ºè§†é¢‘ç‰‡æ®µ
    
    Args:
        video_path: åŸå§‹è§†é¢‘è·¯å¾„
        segments_data: ç‰‡æ®µæ•°æ®åˆ—è¡¨
        video_id: è§†é¢‘ID
    
    Returns:
        æˆåŠŸåˆ›å»ºçš„ç‰‡æ®µåˆ—è¡¨
    """
    try:
        # è°ƒè¯•ä¿¡æ¯
        st.info(f"ğŸ” è°ƒè¯•ä¿¡æ¯:")
        st.write(f"- è§†é¢‘è·¯å¾„: {video_path}")
        st.write(f"- è§†é¢‘ID: {video_id}")
        st.write(f"- ç‰‡æ®µæ•°é‡: {len(segments_data)}")
        st.write(f"- è§†é¢‘æ–‡ä»¶å­˜åœ¨: {os.path.exists(video_path) if video_path else 'N/A'}")
        
        if not video_path:
            st.error("âŒ è§†é¢‘è·¯å¾„ä¸ºç©ºï¼Œæ— æ³•è¿›è¡Œåˆ‡åˆ†")
            return []
        
        if not os.path.exists(video_path):
            st.error(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return []
            
        # åˆ›å»ºè¾“å‡ºç›®å½•
        from pathlib import Path
        root_dir = Path(__file__).parent.parent.parent
        output_dir = root_dir / "data" / "output" / "google_video"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # å¯¼å…¥è§†é¢‘å¤„ç†å™¨
        import sys
        sys.path.append(str(root_dir))
        from src.core.utils.video_processor import VideoProcessor
        
        processor = VideoProcessor()
        created_segments = []
        
        # æ˜¾ç¤ºè¿›åº¦æ¡
        st.info("ğŸ¬ æ­£åœ¨åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ...")
        progress_bar = st.progress(0)
        
        for i, segment in enumerate(segments_data):
            try:
                start_time = segment['start_time']
                end_time = segment['end_time']
                segment_type = segment['type']
                confidence = segment.get('confidence', 1.0)
                
                # ç¡®ä¿æ—¶é—´æœ‰æ•ˆ
                if start_time >= end_time or end_time - start_time < 0.5:
                    st.warning(f"è·³è¿‡æ— æ•ˆç‰‡æ®µ {i+1}: æ—¶é—´èŒƒå›´ {start_time:.2f}s - {end_time:.2f}s")
                    continue
                
                # ä½¿ç”¨VideoProcessoræå–ç‰‡æ®µ
                extracted_path = processor.extract_segment(
                    video_path=video_path,
                    start_time=start_time,
                    end_time=end_time,
                    segment_index=i,
                    semantic_type=segment_type,
                    video_id=video_id,
                    output_dir=str(output_dir)
                )
                
                if extracted_path and os.path.exists(extracted_path):
                    created_segments.append({
                        'index': i + 1,
                        'type': segment_type,
                        'start_time': start_time,
                        'end_time': end_time,
                        'duration': end_time - start_time,
                        'confidence': confidence,
                        'file_path': extracted_path,
                        'file_size': os.path.getsize(extracted_path) / (1024*1024)  # MB
                    })
                    
                    st.success(f"âœ… ç‰‡æ®µ {i+1}: {segment_type} ({start_time:.1f}s-{end_time:.1f}s)")
                else:
                    st.error(f"âŒ ç‰‡æ®µ {i+1} åˆ›å»ºå¤±è´¥")
                
                # æ›´æ–°è¿›åº¦
                progress = (i + 1) / len(segments_data)
                progress_bar.progress(progress)
                    
            except Exception as e:
                st.error(f"âŒ å¤„ç†ç‰‡æ®µ {i+1} æ—¶å‡ºé”™: {str(e)}")
                continue
        
        progress_bar.progress(1.0)
        st.success(f"âœ… è§†é¢‘åˆ‡åˆ†å®Œæˆï¼šæˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªè§†é¢‘ç‰‡æ®µ")
        
        return created_segments
        
    except Exception as e:
        st.error(f"åˆ›å»ºè§†é¢‘ç‰‡æ®µæ—¶å‡ºé”™: {str(e)}")
        return []

def display_results(result, shot_detection, label_detection, text_detection, face_detection, object_tracking, use_deepseek_translation=False, video_path=None, video_id=None):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.subheader("ğŸ“Š åˆ†æç»“æœ")
    
    if not result.annotation_results:
        st.warning("æ²¡æœ‰è·å¾—åˆ†æç»“æœ")
        return
    
    annotation = result.annotation_results[0]
    
    # åˆ›å»ºGoogle Videoåˆ†æå™¨å®ä¾‹ç”¨äºæ•°æ®æå–
    from streamlit_app.modules.ai_analyzers import GoogleVideoAnalyzer
    google_analyzer = GoogleVideoAnalyzer()
    
    # é•œå¤´åˆ‡åˆ†ç»“æœ
    if shot_detection and annotation.shot_annotations:
        st.subheader("ğŸ¬ é•œå¤´åˆ‡åˆ†ç»“æœ")
        
        # æ˜¾ç¤ºåŸå§‹é•œå¤´ç»Ÿè®¡
        total_shots = len(annotation.shot_annotations)
        durations = []
        shot_times = []
        
        for shot in annotation.shot_annotations:
            start_time = get_time_seconds(shot.start_time_offset)
            end_time = get_time_seconds(shot.end_time_offset)
            durations.append(end_time - start_time)
            shot_times.append((start_time, end_time))
        
        avg_duration = sum(durations) / len(durations) if durations else 0
        min_duration = min(durations) if durations else 0
        max_duration = max(durations) if durations else 0
        
        # ä½¿ç”¨åˆ†æå™¨æå–é•œå¤´ä¿¡æ¯
        mock_result = {"success": True, "result": result}
        shots = google_analyzer.extract_shots(mock_result)
        
        # éªŒè¯é•œå¤´è¿è´¯æ€§
        continuity = google_analyzer.validate_shot_continuity(shots)
        
        # ä½¿ç”¨åˆ†æå™¨çš„è¿è´¯æ€§éªŒè¯ç»“æœ
        gaps = continuity["gaps"]
        overlaps = continuity["overlaps"]
        total_video_duration = continuity["total_duration"]
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("é•œå¤´æ€»æ•°", total_shots)
        with col2:
            st.metric("å¹³å‡æ—¶é•¿", f"{avg_duration:.1f}s")
        with col3:
            st.metric("æœ€çŸ­æ—¶é•¿", f"{min_duration:.1f}s")
        with col4:
            st.metric("æœ€é•¿æ—¶é•¿", f"{max_duration:.1f}s")
        
        # æ˜¾ç¤ºè¿è´¯æ€§æ£€æŸ¥ç»“æœ
        st.markdown("### ğŸ” é•œå¤´è¿è´¯æ€§æ£€æŸ¥")
        
        if not gaps and not overlaps:
            st.success("âœ… æ‰€æœ‰é•œå¤´æ—¶é—´å®Œå…¨è¿è´¯ï¼Œæ— ç©ºéš™æˆ–é‡å ")
            col1, col2 = st.columns(2)
            with col1:
                st.metric("è§†é¢‘æ€»æ—¶é•¿", f"{total_video_duration:.2f}s")
            with col2:
                total_cuts_duration = sum(durations)
                st.metric("é•œå¤´æ€»æ—¶é•¿", f"{total_cuts_duration:.2f}s")
                if abs(total_video_duration - total_cuts_duration) < 0.1:
                    st.success("âœ… æ—¶é•¿åŒ¹é…å®Œç¾")
        else:
            if gaps:
                st.warning("âš ï¸ å‘ç°æ—¶é—´ç©ºéš™:")
                for gap in gaps:
                    st.write(f"  - {gap}")
            
            if overlaps:
                st.error("âŒ å‘ç°æ—¶é—´é‡å :")
                for overlap in overlaps:
                    st.write(f"  - {overlap}")
            
            st.info("ğŸ’¡ æ³¨æ„ï¼šå°‘é‡è¯¯å·®ï¼ˆ<0.1ç§’ï¼‰æ˜¯æ­£å¸¸çš„ï¼Œå¯èƒ½ç”±äºæ—¶é—´ç²¾åº¦é€ æˆ")
        
        # å‡†å¤‡è¡¨æ ¼æ•°æ®
        shots_data = []
        segments_for_cutting = []
        
        for shot in shots:
            shots_data.append({
                "é•œå¤´": f"é•œå¤´ {shot['index']}",
                "å¼€å§‹æ—¶é—´ (ç§’)": f"{shot['start_time']:.2f}",
                "ç»“æŸæ—¶é—´ (ç§’)": f"{shot['end_time']:.2f}",
                "æŒç»­æ—¶é—´ (ç§’)": f"{shot['duration']:.2f}"
            })
            
            segments_for_cutting.append({
                'start_time': shot['start_time'],
                'end_time': shot['end_time'],
                'type': shot['type'],
                'confidence': shot['confidence']
            })
        
        if shots_data:
            import pandas as pd
            df = pd.DataFrame(shots_data)
            st.dataframe(
                df, 
                use_container_width=True,
                hide_index=True,
                column_config={
                    "é•œå¤´": st.column_config.TextColumn("é•œå¤´", width="small"),
                    "å¼€å§‹æ—¶é—´ (ç§’)": st.column_config.NumberColumn("å¼€å§‹æ—¶é—´ (ç§’)", width="medium"),
                    "ç»“æŸæ—¶é—´ (ç§’)": st.column_config.NumberColumn("ç»“æŸæ—¶é—´ (ç§’)", width="medium"),
                    "æŒç»­æ—¶é—´ (ç§’)": st.column_config.NumberColumn("æŒç»­æ—¶é—´ (ç§’)", width="medium")
                }
            )
            
                        # æ·»åŠ è§†é¢‘åˆ‡åˆ†åŠŸèƒ½
            if video_path and video_id and segments_for_cutting:
                st.markdown("### ğŸ¬ è§†é¢‘ç‰‡æ®µåˆ‡åˆ†")
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.info(f"å°†æ ¹æ® {len(segments_for_cutting)} ä¸ªé•œå¤´åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ")
                with col2:
                    if st.button("ğŸ”ª å¼€å§‹åˆ‡åˆ†", type="primary"):
                        with st.spinner("æ­£åœ¨åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ..."):
                            created_segments = create_video_segments(
                                video_path, segments_for_cutting, video_id
                            )
                            
                            if created_segments:
                                st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªé•œå¤´ç‰‡æ®µ")
                                
                                # æ˜¾ç¤ºåˆ›å»ºçš„ç‰‡æ®µä¿¡æ¯
                                with st.expander("ğŸ“ æŸ¥çœ‹åˆ›å»ºçš„ç‰‡æ®µ", expanded=True):
                                    for segment in created_segments:
                                        col1, col2, col3 = st.columns([2, 1, 1])
                                        
                                        with col1:
                                            st.write(f"**ç‰‡æ®µ {segment['index']}**: {segment['type']}")
                                            st.write(f"æ—¶é—´: {segment['start_time']:.1f}s - {segment['end_time']:.1f}s")
                                        
                                        with col2:
                                            st.write(f"ğŸ“ {segment['file_size']:.1f}MB")
                                        
                                        with col3:
                                            if st.button(f"ğŸ“‚ æ‰“å¼€", key=f"open_shot_{segment['index']}"):
                                                import subprocess
                                                subprocess.run(["open", "-R", segment['file_path']], check=False)
                            else:
                                st.error("âŒ è§†é¢‘ç‰‡æ®µåˆ›å»ºå¤±è´¥")
    
    # æ ‡ç­¾æ£€æµ‹ç»“æœ
    if label_detection and annotation.segment_label_annotations:
        st.subheader("ğŸ·ï¸ æ ‡ç­¾æ£€æµ‹ç»“æœ")
        
        try:
            # ä½¿ç”¨åˆ†æå™¨æå–æ ‡ç­¾ä¿¡æ¯
            mock_result = {"success": True, "result": result}
            labels = google_analyzer.extract_labels(mock_result)
            
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            label_data = []
            
            # ç¿»è¯‘çŠ¶æ€ç»Ÿè®¡
            local_translated = 0
            deepseek_translated = 0
            
            for label in labels[:20]:  # æ˜¾ç¤ºå‰20ä¸ªæ ‡ç­¾
                label_name = label['label']
                
                # å…ˆå°è¯•æœ¬åœ°ç¿»è¯‘
                local_translation = translate_label_to_chinese(label_name, use_deepseek=False)
                if local_translation != label_name:
                    label_name_cn = local_translation
                    local_translated += 1
                elif use_deepseek_translation:
                    # ä½¿ç”¨DeepSeekç¿»è¯‘
                    deepseek_translation = translate_with_deepseek(label_name)
                    if deepseek_translation and deepseek_translation != label_name:
                        label_name_cn = deepseek_translation
                        deepseek_translated += 1
                    else:
                        label_name_cn = label_name
                else:
                    label_name_cn = label_name
                
                # æ ¼å¼åŒ–æ—¶é—´æ˜¾ç¤º
                start_time = label['start_time']
                end_time = label['end_time']
                confidence = label['confidence']
                
                start_min = int(start_time // 60)
                start_sec = int(start_time % 60)
                end_min = int(end_time // 60)
                end_sec = int(end_time % 60)
                
                time_range = f"{start_min:02d}:{start_sec:02d} - {end_min:02d}:{end_sec:02d}"
                
                label_data.append({
                    "æ ‡ç­¾": label_name_cn,
                    "æ—¶é—´æ®µ": time_range,
                    "ç½®ä¿¡åº¦": f"{confidence:.2f}"
                })
            
            if label_data:
                # æ˜¾ç¤ºä¸ºè¡¨æ ¼
                import pandas as pd
                df = pd.DataFrame(label_data)
                
                # è®¾ç½®è¡¨æ ¼æ ·å¼
                st.dataframe(
                    df, 
                    use_container_width=True, 
                    hide_index=True,
                    column_config={
                        "æ ‡ç­¾": st.column_config.TextColumn(
                            "æ ‡ç­¾",
                            help="æ£€æµ‹åˆ°çš„ç‰©ä½“æˆ–åœºæ™¯æ ‡ç­¾",
                            width="medium"
                        ),
                        "æ—¶é—´æ®µ": st.column_config.TextColumn(
                            "æ—¶é—´æ®µ",
                            help="æ ‡ç­¾å‡ºç°çš„æ—¶é—´èŒƒå›´",
                            width="medium"
                        ),
                        "ç½®ä¿¡åº¦": st.column_config.NumberColumn(
                            "ç½®ä¿¡åº¦",
                            help="AIè¯†åˆ«çš„ç½®ä¿¡åº¦ï¼ˆ0-1ä¹‹é—´ï¼‰",
                            width="small",
                            format="%.2f"
                        )
                    }
                )
                
                # ç»Ÿè®¡ä¿¡æ¯
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("æ£€æµ‹åˆ°çš„æ ‡ç­¾ç±»å‹", len(annotation.segment_label_annotations))
                with col2:
                    st.metric("æ ‡ç­¾å®ä¾‹æ€»æ•°", len(label_data))
                with col3:
                    avg_confidence = sum(float(item["ç½®ä¿¡åº¦"]) for item in label_data) / len(label_data)
                    st.metric("å¹³å‡ç½®ä¿¡åº¦", f"{avg_confidence:.2f}")
                with col4:
                    if use_deepseek_translation:
                        st.metric("AIç¿»è¯‘æ ‡ç­¾", deepseek_translated)
                    else:
                        st.metric("æœ¬åœ°ç¿»è¯‘", local_translated)
                
                # ç¿»è¯‘è¯¦æƒ…
                if use_deepseek_translation and (local_translated > 0 or deepseek_translated > 0):
                    st.info(f"ğŸ“Š ç¿»è¯‘ç»Ÿè®¡: æœ¬åœ°å­—å…¸ç¿»è¯‘ {local_translated} ä¸ªï¼ŒDeepSeek AIç¿»è¯‘ {deepseek_translated} ä¸ª")
                
                # æ·»åŠ æ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†åŠŸèƒ½
                if video_path and video_id:
                    st.markdown("### ğŸ·ï¸ æ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†")
                    
                    # å¯è°ƒèŠ‚çš„å‚æ•°è®¾ç½®
                    with st.expander("âš™ï¸ æ ‡ç­¾ç‰‡æ®µå‚æ•°è®¾ç½®", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            min_duration = st.slider(
                                "æœ€å°ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰",
                                min_value=0.5,
                                max_value=5.0,
                                value=1.0,
                                step=0.5,
                                help="çŸ­äºæ­¤æ—¶é•¿çš„æ ‡ç­¾ç‰‡æ®µå°†è¢«è¿‡æ»¤"
                            )
                        with col2:
                            min_confidence = st.slider(
                                "æœ€å°ç½®ä¿¡åº¦",
                                min_value=0.1,
                                max_value=1.0,
                                value=0.5,
                                step=0.1,
                                help="ä½äºæ­¤ç½®ä¿¡åº¦çš„æ ‡ç­¾ç‰‡æ®µå°†è¢«è¿‡æ»¤"
                            )
                        with col3:
                            max_labels = st.slider(
                                "æœ€å¤§æ ‡ç­¾æ•°é‡",
                                min_value=5,
                                max_value=50,
                                value=10,
                                step=5,
                                help="å¤„ç†çš„æ ‡ç­¾æ•°é‡ä¸Šé™"
                            )
                    
                    # ç»Ÿè®¡åŸå§‹æ ‡ç­¾ä¿¡æ¯
                    total_labels = len(annotation.segment_label_annotations)
                    all_segments_count = 0
                    filtered_segments_count = 0
                    
                    # å‡†å¤‡æ ‡ç­¾ç‰‡æ®µæ•°æ®
                    label_segments = []
                    label_debug_info = []
                    
                    for i, label in enumerate(annotation.segment_label_annotations[:max_labels]):
                        label_name = label.entity.description
                        label_name_cn = translate_label_to_chinese(label_name, use_deepseek=use_deepseek_translation)
                        
                        for segment in label.segments:
                            try:
                                start_time = get_time_seconds(segment.segment.start_time_offset)
                                end_time = get_time_seconds(segment.segment.end_time_offset)
                                confidence = segment.confidence
                                duration = end_time - start_time
                                
                                all_segments_count += 1
                                
                                # è®°å½•è°ƒè¯•ä¿¡æ¯
                                label_debug_info.append({
                                    'label': label_name_cn,
                                    'duration': duration,
                                    'confidence': confidence,
                                    'start_time': start_time,
                                    'end_time': end_time,
                                    'passed_duration': duration >= min_duration,
                                    'passed_confidence': confidence >= min_confidence
                                })
                                
                                if duration >= min_duration and confidence >= min_confidence:
                                    filtered_segments_count += 1
                                    label_segments.append({
                                        'start_time': start_time,
                                        'end_time': end_time,
                                        'type': f"æ ‡ç­¾_{label_name_cn}",
                                        'confidence': confidence
                                    })
                            except Exception as e:
                                continue
                    
                    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æ£€æµ‹åˆ°çš„æ ‡ç­¾", total_labels)
                    with col2:
                        st.metric("åŸå§‹ç‰‡æ®µæ•°", all_segments_count)
                    with col3:
                        st.metric("è¿‡æ»¤åç‰‡æ®µ", filtered_segments_count)
                    with col4:
                        filter_rate = (filtered_segments_count / all_segments_count * 100) if all_segments_count > 0 else 0
                        st.metric("é€šè¿‡ç‡", f"{filter_rate:.1f}%")
                    
                    # æ˜¾ç¤ºè¯¦ç»†çš„è¿‡æ»¤ä¿¡æ¯
                    if st.checkbox("æ˜¾ç¤ºæ ‡ç­¾è¿‡æ»¤è¯¦æƒ…", key="show_label_filter_details"):
                        st.markdown("#### ğŸ“Š æ ‡ç­¾ç‰‡æ®µè¿‡æ»¤è¯¦æƒ…")
                        
                        if label_debug_info:
                            import pandas as pd
                            df_debug = pd.DataFrame(label_debug_info)
                            
                            # æ·»åŠ çŠ¶æ€åˆ—
                            df_debug['çŠ¶æ€'] = df_debug.apply(
                                lambda row: 'âœ… é€šè¿‡' if row['passed_duration'] and row['passed_confidence'] 
                                else f"âŒ {'æ—¶é•¿ä¸è¶³' if not row['passed_duration'] else ''}{'ç½®ä¿¡åº¦ä½' if not row['passed_confidence'] else ''}", 
                                axis=1
                            )
                            
                            # æ ¼å¼åŒ–æ˜¾ç¤º
                            df_display = df_debug[['label', 'duration', 'confidence', 'çŠ¶æ€']].copy()
                            df_display['duration'] = df_display['duration'].apply(lambda x: f"{x:.2f}s")
                            df_display['confidence'] = df_display['confidence'].apply(lambda x: f"{x:.2f}")
                            df_display.columns = ['æ ‡ç­¾', 'æ—¶é•¿', 'ç½®ä¿¡åº¦', 'çŠ¶æ€']
                            
                            st.dataframe(df_display, use_container_width=True, hide_index=True)
                            
                            # åˆ†æè¿‡æ»¤åŸå› 
                            duration_filtered = len([x for x in label_debug_info if not x['passed_duration']])
                            confidence_filtered = len([x for x in label_debug_info if not x['passed_confidence']])
                            
                            st.info(f"ğŸ“ˆ è¿‡æ»¤ç»Ÿè®¡: {duration_filtered} ä¸ªå› æ—¶é•¿ä¸è¶³è¢«è¿‡æ»¤ï¼Œ{confidence_filtered} ä¸ªå› ç½®ä¿¡åº¦è¿‡ä½è¢«è¿‡æ»¤")
                        else:
                            st.warning("æ²¡æœ‰æ ‡ç­¾ç‰‡æ®µæ•°æ®")
                    
                    if label_segments:
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.info(f"å°†æ ¹æ® {len(label_segments)} ä¸ªæ ‡ç­¾ç‰‡æ®µåˆ‡åˆ†è§†é¢‘")
                        with col2:
                            if st.button("ğŸ”ª å¼€å§‹åˆ‡åˆ†æ ‡ç­¾", type="secondary"):
                                with st.spinner("æ­£åœ¨åˆ‡åˆ†æ ‡ç­¾ç‰‡æ®µ..."):
                                    created_segments = create_video_segments(video_path, label_segments, video_id)
                                    
                                    if created_segments:
                                        st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªæ ‡ç­¾ç‰‡æ®µ")
                                        
                                        # æ˜¾ç¤ºåˆ›å»ºçš„ç‰‡æ®µä¿¡æ¯
                                        with st.expander("ğŸ“ æŸ¥çœ‹åˆ›å»ºçš„æ ‡ç­¾ç‰‡æ®µ", expanded=True):
                                            for segment in created_segments:
                                                col1, col2, col3 = st.columns([2, 1, 1])
                                                with col1:
                                                    st.write(f"**{segment['type']}** ({segment['duration']:.1f}ç§’)")
                                                with col2:
                                                    st.write(f"{segment['file_size']:.1f} MB")
                                                with col3:
                                                    if st.button(f"ğŸ“ æ‰“å¼€", key=f"open_label_{segment['index']}"):
                                                        import subprocess
                                                        subprocess.run(["open", "-R", segment['file_path']], check=False)
                                    else:
                                        st.error("âŒ æ ‡ç­¾ç‰‡æ®µåˆ›å»ºå¤±è´¥")
                    else:
                        st.info("æ²¡æœ‰æ‰¾åˆ°é€‚åˆåˆ‡åˆ†çš„æ ‡ç­¾ç‰‡æ®µï¼ˆéœ€è¦è‡³å°‘1ç§’é•¿åº¦ï¼‰")
                    
            else:
                st.warning("æ²¡æœ‰æˆåŠŸè§£æçš„æ ‡ç­¾æ•°æ®")
                
        except Exception as e:
            st.error(f"æ ‡ç­¾æ£€æµ‹ç»“æœæ˜¾ç¤ºé”™è¯¯: {e}")
            # æ˜¾ç¤ºåŸå§‹æ•°æ®ç”¨äºè°ƒè¯•
            st.write("åŸå§‹æ ‡ç­¾æ•°æ®:")
            st.json(str(annotation.segment_label_annotations[0]) if annotation.segment_label_annotations else "æ— æ•°æ®")
    
    # æ–‡æœ¬æ£€æµ‹ç»“æœ
    if text_detection and annotation.text_annotations:
        st.subheader("ğŸ“ æ–‡æœ¬æ£€æµ‹ç»“æœ")
        
        try:
            for text_annotation in annotation.text_annotations:
                st.write(f"**æ£€æµ‹åˆ°çš„æ–‡æœ¬:** {text_annotation.text}")
                
                for segment in text_annotation.segments:
                    try:
                        start_time = get_time_seconds(segment.segment.start_time_offset)
                        end_time = get_time_seconds(segment.segment.end_time_offset)
                        confidence = segment.confidence
                        
                        st.write(f"  - æ—¶é—´æ®µ: {start_time:.2f}s - {end_time:.2f}s, ç½®ä¿¡åº¦: {confidence:.2f}")
                    except Exception as e:
                        st.write(f"  - æ—¶é—´æ®µè§£æé”™è¯¯: {e}")
        except Exception as e:
            st.error(f"æ–‡æœ¬æ£€æµ‹ç»“æœæ˜¾ç¤ºé”™è¯¯: {e}")
    
    # äººè„¸æ£€æµ‹ç»“æœ
    if face_detection and annotation.face_annotations:
        st.subheader("ğŸ‘¤ äººè„¸æ£€æµ‹ç»“æœ")
        
        # ä½¿ç”¨åˆ†æå™¨æå–äººè„¸ä¿¡æ¯
        mock_result = {"success": True, "result": result}
        faces = google_analyzer.extract_faces(mock_result)
        
        st.info(f"æ£€æµ‹åˆ° {len(annotation.face_annotations)} ä¸ªäººè„¸è½¨è¿¹")
        
        face_segments = []  # ç”¨äºè§†é¢‘åˆ‡åˆ†çš„äººè„¸ç‰‡æ®µæ•°æ®
        
        try:
            # æŒ‰äººè„¸IDåˆ†ç»„æ˜¾ç¤º
            face_groups = {}
            for face in faces:
                face_id = face['face_id']
                if face_id not in face_groups:
                    face_groups[face_id] = []
                face_groups[face_id].append(face)
            
            for face_id, segments in list(face_groups.items())[:5]:  # æ˜¾ç¤ºå‰5ä¸ªäººè„¸
                st.write(f"**äººè„¸ {face_id}:**")
                
                for face in segments:
                    start_time = face['start_time']
                    end_time = face['end_time']
                    
                    st.write(f"  - å‡ºç°æ—¶é—´: {start_time:.2f}s - {end_time:.2f}s")
                    
                    # å‡†å¤‡åˆ‡åˆ†æ•°æ®ï¼ˆåªå¤„ç†1ç§’ä»¥ä¸Šçš„ç‰‡æ®µï¼‰
                    if face['duration'] >= 1.0:
                        face_segments.append({
                            'start_time': start_time,
                            'end_time': end_time,
                            'type': face['type'],
                            'confidence': face['confidence']
                        })
            
            # æ·»åŠ äººè„¸ç‰‡æ®µåˆ‡åˆ†åŠŸèƒ½
            if video_path and video_id and face_segments:
                st.markdown("### ğŸ‘¤ äººè„¸ç‰‡æ®µåˆ‡åˆ†")
                
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.info(f"å°†æ ¹æ® {len(face_segments)} ä¸ªäººè„¸ç‰‡æ®µåˆ‡åˆ†è§†é¢‘")
                with col2:
                    if st.button("ğŸ”ª å¼€å§‹åˆ‡åˆ†äººè„¸", type="secondary"):
                        with st.spinner("æ­£åœ¨åˆ‡åˆ†äººè„¸ç‰‡æ®µ..."):
                            created_segments = create_video_segments(video_path, face_segments, video_id)
                            
                            if created_segments:
                                st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªäººè„¸ç‰‡æ®µ")
                                
                                # æ˜¾ç¤ºåˆ›å»ºçš„ç‰‡æ®µä¿¡æ¯
                                with st.expander("ğŸ“ æŸ¥çœ‹åˆ›å»ºçš„äººè„¸ç‰‡æ®µ", expanded=True):
                                    for segment in created_segments:
                                        col1, col2, col3 = st.columns([2, 1, 1])
                                        with col1:
                                            st.write(f"**{segment['type']}** ({segment['duration']:.1f}ç§’)")
                                        with col2:
                                            st.write(f"{segment['file_size']:.1f} MB")
                                        with col3:
                                            if st.button(f"ğŸ“ æ‰“å¼€", key=f"open_face_{segment['index']}"):
                                                import subprocess
                                                subprocess.run(["open", "-R", segment['file_path']], check=False)
                            else:
                                st.error("âŒ äººè„¸ç‰‡æ®µåˆ›å»ºå¤±è´¥")
            elif video_path and video_id and not face_segments:
                st.info("æ²¡æœ‰æ‰¾åˆ°é€‚åˆåˆ‡åˆ†çš„äººè„¸ç‰‡æ®µï¼ˆéœ€è¦è‡³å°‘1ç§’é•¿åº¦ï¼‰")
                
        except Exception as e:
            st.error(f"äººè„¸æ£€æµ‹ç»“æœæ˜¾ç¤ºé”™è¯¯: {e}")
    

    
    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    with st.expander("ğŸ” è°ƒè¯•ä¿¡æ¯"):
        st.write("**åˆ†æç»“æœè¯¦æƒ…:**")
        
        # æ£€æŸ¥å„ç§åˆ†æç»“æœ
        results_summary = []
        
        # é•œå¤´åˆ‡åˆ†
        if hasattr(annotation, 'shot_annotations'):
            if annotation.shot_annotations:
                results_summary.append(f"âœ… é•œå¤´åˆ‡åˆ†: {len(annotation.shot_annotations)} ä¸ªé•œå¤´")
            else:
                results_summary.append("âŒ é•œå¤´åˆ‡åˆ†: æ— ç»“æœ")
        else:
            results_summary.append("âŒ é•œå¤´åˆ‡åˆ†: æœªæ£€æµ‹")
            
        # æ ‡ç­¾æ£€æµ‹
        if hasattr(annotation, 'segment_label_annotations'):
            if annotation.segment_label_annotations:
                results_summary.append(f"âœ… æ ‡ç­¾æ£€æµ‹: {len(annotation.segment_label_annotations)} ä¸ªæ ‡ç­¾")
            else:
                results_summary.append("âŒ æ ‡ç­¾æ£€æµ‹: æ— ç»“æœ")
        else:
            results_summary.append("âŒ æ ‡ç­¾æ£€æµ‹: æœªæ£€æµ‹")
            
        # æ–‡æœ¬æ£€æµ‹
        if hasattr(annotation, 'text_annotations'):
            if annotation.text_annotations:
                results_summary.append(f"âœ… æ–‡æœ¬æ£€æµ‹: {len(annotation.text_annotations)} ä¸ªæ–‡æœ¬")
            else:
                results_summary.append("âŒ æ–‡æœ¬æ£€æµ‹: æ— ç»“æœ")
        else:
            results_summary.append("âŒ æ–‡æœ¬æ£€æµ‹: æœªæ£€æµ‹")
            
        # äººè„¸æ£€æµ‹
        if hasattr(annotation, 'face_annotations'):
            if annotation.face_annotations:
                results_summary.append(f"âœ… äººè„¸æ£€æµ‹: {len(annotation.face_annotations)} ä¸ªäººè„¸")
            else:
                results_summary.append("âŒ äººè„¸æ£€æµ‹: æ— ç»“æœ")
        else:
            results_summary.append("âŒ äººè„¸æ£€æµ‹: æœªæ£€æµ‹")
            

            
        # ç‰©ä½“è·Ÿè¸ª
        if hasattr(annotation, 'object_annotations'):
            if annotation.object_annotations:
                results_summary.append(f"âœ… ç‰©ä½“è·Ÿè¸ª: {len(annotation.object_annotations)} ä¸ªç‰©ä½“")
            else:
                results_summary.append("âŒ ç‰©ä½“è·Ÿè¸ª: æ— ç»“æœ")
        else:
            results_summary.append("âŒ ç‰©ä½“è·Ÿè¸ª: æœªæ£€æµ‹")
        
        for result in results_summary:
            st.write(f"- {result}")
            
        # æ˜¾ç¤ºåŸå§‹annotationç»“æ„ï¼ˆç”¨äºé«˜çº§è°ƒè¯•ï¼‰
        if st.checkbox("æ˜¾ç¤ºåŸå§‹APIå“åº”ç»“æ„"):
            st.write("**åŸå§‹annotationå¯¹è±¡å±æ€§:**")
            attrs = [attr for attr in dir(annotation) if not attr.startswith('_')]
            st.write(attrs)
            
            st.write("**annotationå¯¹è±¡è¯¦æƒ…:**")
            st.json({
                "has_shot_annotations": hasattr(annotation, 'shot_annotations'),
                "has_segment_label_annotations": hasattr(annotation, 'segment_label_annotations'),
                "has_text_annotations": hasattr(annotation, 'text_annotations'),
                "has_face_annotations": hasattr(annotation, 'face_annotations'),
                "has_object_annotations": hasattr(annotation, 'object_annotations'),
            })
    
    # ç»¼åˆåˆ‡åˆ†åŠŸèƒ½
    if video_path and video_id:
        st.markdown("---")
        st.subheader("ğŸ¬ ç»¼åˆè§†é¢‘åˆ‡åˆ†")
        st.markdown("ä¸€æ¬¡æ€§æ ¹æ®æ‰€æœ‰æ£€æµ‹ç»“æœåˆ›å»ºè§†é¢‘ç‰‡æ®µ")
        
        # æ”¶é›†æ‰€æœ‰å¯åˆ‡åˆ†çš„ç‰‡æ®µ
        all_segments = []
        
        # é•œå¤´ç‰‡æ®µ
        if shot_detection and annotation.shot_annotations:
            for i, shot in enumerate(annotation.shot_annotations):
                try:
                    start_time = get_time_seconds(shot.start_time_offset)
                    end_time = get_time_seconds(shot.end_time_offset)
                    if end_time - start_time >= 0.5:
                        all_segments.append({
                            'start_time': start_time,
                            'end_time': end_time,
                            'type': f"é•œå¤´{i+1}",
                            'confidence': 1.0,
                            'category': 'é•œå¤´åˆ‡åˆ†'
                        })
                except:
                    continue
        
        # æ ‡ç­¾ç‰‡æ®µ
        if label_detection and annotation.segment_label_annotations:
            for label in annotation.segment_label_annotations[:5]:  # é™åˆ¶å‰5ä¸ªæ ‡ç­¾
                label_name = label.entity.description
                label_name_cn = translate_label_to_chinese(label_name, use_deepseek=use_deepseek_translation)
                
                for segment in label.segments:
                    try:
                        start_time = get_time_seconds(segment.segment.start_time_offset)
                        end_time = get_time_seconds(segment.segment.end_time_offset)
                        confidence = segment.confidence
                        
                        if end_time - start_time >= 1.0:
                            all_segments.append({
                                'start_time': start_time,
                                'end_time': end_time,
                                'type': f"æ ‡ç­¾_{label_name_cn}",
                                'confidence': confidence,
                                'category': 'æ ‡ç­¾æ£€æµ‹'
                            })
                    except:
                        continue
        
        # äººè„¸ç‰‡æ®µ
        if face_detection and annotation.face_annotations:
            for i, face in enumerate(annotation.face_annotations[:3]):  # é™åˆ¶å‰3ä¸ªäººè„¸
                for j, segment in enumerate(face.segments):
                    try:
                        start_time = get_time_seconds(segment.segment.start_time_offset)
                        end_time = get_time_seconds(segment.segment.end_time_offset)
                        
                        if end_time - start_time >= 1.0:
                            all_segments.append({
                                'start_time': start_time,
                                'end_time': end_time,
                                'type': f"äººè„¸{i+1}_ç‰‡æ®µ{j+1}",
                                'confidence': 1.0,
                                'category': 'äººè„¸æ£€æµ‹'
                            })
                    except:
                        continue
        
        if all_segments:
            # æŒ‰æ—¶é—´æ’åº
            all_segments.sort(key=lambda x: x['start_time'])
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3, col4 = st.columns(4)
            
            shot_count = len([s for s in all_segments if s['category'] == 'é•œå¤´åˆ‡åˆ†'])
            label_count = len([s for s in all_segments if s['category'] == 'æ ‡ç­¾æ£€æµ‹'])
            face_count = len([s for s in all_segments if s['category'] == 'äººè„¸æ£€æµ‹'])
            
            with col1:
                st.metric("é•œå¤´ç‰‡æ®µ", shot_count)
            with col2:
                st.metric("æ ‡ç­¾ç‰‡æ®µ", label_count)
            with col3:
                st.metric("äººè„¸ç‰‡æ®µ", face_count)
            with col4:
                st.metric("æ€»ç‰‡æ®µæ•°", len(all_segments))
            
            # åˆ‡åˆ†æŒ‰é’®
            col1, col2 = st.columns([3, 1])
            with col1:
                st.info(f"å°†åˆ›å»º {len(all_segments)} ä¸ªè§†é¢‘ç‰‡æ®µï¼Œä¿å­˜åˆ° data/output/google_video/ ç›®å½•")
            with col2:
                if st.button("ğŸš€ å¼€å§‹ç»¼åˆåˆ‡åˆ†", type="primary", key="comprehensive_cut"):
                    with st.spinner("æ­£åœ¨åˆ›å»ºæ‰€æœ‰è§†é¢‘ç‰‡æ®µ..."):
                        created_segments = create_video_segments(video_path, all_segments, video_id)
                        
                        if created_segments:
                            st.success(f"âœ… æˆåŠŸåˆ›å»º {len(created_segments)} ä¸ªè§†é¢‘ç‰‡æ®µ")
                            
                            # æŒ‰ç±»åˆ«ç»Ÿè®¡
                            category_stats = {}
                            total_size = 0
                            total_duration = 0
                            
                            for segment in created_segments:
                                category = next((s['category'] for s in all_segments if s['type'] == segment['type']), 'æœªçŸ¥')
                                if category not in category_stats:
                                    category_stats[category] = {'count': 0, 'size': 0, 'duration': 0}
                                
                                category_stats[category]['count'] += 1
                                category_stats[category]['size'] += segment['file_size']
                                category_stats[category]['duration'] += segment['duration']
                                
                                total_size += segment['file_size']
                                total_duration += segment['duration']
                            
                            # æ˜¾ç¤ºç»Ÿè®¡ç»“æœ
                            st.markdown("### ğŸ“Š åˆ‡åˆ†ç»“æœç»Ÿè®¡")
                            
                            col1, col2 = st.columns(2)
                            with col1:
                                st.write("**æŒ‰ç±»åˆ«ç»Ÿè®¡:**")
                                for category, stats in category_stats.items():
                                    st.write(f"- {category}: {stats['count']} ä¸ªç‰‡æ®µ, {stats['size']:.1f} MB, {stats['duration']:.1f} ç§’")
                            
                            with col2:
                                st.write("**æ€»è®¡:**")
                                st.write(f"- æ€»ç‰‡æ®µæ•°: {len(created_segments)}")
                                st.write(f"- æ€»å¤§å°: {total_size:.1f} MB")
                                st.write(f"- æ€»æ—¶é•¿: {total_duration:.1f} ç§’")
                            
                            # æ˜¾ç¤ºè¾“å‡ºç›®å½•
                            from pathlib import Path
                            root_dir = Path(__file__).parent.parent.parent
                            output_dir = root_dir / "data" / "output" / "google_video"
                            
                            st.info(f"ğŸ“ æ‰€æœ‰ç‰‡æ®µå·²ä¿å­˜åˆ°: {output_dir}")
                            
                            if st.button("ğŸ“‚ æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹"):
                                import subprocess
                                subprocess.run(["open", str(output_dir)], check=False)
                        else:
                            st.error("âŒ è§†é¢‘ç‰‡æ®µåˆ›å»ºå¤±è´¥")
        else:
            st.info("æ²¡æœ‰æ‰¾åˆ°å¯åˆ‡åˆ†çš„ç‰‡æ®µæ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    st.title("ğŸ”¬ Google Cloud Video Intelligence API æµ‹è¯•")
    st.markdown("""
    è¿™ä¸ªæµ‹è¯•é¡µé¢å¯ä»¥å¸®æ‚¨éªŒè¯ Google Cloud Video Intelligence API çš„å„é¡¹åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
    - ğŸ¬ é•œå¤´åˆ‡åˆ†æ£€æµ‹
    - ğŸ·ï¸ æ ‡ç­¾æ£€æµ‹
    - ğŸ“ æ–‡æœ¬æ£€æµ‹
    - ğŸ‘¤ äººè„¸æ£€æµ‹
    - ğŸ“¦ ç‰©ä½“è·Ÿè¸ª
    
    **ğŸš€ æ ¸å¿ƒåŠŸèƒ½**:
    - âœ‚ï¸ **æ™ºèƒ½è§†é¢‘åˆ‡åˆ†**: æ ¹æ®Google Cloudåˆ†æç»“æœè‡ªåŠ¨åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ
    - ğŸ“ ç‰‡æ®µè‡ªåŠ¨ä¿å­˜åˆ° `data/output/google_video/` ç›®å½•
    - ğŸ“Š æä¾›è¯¦ç»†çš„åˆ†æç»Ÿè®¡å’Œå¯è§†åŒ–å±•ç¤º
    - ğŸ” æ”¯æŒé•œå¤´ã€æ ‡ç­¾ã€äººè„¸ç­‰å¤šç§åˆ‡åˆ†æ¨¡å¼
    
    **ä½¿ç”¨æµç¨‹**: ä¸Šä¼ è§†é¢‘ â†’ Google Cloud AIåˆ†æ â†’ è‡ªåŠ¨åˆ‡åˆ†è§†é¢‘ç‰‡æ®µ â†’ æŸ¥çœ‹ç»“æœ
    """)
    st.markdown("---")
    
    # æ£€æŸ¥å‡­æ®çŠ¶æ€
    has_credentials, cred_path = check_credentials()
    
    if has_credentials:
        st.success(f"âœ… Google Cloud å‡­æ®å·²è®¾ç½®: {cred_path}")
        
        # æ˜¾ç¤ºå½“å‰é¡¹ç›®ä¿¡æ¯
        try:
            with open(cred_path, 'r', encoding='utf-8') as f:
                cred_data = json.load(f)
                st.info(f"å½“å‰é¡¹ç›®ID: {cred_data.get('project_id', 'Unknown')}")
        except:
            pass
        
        # æä¾›é‡æ–°ä¸Šä¼ é€‰é¡¹
        if st.button("ğŸ”„ é‡æ–°ä¸Šä¼ å‡­æ®æ–‡ä»¶"):
            if upload_credentials():
                st.rerun()
        
        # ä¿ç•™å…¼å®¹æ€§
        use_deepseek_translation = False
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ä¿å­˜çš„åˆ†æç»“æœ
        if st.session_state.analysis_result and st.session_state.analysis_config:
            st.success("âœ… å‘ç°ä¹‹å‰çš„åˆ†æç»“æœ")
            
            # æ˜¾ç¤ºä¹‹å‰çš„åˆ†æç»“æœ
            config = st.session_state.analysis_config
            display_results(
                st.session_state.analysis_result,
                config['shot_detection'],
                config['label_detection'], 
                config['text_detection'],
                config['face_detection'],
                config.get('object_tracking', False),
                config['use_deepseek_translation'],
                st.session_state.current_video_path,
                st.session_state.current_video_id
            )
            
            # æ·»åŠ æ¸…é™¤ç»“æœæŒ‰é’®
            if st.button("ğŸ”„ é‡æ–°åˆ†æ", type="secondary"):
                st.session_state.analysis_result = None
                st.session_state.current_video_path = None
                st.session_state.current_video_id = None
                st.session_state.analysis_config = None
                st.rerun()
        else:
            # å¼€å§‹æµ‹è¯•
            test_video_intelligence(use_deepseek_translation)
        
    else:
        st.warning("âš ï¸ æœªæ£€æµ‹åˆ° Google Cloud å‡­æ®")
        st.markdown("""
        ### ğŸ“‹ è®¾ç½®æ­¥éª¤ï¼š
        
        1. **åˆ›å»º Google Cloud é¡¹ç›®**
           - è®¿é—® [Google Cloud Console](https://console.cloud.google.com)
           - åˆ›å»ºæ–°é¡¹ç›®æˆ–é€‰æ‹©ç°æœ‰é¡¹ç›®
        
        2. **å¯ç”¨ Video Intelligence API**
           - åœ¨å¯¼èˆªèœå•ä¸­é€‰æ‹© "API å’ŒæœåŠ¡" > "åº“"
           - æœç´¢å¹¶å¯ç”¨ "Cloud Video Intelligence API"
        
        3. **åˆ›å»ºæœåŠ¡è´¦å·**
           - åœ¨å¯¼èˆªèœå•ä¸­é€‰æ‹© "API å’ŒæœåŠ¡" > "å‡­æ®"
           - ç‚¹å‡» "åˆ›å»ºå‡­æ®" > "æœåŠ¡è´¦å·"
           - å¡«å†™æœåŠ¡è´¦å·ä¿¡æ¯å¹¶å®Œæˆåˆ›å»º
        
        4. **ä¸‹è½½å¯†é’¥æ–‡ä»¶**
           - åœ¨æœåŠ¡è´¦å·åˆ—è¡¨ä¸­ï¼Œç‚¹å‡»åˆšåˆ›å»ºçš„è´¦å·
           - é€‰æ‹© "å¯†é’¥" æ ‡ç­¾é¡µ
           - ç‚¹å‡» "æ·»åŠ å¯†é’¥" > "åˆ›å»ºæ–°å¯†é’¥"ï¼Œé€‰æ‹© JSON æ ¼å¼
        
        5. **ä¸Šä¼ å¯†é’¥æ–‡ä»¶**
           - ä½¿ç”¨ä¸‹é¢çš„æ–‡ä»¶ä¸Šä¼ å™¨ä¸Šä¼ åˆšä¸‹è½½çš„ JSON å¯†é’¥æ–‡ä»¶
        """)
        
        # ä¸Šä¼ å‡­æ®
        if upload_credentials():
            st.rerun()

if __name__ == "__main__":
    main() 